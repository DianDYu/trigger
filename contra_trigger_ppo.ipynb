{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration, BlenderbotConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.generation_beam_search import BeamSearchScorer\n",
    "\n",
    "from ppo_model_ac import BlenderWithValueModel\n",
    "\n",
    "from ppo import AdaptiveKLController, FixedKLController\n",
    "from ppo_utils import build_bert_batch_from_txt, logprobs_from_logits, whiten, clip_by_value, entropy_from_logits, flatten_dict, stats_to_np, stack_dicts\n",
    "from utils import get_classifier, generate_next, concat_past, expand_past, read_file\n",
    "from trigger_semi_supervised import penalize_new_line, prep_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BlenderWithValueModel were not initialized from the model checkpoint at facebook/blenderbot-400M-distill and are newly initialized: ['v_head.summary.weight', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlenderWithValueModel(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): Embedding(8008, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
       "  (v_head): ValueHead(\n",
       "    (summary): Linear(in_features=1280, out_features=1, bias=True)\n",
       "    (activation): Identity()\n",
       "    (first_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (last_dropout): Identity()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mname = 'facebook/blenderbot-400M-distill'\n",
    "model = BlenderWithValueModel.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "model.config.do_sample = True\n",
    "model.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lm_name\": \"gpt2-medium\",\n",
    "    \"ref_lm_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"cls_model_name\": \"/mnt//trigger_experiments/roberta_decode\",  # WARNING: No special token inserted for roles\n",
    "    \"tk_name\": \"gpt2\",\n",
    "    \"steps\": 75200,  # changed from 30720 for finetune\n",
    "    \"batch_size\": 752,  # changed from 512\n",
    "    \"forward_batch_size\": 16,  # WARNING: changed forward_batch_size and batch_size to 4 for debugging. Was 16\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_len\": 5,\n",
    "    \"txt_out_len\": 20,\n",
    "    \"lr\": 2e-4, # WARNING: Changed from 5e-4. debugging with smaller learning rate\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "    \"seed\": 2,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "#     \"tgt_label\": 1,  # 0 for negative, 1 for positive\n",
    "    \"tgt_label\": 0,  # 0 for not_ok, 1 for ok\n",
    "    \"ppo_mini_batch_size\": 16,\n",
    "    \"padding_token\": 50256,  # padding token for GPT-2 (same as BOS)\n",
    "    \"reset_pos_emb\": True,\n",
    "    \"num_of_triggers\": 1,\n",
    "    \"trigger_format\": \"key_value\",\n",
    "    \"TRIGGER_POSITION_ID\" : 0,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# for blender:\n",
    "num_beam_groups = 1\n",
    "do_sample = False\n",
    "\n",
    "pad_token_id = 0\n",
    "bos_token_id = 1\n",
    "eos_token_id = 2\n",
    "\n",
    "# length_penalty = 0.65\n",
    "# early_stopping = False\n",
    "    \n",
    "# logits_processor = model._get_logits_processor(\n",
    "#     repetition_penalty=1.0,\n",
    "#     no_repeat_ngram_size=3,\n",
    "#     bad_words_ids=None,\n",
    "#     min_length=20,\n",
    "#     eos_token_id=eos_token_id,\n",
    "#     prefix_allowed_tokens_fn=None,\n",
    "#     num_beams=10,\n",
    "#     num_beam_groups=num_beam_groups,\n",
    "#     diversity_penalty=0,\n",
    "# )\n",
    "\n",
    "batch_size = 16  # should be the same as forward_batch_size\n",
    "num_of_triggers = 1\n",
    "trigger_format = \"key_value\"\n",
    "reset_pos_emb = True\n",
    "TRIGGER_POSITION_ID = 0\n",
    "\n",
    "model.model.encoder.reset_pos_emb = reset_pos_emb\n",
    "model.model.encoder.num_of_triggers = num_of_triggers\n",
    "\n",
    "# WARNING: need to change \n",
    "sample = True\n",
    "top_k = 10\n",
    "temperature = 1.0\n",
    "repetition_penalty = 1.0\n",
    "length = 40\n",
    "\n",
    "\n",
    "if num_of_triggers > 1:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n",
    "if not reset_pos_emb:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Training: data/trigger_decode_human-bot.txt with shuffle_data = True\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/mnt//trigger_experiments/contra_final_2_fthb_init_100\"\n",
    "\n",
    "cls_max_length = 256\n",
    "prompt_reward = False\n",
    "c_p_reward_weight = 0.2\n",
    "\n",
    "finetune_dev = True\n",
    "\n",
    "mode = \"train\"\n",
    "shuffle_data = True\n",
    "\n",
    "# WARNING: should change input\n",
    "training_data = \"data/trigger_decode_train.txt\"\n",
    "if finetune_dev:\n",
    "    training_data = \"data/trigger_decode_human-bot.txt\"\n",
    "#     finetune_init_ckeckpoint = \"/mnt//trigger_experiments/contra_final_2/e17.pt\"\n",
    "    finetune_init_ckeckpoint = None\n",
    "\n",
    "    \n",
    "context_list = read_file(training_data)\n",
    "\n",
    "print(\"WARNING: Training: %s with shuffle_data = %s\" % (training_data, shuffle_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">contra_ppo</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai//final_2_fthb_init_100\" target=\"_blank\">https://wandb.ai//final_2_fthb_init_100</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai//final_2_fthb_init_100/runs/n8y4a325\" target=\"_blank\">https://wandb.ai//final_2_fthb_init_100/runs/n8y4a325</a><br/>\n",
       "                Run data is saved locally in <code>/home//trigger/wandb/run-20210514_102513-n8y4a325</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(n8y4a325)</h1><iframe src=\"https://wandb.ai//final_2_fthb_init_100/runs/n8y4a325\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1edaa8aa58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name='contra_ppo', project='final_2_fthb_init_100', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model for classification\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(config[\"cls_model_name\"])\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(config[\"cls_model_name\"])\n",
    "cls_model.to(device)\n",
    "cls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "\n",
    "# Freeze GPT-2 weights\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"v_head\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "num_enc_layers = model.config.encoder_layers\n",
    "num_dec_layers = model.config.decoder_layers\n",
    "        \n",
    "    \n",
    "# lm_bos_output = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long, device=device).unsqueeze(0).repeat(batch_size, 1))  # BOS\n",
    "# # Note: GPT2HeadWithValueModel returns lm_logits, transformer_outputs[1:], value\n",
    "# # transformer_outputs: hidden_states, past_key_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1280])\n",
      "torch.Size([1, 32, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "# prepare for triggers\n",
    "\n",
    "# get_bos_embeddings\n",
    "bos_embeddings = model.model.encoder.embed_tokens(torch.tensor([bos_token_id], dtype=torch.long, device=device)).unsqueeze(0)  # 1, 1, hid_size\n",
    "\n",
    "# get_bos_key_values\n",
    "text_bos = [\"<s>\"]\n",
    "inputs_bos = tokenizer(text_bos, return_tensors='pt', padding=True).to(\"cuda\")\n",
    "inputs_bos_ids = inputs_bos[\"input_ids\"][:, 1:2]  # tensor([[228,   1,   2]]) for [<s>] (shape: 1, 3)\n",
    "bos_model_kwargs = dict()\n",
    "if bos_model_kwargs.get(\"attention_mask\", None) is None:\n",
    "    # init `attention_mask` depending on `pad_token_id`\n",
    "    bos_model_kwargs[\"attention_mask\"] = model._prepare_attention_mask_for_generation(\n",
    "        inputs_bos_ids, pad_token_id, eos_token_id\n",
    "    )\n",
    "\n",
    "bos_encoder_kwargs = {\n",
    "            argument: value for argument, value in bos_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "bos_output = model.model.encoder(inputs_bos_ids, return_dict=True, **bos_encoder_kwargs, use_cache=True)\n",
    "bos_key_values = bos_output[\"past_key_values\"]\n",
    "bos_hidden = bos_output[\"last_hidden_state\"]  # 1, 1, 1280\n",
    "print(bos_hidden.shape)\n",
    "print(bos_key_values[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trigger\n",
    "# Note: since we use the same trigger for all inputs in a batch, we only create/register trigger(s) for one and repeat it\n",
    "def init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=False):\n",
    "    if num_of_triggers > 0:\n",
    "        \n",
    "        # create hidden states for decoder\n",
    "        trigger_hidden_list = []\n",
    "        for _ in range(num_of_triggers):\n",
    "            trigger_hidden_i = nn.Parameter(copy.deepcopy(bos_hidden))\n",
    "            trigger_hidden_list.append(trigger_hidden_i)\n",
    "        if not ref:\n",
    "            ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            # WARNING: no need to register parameter?\n",
    "            model.register_parameter(name=\"ori_trigger_hidden\", param=ori_trigger_hidden)\n",
    "            model.ori_trigger_hidden = ori_trigger_hidden\n",
    "        else:\n",
    "            ref_ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            ref_ori_trigger_hidden.requires_grad = False\n",
    "            model.register_parameter(name=\"ref_ori_trigger_hidden\", param=ref_ori_trigger_hidden)\n",
    "            model.ref_ori_trigger_hidden = ref_ori_trigger_hidden\n",
    "            \n",
    "        if trigger_format == \"token\":  # learn a continuous embedding\n",
    "            trigger_embedding_list = []\n",
    "            for _ in range(num_of_triggers):\n",
    "                trigger_embedding_i = copy.deepcopy(bos_embeddings)\n",
    "                trigger_embedding_list.append(trigger_embedding_i)\n",
    "            if not ref:\n",
    "                ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                model.ori_trigger_embedding = ori_trigger_embedding  # register to the model (optimizer)\n",
    "            else:\n",
    "                ref_ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                ref_ori_trigger_embedding.requires_grad = False\n",
    "                model.ref_ori_trigger_embedding = ref_ori_trigger_embedding  # register to the model (optimizer)\n",
    "            # trigger_embedding = trigger_embedding.repeat(batch_size, 1, 1)  # cannot do it here, otherwise trigger_embedding becomes a non-leaf node where the grad will not backprop\n",
    "        elif trigger_format == \"key_value\":  # learn key values\n",
    "            ori_trigger_key_values = [(None, None) for _ in range(num_enc_layers)]\n",
    "            for layer in range(num_enc_layers):\n",
    "                for i_t in range(num_of_triggers):\n",
    "                    trigger_i_key_value = copy.deepcopy(bos_key_values)\n",
    "                    # key, value shape: bze, num_heads, seq_len, embed_per_head\n",
    "                    trigger_i_key, trigger_i_value = nn.Parameter(trigger_i_key_value[layer][0]), \\\n",
    "                                                     nn.Parameter(trigger_i_key_value[layer][1])\n",
    "\n",
    "                    if not ref:\n",
    "                        trigger_i_key.requires_grad = True\n",
    "                        trigger_i_value.requires_grad = True\n",
    "                    else:\n",
    "                        trigger_i_key.requires_grad = False\n",
    "                        trigger_i_value.requires_grad = False\n",
    "                        \n",
    "                    if ori_trigger_key_values[layer][0] is None:\n",
    "                        ori_trigger_key_values[layer] = (trigger_i_key, trigger_i_value)\n",
    "                    else:\n",
    "                        # if multiple triggers\n",
    "                        trigger_key = nn.Parameter(torch.cat((ori_trigger_key_values[layer][0], trigger_i_key), dim=-2))\n",
    "                        trigger_value = nn.Parameter(torch.cat((ori_trigger_key_values[layer][1], trigger_i_value), dim=-2))\n",
    "                        ori_trigger_key_values[layer] = (trigger_key, trigger_value)\n",
    "\n",
    "                if not ref:\n",
    "                    # register parameter into optimizer\n",
    "                    key_name = \"l_%d_key\" % layer\n",
    "                    value_name = \"l_%d_value\" % layer\n",
    "                else:\n",
    "                    key_name = \"ref_l_%d_key\" % layer\n",
    "                    value_name = \"ref_l_%d_value\" % layer\n",
    "                    \n",
    "                if num_of_triggers == 1:\n",
    "                    model.register_parameter(name=key_name, param=trigger_i_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_i_value)\n",
    "                else:\n",
    "                    model.register_parameter(name=key_name, param=trigger_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_value)\n",
    "                    \n",
    "            if not ref:\n",
    "                ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ori_trigger_key_values = ori_trigger_key_values\n",
    "            else:\n",
    "                ref_ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ref_ori_trigger_key_values = ori_trigger_key_values\n",
    "            # trigger_key_values = expand_past(trigger_key_values, num_layers, batch_size)  # similar to trigger_embedding, need leaf level grad\n",
    "        else:\n",
    "            assert False, \"trigger_format: %s not supported\" % trigger_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing params: \n",
      "ori_trigger_hidden l_0_key l_0_value l_1_key l_1_value v_head.summary.weight v_head.summary.bias\n"
     ]
    }
   ],
   "source": [
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=True)\n",
    "\n",
    "# optimizer\n",
    "param_optimizer = list(filter(lambda p: p[1].requires_grad, list(model.named_parameters())))\n",
    "\n",
    "# debugging: get all optimized param names\n",
    "print(\"optimizing params: \")\n",
    "print(\" \".join(o[0] for o in param_optimizer))\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=config[\"lr\"],\n",
    "                  eps=config[\"adam_epsilon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: fine-tuning from None\n",
      "total training steps: 75200\n"
     ]
    }
   ],
   "source": [
    "if finetune_dev:\n",
    "    if finetune_init_ckeckpoint is not None:\n",
    "        ft_saved_dict = torch.load(finetune_init_ckeckpoint)\n",
    "        model.ori_trigger_hidden = ft_saved_dict[\"ori_trigger_hidden\"]\n",
    "        model.ori_trigger_key_values = ft_saved_dict[\"ori_trigger_key_values\"]\n",
    "    print(\"WARNING: fine-tuning from %s\" % finetune_init_ckeckpoint)\n",
    "    print(\"total training steps: %d\" % config[\"steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f1f493708d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability distribution warper\n",
    "logits_warper = model._get_logits_warper(\n",
    "    top_k=model.config.top_k, top_p=model.config.top_p, temperature=model.config.temperature, num_beams=model.config.num_beams\n",
    ")\n",
    "\n",
    "# WARNING: use hyperparameters from the config instead of the following\n",
    "logits_processor = model._get_logits_processor(\n",
    "    repetition_penalty=model.config.repetition_penalty,\n",
    "    no_repeat_ngram_size=model.config.no_repeat_ngram_size,\n",
    "    bad_words_ids=None,\n",
    "    min_length=model.config.min_length,\n",
    "    eos_token_id=eos_token_id,\n",
    "    prefix_allowed_tokens_fn=None,\n",
    "    num_beams=model.config.num_beams,\n",
    "    num_beam_groups=model.config.num_beam_groups,\n",
    "    diversity_penalty=model.config.diversity_penalty,\n",
    ")\n",
    "\n",
    "\n",
    "if model.config.num_beams > 1:\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "            batch_size=config[\"forward_batch_size\"],\n",
    "            max_length=model.config.max_length,\n",
    "            num_beams=model.config.num_beams,\n",
    "            device=device,\n",
    "            length_penalty=model.config.length_penalty,\n",
    "            do_early_stopping=model.config.early_stopping,\n",
    "            num_beam_hyps_to_keep=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_trigger(text_list, num_layers, cur_num_of_triggers, get_ppl=False):\n",
    "    # cur_num_of_triggers: different from \"num_of_triggers\" in the config, can be 0 if is ref or num_of_triggers\n",
    "    batch_size = len(text_list)\n",
    "    \n",
    "    # prepare past\n",
    "    past = expand_past(bos_key_values, num_layers, batch_size)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":\n",
    "            trigger_embedding = model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "            lm_trigger_output = model.model.encoder(inputs_embeds=trigger_embedding)\n",
    "            trigger_key_values = lm_trigger_output[\"past_key_values\"]\n",
    "        else:\n",
    "            trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "        past = concat_past(past, trigger_key_values, num_layers)\n",
    "        \n",
    "    # prepare hidden\n",
    "    prev_hidden = bos_hidden.repeat(batch_size, 1, 1)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        trigger_hidden = model.ori_trigger_hidden\n",
    "        trigger_hidden = trigger_hidden.repeat(batch_size, 1, 1)\n",
    "        prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "    \n",
    "    # prepare context\n",
    "    prev_length = prev_hidden.shape[1]\n",
    "    ctx_model_kwargs = dict()\n",
    "    ctx_inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "    # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "    cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "    ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "    # get encoder output\n",
    "    trigger_encoder_kwargs = {\n",
    "            argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "    trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "    try:\n",
    "        ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "    except:\n",
    "        print(ctx_inputs[\"input_ids\"].shape)\n",
    "        assert False\n",
    "        \n",
    "    ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "\n",
    "    ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "    # generate one sentence with trigger\n",
    "    ctx_input_ids = ctx_inputs['input_ids']\n",
    "    dec_input_ids = model._prepare_decoder_input_ids_for_generation(\n",
    "                    ctx_input_ids, decoder_start_token_id=bos_token_id, bos_token_id=bos_token_id)\n",
    "     \n",
    "    is_greedy_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_sample_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    is_beam_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_beam_sample_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    \n",
    "    output_scores = False\n",
    "    return_dict_in_generate = model.config.return_dict_in_generate\n",
    "    if get_ppl:\n",
    "        output_scores = True\n",
    "        return_dict_in_generate = True\n",
    "        \n",
    "    if is_greedy_gen_mode:\n",
    "        res = model.greedy_search(\n",
    "                dec_input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=False,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "        \n",
    "    elif is_sample_gen_mode:\n",
    "\n",
    "        # expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids,\n",
    "            expand_size=model.config.num_return_sequences,\n",
    "            is_encoder_decoder=True,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "\n",
    "        # sample\n",
    "        res = model.sample(\n",
    "            dec_input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "    elif is_beam_gen_mode:\n",
    "        # interleave with `num_beams`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_search(\n",
    "            dec_input_ids,\n",
    "            beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=False,\n",
    "            return_dict_in_generate=model.config.return_dict_in_generate,\n",
    "            **ctx_model_kwargs,\n",
    "        ) \n",
    "    elif is_beam_sample_gen_mode:\n",
    "        # interleave with `num_beams * num_return_sequences`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams * model.config.num_return_sequences, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_sample(\n",
    "                dec_input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=output_scores,\n",
    "                return_dict_in_generate=model.config.return_dict_in_generate,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "     \n",
    "    if get_ppl:\n",
    "        generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "    \n",
    "        generated_sentence_mask = res.sequences.ne(pad_token_id).long()[:, :-2]  # the first one is bos\n",
    "        logits_tensor = torch.cat([raw_logits.unsqueeze(1) for raw_logits in res.scores], dim=1)  # bze x len x vocab\n",
    "        shift_logits = logits_tensor[..., :-1, :].contiguous()\n",
    "        shift_labels = res.sequences[..., 1:-1].contiguous()\n",
    "        loss_fct = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)).detach()\n",
    "        loss_reshape = loss.view(generated_sentence_mask.shape)  # bze x seq_len\n",
    "        # if loss is inf, then the masked loss (after multipling mask) will be nan\n",
    "        loss_reshape = torch.where(loss_reshape > 1e10, torch.ones_like(loss_reshape) * 0, loss_reshape)\n",
    "        masked_loss_sum = torch.sum(loss_reshape * generated_sentence_mask, dim=-1)  # [bze]\n",
    "        real_length = torch.sum(generated_sentence_mask, dim=-1)\n",
    "        masked_loss = torch.mean(masked_loss_sum / real_length).item()\n",
    "        ppl = math.exp(masked_loss)\n",
    "        return generated_sentence_clean, ppl\n",
    "    else:  \n",
    "        generated_sentence_raw = tokenizer.batch_decode(res)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        \n",
    "        return generated_sentence_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_blender_generation(raw_texts):\n",
    "    clean_texts = list()\n",
    "    for sentence_i in raw_texts:\n",
    "        sentence_i_0 = sentence_i.split(\"<s>\")[-1]\n",
    "        sentence_i_1 = sentence_i_0.split(\"</s>\")[0]\n",
    "        clean_texts.append(sentence_i_1.strip())\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cls_examples_to_features(texts_a, texts_b, max_length):\n",
    "    all_cls_input_ids, all_cls_attention_mask = list(), list()\n",
    "    for text_a, text_b in zip(texts_a, texts_b):\n",
    "        cls_inputs = cls_tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length, truncation=True)\n",
    "        cls_input_ids = cls_inputs[\"input_ids\"]\n",
    "        cls_attention_mask = [1] * len(cls_input_ids)\n",
    "        \n",
    "        padding_length = max_length - len(cls_input_ids)\n",
    "        \n",
    "        cls_input_ids = cls_input_ids + ([cls_tokenizer.pad_token_id] * padding_length)\n",
    "        cls_attention_mask = cls_attention_mask + ([0] * padding_length)\n",
    "        # token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)  # not used in RoBERTa\n",
    "        \n",
    "        all_cls_input_ids.append(cls_input_ids)\n",
    "        all_cls_attention_mask.append(cls_attention_mask)\n",
    "    \n",
    "    all_cls_input_tensors = torch.tensor(all_cls_input_ids, dtype=torch.long, device=device)\n",
    "    all_cls_attention_mask_tensors = torch.tensor(all_cls_attention_mask, dtype=torch.long, device=device)\n",
    "    \n",
    "    return all_cls_input_tensors, all_cls_attention_mask_tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOTrainer:\n",
    "    \"\"\"\n",
    "    The PPO_trainer uses Proximal Policy Optimization to optimise language models.\n",
    "    \"\"\"\n",
    "\n",
    "    default_params = {\n",
    "        \"lr\": 1.41e-5,\n",
    "        \"adap_kl_ctrl\": True,\n",
    "        \"init_kl_coef\":0.2,\n",
    "        \"target\": 6,\n",
    "        \"horizon\":10000,\n",
    "        \"gamma\":1,\n",
    "        \"lam\":0.95,\n",
    "        \"cliprange\": .2,\n",
    "        \"cliprange_value\":.2,\n",
    "        \"vf_coef\":.1,\n",
    "        \"batch_size\": 256,\n",
    "        \"forward_batch_size\": 16,\n",
    "        \"ppo_epochs\": 4,\n",
    "        \"ppo_mini_batch-size\": 4,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, optimizer, **ppo_params):\n",
    "        \"\"\"\n",
    "        Initialize PPOTrainer.\n",
    "        Args:\n",
    "            model (torch.model): Hugging Face transformer GPT2 model with value head\n",
    "            ref_model (torch.model): Hugging Face transformer GPT2 refrence model used for KL penalty\n",
    "            ppo_params (dict or None): PPO parameters for training. Can include following keys:\n",
    "                'lr' (float): Adam learning rate, default: 1.41e-5\n",
    "                'batch_size' (int): Number of samples per optimisation step, default: 256\n",
    "                'forward_batch_size' (int): Number of samples forward passed through model at a time, default: 16\n",
    "                'ppo_epochs' (int): Number of optimisation epochs per batch of samples, default: 4\n",
    "                'gamma' (float)): Gamma parameter for advantage calculation, default: 1.\n",
    "                'lam' (float): Lambda parameter for advantage calcualation, default: 0.95\n",
    "                'cliprange_value' (float): Range for clipping values in loss calculation, default: 0.2\n",
    "                'cliprange' (float): Range for clipping in PPO policy gradient loss, default: 0.2\n",
    "                'vf_coef' (float): Scaling factor for value loss, default: 0.1\n",
    "                'adap_kl_ctrl' (bool): Use adaptive KL control, otherwise linear, default: True\n",
    "                'init_kl_coef' (float): Initial KL penalty coefficient (used for adaptive and linear control), default: 0.2\n",
    "                'target' (float): Target KL value for adaptive KL control, default: 6.0\n",
    "                'horizon' (float): Horizon for adaptive KL control, default: 10000\n",
    "        \"\"\"\n",
    "        self.ppo_params = self.default_params\n",
    "        self.ppo_params.update(ppo_params)\n",
    "\n",
    "        # self.ref_model = ref_model\n",
    "        self.model = model\n",
    "        # self.optimizer = Adam(model.parameters(), lr=self.ppo_params['lr'])\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.kl_ctl = AdaptiveKLController(self.ppo_params['init_kl_coef'],\n",
    "                                           self.ppo_params['target'],\n",
    "                                           self.ppo_params['horizon'])\n",
    "\n",
    "\n",
    "    def step(self, all_c_texts, all_p_texts, all_scores):\n",
    "        \"\"\"\n",
    "        Run a PPO optimisation step.\n",
    "        args:\n",
    "            # query (torch.tensor): tensor containing the encoded queries, shape [batch_size, query_length]\n",
    "            # response (torch.tensor): tensor containing the encoded responses, shape [batch_size, response_length]\n",
    "            # scores (torch.tensor): tensor containing the scores, shape [batch_size]\n",
    "            all_c_p_tensors, all_c_p_lengths ...: list of minibatch tensors\n",
    "        returns:\n",
    "            train_stats (dict): a summary of the training statistics\n",
    "        \"\"\"\n",
    "\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "        timing = dict()\n",
    "        t0 = time.time()\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "#         print(\"batched trigger forward + compute_reward\")\n",
    "#         logprobs, ref_logprobs, values, rewards, non_score_reward, kl_coef, real_p_tensors, real_c_p_tensors, real_c_p_lengths, real_c_lengths = self.batched_trigger_forward_pass(\n",
    "#             all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_scores)\n",
    "        logprobs, ref_logprobs, values, rewards, non_score_reward, kl_coef = self.batched_trigger_forward_pass(\n",
    "            all_c_texts, all_p_texts, all_scores)\n",
    "        # flat text lists so that we can form dynamic batches in ppo epoches\n",
    "        flat_c_texts = sum(all_c_texts, [])\n",
    "        flat_p_texts = sum(all_p_texts, [])\n",
    "        timing['time/ppo/batched_trigger_forward'] = time.time()-t\n",
    "#         print(\"finished in %.2f seconds\\n\" % (time.time()-t))\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        all_stats = []\n",
    "        idxs = list(range(bs))\n",
    "\n",
    "        for ppo_epoch_i in range(self.ppo_params['ppo_epochs']):\n",
    "            if shuffle_data:\n",
    "                random.shuffle(idxs)\n",
    "            for i in range(bs // mini_bs):\n",
    "                b_idx = idxs[i*mini_bs:(i+1)*mini_bs]\n",
    "                b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts = \\\n",
    "                    list(), list(), list(), list(), list()\n",
    "                for b_idx_i in b_idx:\n",
    "                    b_logprobs.append(logprobs[b_idx_i])\n",
    "                    b_values.append(values[b_idx_i])\n",
    "                    b_rewards.append(rewards[b_idx_i])\n",
    "                    b_c_texts.append(flat_c_texts[b_idx_i])\n",
    "                    b_p_texts.append(flat_p_texts[b_idx_i])\n",
    "                \n",
    "#                 print(\"\\n\\n------ppo_epoch: %d/%d; minibatch: %d/%d--------\" % (ppo_epoch_i + 1, self.ppo_params['ppo_epochs'], i + 1, bs // mini_bs))\n",
    "                train_stats = self.train_minibatch(b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts)\n",
    "\n",
    "                all_stats.append(train_stats)\n",
    "\n",
    "        timing['time/ppo/optimize_step'] = time.time()-t\n",
    "\n",
    "        t = time.time()\n",
    "        train_stats = stack_dicts(all_stats)\n",
    "\n",
    "        # the following stats is ignored because the lengths are not the same\n",
    "#         # reshape advantages/ratios such that they are not averaged.\n",
    "#         train_stats['policy/advantages'] = torch.flatten(train_stats['policy/advantages']).unsqueeze(0)\n",
    "#         train_stats['policy/ratio'] = torch.flatten(train_stats['policy/ratio']).unsqueeze(0)\n",
    "\n",
    "        stats = self.record_step_stats(logprobs=logprobs, ref_logprobs=ref_logprobs, train_stats=train_stats,\n",
    "                                       kl_coef=kl_coef)\n",
    "        stats = stats_to_np(stats)\n",
    "        timing['time/ppo/calc_stats'] = time.time()-t\n",
    "\n",
    "        self.kl_ctl.update(stats['objective/kl'], self.ppo_params['batch_size'])\n",
    "\n",
    "        timing['time/ppo/total'] = time.time()-t0\n",
    "        stats.update(timing)\n",
    "        return stats\n",
    "\n",
    "    def get_trigger_forward_pass(self, c_texts, p_texts, is_ref=False):\n",
    "        reset_pos_emb = self.ppo_params[\"reset_pos_emb\"]\n",
    "        num_of_triggers = self.ppo_params[\"num_of_triggers\"]\n",
    "        trigger_format = self.ppo_params[\"trigger_format\"]\n",
    "        TRIGGER_POSITION_ID = self.ppo_params[\"TRIGGER_POSITION_ID\"]\n",
    "        device = self.ppo_params[\"device\"]\n",
    "        \n",
    "        mini_batch_size = len(c_texts)\n",
    "        \n",
    "        # WARNING: bos_key_value need to be passed\n",
    "        past = expand_past(bos_key_values, num_enc_layers, mini_batch_size)  # deep copy? shouldn't be modifed\n",
    "\n",
    "        if num_of_triggers > 0:\n",
    "            if trigger_format == \"token\":\n",
    "                if is_ref:\n",
    "                    trigger_embedding = self.model.ref_ori_trigger_embedding.repeat(mini_batch_size, 1, 1)\n",
    "                else:\n",
    "                    trigger_embedding = self.model.ori_trigger_embedding.repeat(mini_batch_size, 1, 1)\n",
    "                trigger_key_values = self.model.model.encoder(inputs_embeds=trigger_embedding)[\"past_key_values\"]\n",
    "            else:\n",
    "                if is_ref:\n",
    "                    trigger_key_values = expand_past(self.model.ref_ori_trigger_key_values, num_enc_layers, mini_batch_size)\n",
    "                else:\n",
    "                    trigger_key_values = expand_past(self.model.ori_trigger_key_values, num_enc_layers, mini_batch_size)\n",
    "\n",
    "            past = concat_past(past, trigger_key_values, num_enc_layers)\n",
    "        \n",
    "        # prepare hidden\n",
    "        prev_hidden = bos_hidden.repeat(mini_batch_size, 1, 1)\n",
    "        if num_of_triggers > 0:\n",
    "            trigger_hidden = model.ori_trigger_hidden\n",
    "            trigger_hidden = trigger_hidden.repeat(mini_batch_size, 1, 1)\n",
    "            prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "            \n",
    "        # prepare context\n",
    "        prev_length = prev_hidden.shape[1]\n",
    "        ctx_model_kwargs = dict()\n",
    "        ctx_inputs = tokenizer(c_texts, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "        # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "        cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "        ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "        \n",
    "        # get encoder output\n",
    "        trigger_encoder_kwargs = {\n",
    "                argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "            }\n",
    "        trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "        ctx_output = self.model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "        ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "        ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "        \n",
    "        # prepare decoder\n",
    "        # Note: when calling tokenizer, it will append <eos> to the end (2) but not <bos> at the beginning\n",
    "        prompt_inputs = tokenizer(p_texts, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "        prompt_inputs_ids = prompt_inputs[\"input_ids\"]\n",
    "        prompt_attn_mask = prompt_inputs[\"attention_mask\"]\n",
    "        # add bos\n",
    "        dec_bos_ids = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device) * bos_token_id\n",
    "        dec_bos_mask = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device)\n",
    "        dec_inputs_ids = torch.cat((dec_bos_ids, prompt_inputs_ids), dim=1)\n",
    "        dec_attn_mask = torch.cat((dec_bos_mask, prompt_attn_mask), dim=1)\n",
    "        prompt_length = torch.sum(dec_attn_mask, dim=-1)  # including bos and eos. shape: [bze]\n",
    "        # dec_attn_mask needs to be uni-directional? \n",
    "        # A: do not pass dec_attn_mask to the model. In decoder, when input length > 1, causal mask is created\n",
    "        \n",
    "#         print(\"debugging!\")\n",
    "#         print(c_texts)\n",
    "#         print(p_texts)\n",
    "#         print(\"ctx inputs: %s\" % str(ctx_inputs[\"input_ids\"].shape))\n",
    "#         print(\"encoder output hidden: %s\" % str(ctx_output[\"last_hidden_state\"].shape))\n",
    "#         print(dec_inputs_ids)\n",
    "#         print(dec_attn_mask)\n",
    "#         print(prompt_length)\n",
    "        \n",
    "        # Note: attention_mask is for encoder. \"decoder_attention_mask\" is for decoder\n",
    "        model_inputs = {\"decoder_input_ids\": dec_inputs_ids, \"encoder_outputs\": ctx_model_kwargs[\"encoder_outputs\"],\n",
    "                        \"attention_mask\": ctx_model_kwargs[\"attention_mask\"]}\n",
    "        outputs = self.model(**model_inputs, return_dict=True)\n",
    "        \n",
    "        logits = outputs[\"logits\"]\n",
    "        value = outputs[\"value\"]\n",
    "        \n",
    "#         print(\"dec_inputs_ids: %s\" % str(dec_inputs_ids.shape))\n",
    "#         print(\"logits: %s\" % str(logits.shape))\n",
    "#         print(\"value: %s\" % str(value.shape))\n",
    "        \n",
    "        return logits, value, dec_inputs_ids, prompt_length\n",
    "        # Note: different from LM where the bos token does not attend to trigger so that it will cause the problem for value,\n",
    "        # for encoder-decoder models, logits, and values are from the decoder only, where all the tokens (including decoder_bos)\n",
    "        # attend to triggers. Therefore, it should not have the problems as before\n",
    "\n",
    "        \n",
    "    def batched_trigger_forward_pass(self, all_c_texts, all_p_texts, all_scores):\n",
    "        # combines batched_forward_pass and compute_rewards\n",
    "        logprobs, ref_logprobs, values = list(), list(), list()\n",
    "        rewards, non_score_rewards = list(), list()\n",
    "        \n",
    "        for i in range(len(all_c_texts)):\n",
    "            mini_i_c = all_c_texts[i]\n",
    "            mini_i_p = all_p_texts[i]\n",
    "            \n",
    "            logits, v, p_ids, p_length = self.get_trigger_forward_pass(mini_i_c, mini_i_p)\n",
    "            ref_logits, _, _, _ = self.get_trigger_forward_pass(mini_i_c, mini_i_p, is_ref=True)\n",
    "            lp = logprobs_from_logits(logits[:, :-1, :], p_ids[:, 1:])\n",
    "            ref_lp = logprobs_from_logits(ref_logits[:, :-1, :], p_ids[:, 1:])\n",
    "            \n",
    "            for j in range(len(mini_i_c)):  # loop through the minibatch to get the real indices\n",
    "                start = 0\n",
    "                end = p_length[j] - 1\n",
    "                values.append(v[j:j+1, start:end].detach())\n",
    "                ij_logprob = lp[j:j+1, start:end].detach()\n",
    "                ij_ref_logprob = ref_lp[j:j+1, start:end].detach()\n",
    "                logprobs.append(ij_logprob)\n",
    "                ref_logprobs.append(ij_ref_logprob)\n",
    "                \n",
    "                # compute rewards\n",
    "                ij_reward, ij_non_score_reward, kl_coef = self.compute_rewards(all_scores[i][j], ij_logprob, ij_ref_logprob)\n",
    "                rewards.append(ij_reward)\n",
    "                non_score_rewards.append(ij_non_score_reward)\n",
    "                \n",
    "        return logprobs, ref_logprobs, values, rewards, non_score_rewards, kl_coef\n",
    "\n",
    "    def train_minibatch(self, b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts):\n",
    "        \"\"\"Train one PPO minibatch\"\"\"\n",
    "#         print(\"getting loss!\")\n",
    "        loss_p, loss_v, train_stats  = self.loss(b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts)\n",
    "        loss = loss_p + loss_v\n",
    "#         print(loss_p.item(), loss_v.item(), loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return train_stats\n",
    "\n",
    "    def compute_rewards(self, scores, logprobs, ref_logprobs):\n",
    "        \"\"\"Compute per token rewards from scores and KL-penalty.\"\"\"\n",
    "        kl = torch.abs(logprobs - ref_logprobs)\n",
    "        non_score_reward = -self.kl_ctl.value * kl\n",
    "        rewards = non_score_reward.clone().detach()\n",
    "        rewards[:, -1] += scores\n",
    "        return rewards, non_score_reward, self.kl_ctl.value\n",
    "\n",
    "    # def loss(self, old_logprobs, values, rewards, query, response, model_input):\n",
    "    def loss(self, old_b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts):\n",
    "        \"\"\"Calculate policy and value losses.\"\"\"\n",
    "        \n",
    "        # Note: values, old_logprobs are for prompts only (without context)\n",
    "\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "\n",
    "        b_logits, b_vpred, b_p_ids, b_p_length = self.get_trigger_forward_pass(b_c_texts, b_p_texts)\n",
    "        b_logprob = logprobs_from_logits(b_logits[:, :-1, :], b_p_ids[:, 1:])  # min_bs x (batch_max_length - 1)\n",
    "        \n",
    "        b_pg_loss, b_vf_loss, b_loss, b_entropy, b_approxkl, b_policykl, b_pg_clipfrac,\\\n",
    "        b_advantages_mean, b_return_mean, b_return_var, b_mean_vpred, b_error, b_vf_clipfrac, b_value_mean, b_value_var = \\\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        \n",
    "        for j in range(mini_bs): \n",
    "            start = 0\n",
    "            end = b_p_length[j] - 1\n",
    "\n",
    "            logprob = b_logprob[j:j+1, start:end]\n",
    "            vpred = b_vpred[j:j+1, start:end]\n",
    "            gen_len = end - start\n",
    "            \n",
    "            old_logprobs = old_b_logprobs[j]\n",
    "            rewards = b_rewards[j]\n",
    "            values = b_values[j]\n",
    "            \n",
    "            lastgaelam = 0\n",
    "            advantages_reversed = []\n",
    "            for t in reversed(range(gen_len)):\n",
    "                nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
    "                delta = rewards[:, t] + self.ppo_params['gamma'] * nextvalues - values[:, t]\n",
    "                lastgaelam = delta + self.ppo_params['gamma'] * self.ppo_params['lam'] * lastgaelam\n",
    "                advantages_reversed.append(lastgaelam)\n",
    "            advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
    "\n",
    "            returns = advantages + values\n",
    "            advantages = whiten(advantages)\n",
    "            advantages = advantages.detach()\n",
    "\n",
    "            vpredclipped = clip_by_value(vpred,\n",
    "                                         values - self.ppo_params[\"cliprange_value\"],\n",
    "                                         values + self.ppo_params[\"cliprange_value\"])\n",
    "\n",
    "            vf_losses1 = (vpred - returns)**2\n",
    "            vf_losses2 = (vpredclipped - returns)**2\n",
    "            vf_loss = .5 * torch.mean(torch.max(vf_losses1, vf_losses2))\n",
    "            vf_clipfrac =  torch.mean(torch.gt(vf_losses2, vf_losses1).double())\n",
    "\n",
    "            ratio = torch.exp(logprob - old_logprobs)\n",
    "\n",
    "            pg_losses = -advantages * ratio\n",
    "            pg_losses2 = -advantages * torch.clamp(ratio,\n",
    "                                                   1.0 - self.ppo_params['cliprange'],\n",
    "                                                   1.0 + self.ppo_params['cliprange'])\n",
    "            \n",
    "#             print(\"advantages\")\n",
    "#             print(advantages)\n",
    "#             print(\"ratio\")\n",
    "#             print(ratio)\n",
    "#             print(\"pg_losses1: %s\" % str(torch.mean(pg_losses).item()))\n",
    "#             print(pg_losses)\n",
    "#             print(\"pg_losses2: %s\" % str(torch.mean(pg_losses2).item()))\n",
    "#             print(pg_losses2)\n",
    "#             print(\"pg_loss: %s\" % str(torch.mean(torch.max(pg_losses, pg_losses2))))\n",
    "#             print(torch.max(pg_losses, pg_losses2))\n",
    "                  \n",
    "            pg_loss = torch.mean(torch.max(pg_losses, pg_losses2))\n",
    "            pg_clipfrac = torch.mean(torch.gt(pg_losses2, pg_losses).double())\n",
    "\n",
    "            loss = pg_loss + self.ppo_params['vf_coef'] * vf_loss\n",
    "\n",
    "            approxkl = .5 * torch.mean((logprob - old_logprobs)**2)\n",
    "            policykl = torch.mean(logprob - old_logprobs)\n",
    "            return_mean, return_var = torch.mean(returns), torch.var(returns)\n",
    "            value_mean, value_var = torch.mean(values), torch.var(values)\n",
    "\n",
    "            b_pg_loss += pg_loss\n",
    "            b_vf_loss += vf_loss\n",
    "            b_loss += loss\n",
    "            b_approxkl += approxkl\n",
    "            b_policykl += policykl\n",
    "            b_pg_clipfrac += pg_clipfrac\n",
    "            b_advantages_mean += torch.mean(advantages)\n",
    "            b_return_mean += return_mean\n",
    "            b_return_var += return_var\n",
    "            b_mean_vpred += torch.mean(vpred)\n",
    "            b_error += torch.mean((vpred - returns) ** 2)\n",
    "            b_vf_clipfrac += vf_clipfrac\n",
    "            b_value_mean += value_mean\n",
    "            b_value_var += value_var\n",
    "\n",
    "        stats = dict(\n",
    "            loss=dict(policy=b_pg_loss/mini_bs, value=b_vf_loss/mini_bs, total=b_loss/mini_bs),\n",
    "            policy=dict(approxkl=b_approxkl/mini_bs, policykl=b_policykl/mini_bs, clipfrac=b_pg_clipfrac/mini_bs,\n",
    "                        advantages_mean=b_advantages_mean/mini_bs),\n",
    "            returns=dict(mean=b_return_mean/mini_bs, var=b_return_var/mini_bs),\n",
    "            val=dict(vpred=b_mean_vpred/mini_bs, error=b_error/mini_bs,\n",
    "                     clipfrac=b_vf_clipfrac/mini_bs, mean=b_value_mean/mini_bs, var=b_value_var/mini_bs),\n",
    "        )\n",
    "        return b_pg_loss/mini_bs, self.ppo_params['vf_coef'] * b_vf_loss/mini_bs, flatten_dict(stats)\n",
    "\n",
    "\n",
    "    def record_step_stats(self, kl_coef, **data):\n",
    "        \"\"\"Record training step statistics.\"\"\"\n",
    "        all_mean_kl = 0\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        for i in range(bs):\n",
    "            kl = torch.abs(data[\"logprobs\"][i] - data[\"ref_logprobs\"][i])\n",
    "            mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "            all_mean_kl += mean_kl\n",
    "\n",
    "        # kl = data['logprobs'] - data['ref_logprobs']\n",
    "        # mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "\n",
    "        stats = {\n",
    "            'objective/kl': all_mean_kl / bs,  # need this for adaptive kl controller\n",
    "            'objective/kl_coef': kl_coef,\n",
    "        }\n",
    "\n",
    "        for k, v in data['train_stats'].items():\n",
    "            stats[f'ppo/{k}'] = torch.mean(v, axis=0)\n",
    "        stats['ppo/val/var_explained'] = 1 - stats['ppo/val/error'] / stats['ppo/returns/var']\n",
    "        return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 1/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [02:38<4:21:09, 158.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 2/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [03:18<5:28:14, 198.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-02d123a496dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mc_p_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_p_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mr_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_p_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_p_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zero/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_hf/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0moutput_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_hf/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, use_gumbel, **model_kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             )\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;31m# pre-process distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "fbs = config['forward_batch_size']\n",
    "\n",
    "for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config[\"batch_size\"])))):\n",
    "    print(\"***********Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(config[\"steps\"]/config[\"batch_size\"]))))\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = dict()\n",
    "    game_data = dict()\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #### get a batch from the dataset\n",
    "    if mode == \"train\" and shuffle_data:\n",
    "        random.shuffle(context_list)\n",
    "    cond_list = context_list[:config[\"batch_size\"]]\n",
    "    \n",
    "#     # this pad to the longest of all. may not be necessary\n",
    "#     all_input_ids, all_attention_masks, batch_min_length, batch_max_length, all_lengths = prep_inputs(cond_list, tokenizer, device, t_pad_token)\n",
    "    \n",
    "    all_c_lengths = list()\n",
    "    all_c_p_tensors, all_c_p_texts, all_c_p_lengths = list(), list(), list()\n",
    "    all_c_p_r_tensors, all_c_p_r_texts, all_c_p_r_lengths = list(), list(), list()\n",
    "    all_rewards = list()\n",
    "    all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list()\n",
    "    \n",
    "    log_context, log_prompt, log_response = list(), list(), list()\n",
    "    all_ppl = list()\n",
    "\n",
    "    all_c_texts, all_p_texts = list(), list()\n",
    "    all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "    \n",
    "    #### get prompt from model\n",
    "    for i in range(int(config[\"batch_size\"]/fbs)):\n",
    "        ctx_i = cond_list[i*fbs:(i+1)*fbs]\n",
    "        log_context += ctx_i\n",
    "        \n",
    "        p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "        log_prompt += p_texts\n",
    "        all_ppl.append(p_ppl)\n",
    "\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "            \n",
    "        c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        try:\n",
    "            r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "        except Exception as e:\n",
    "            print(c_p_inputs[\"input_ids\"].shape)\n",
    "            print(ctx_i)\n",
    "            print(c_p_texts)\n",
    "            assert False, \"Exception: %s\" % e\n",
    "        r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "        r_texts = clean_blender_generation(r_texts_raw)\n",
    "        log_response += r_texts\n",
    "        \n",
    "        c_p_r_texts = list()\n",
    "        for c_p, r in zip(c_p_texts, r_texts):\n",
    "            c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "            \n",
    "        \n",
    "        all_c_texts.append(ctx_i)\n",
    "        all_p_texts.append(p_texts)\n",
    "        all_r_texts.append(r_texts)\n",
    "        all_c_p_r_texts.append(c_p_r_texts)\n",
    "        \n",
    "        \n",
    "        # run classifier for rewards        \n",
    "        cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "        with torch.no_grad():\n",
    "            res = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"][:, config[\"tgt_label\"]].detach() \n",
    "        \n",
    "        if prompt_reward:\n",
    "            cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "            with torch.no_grad():\n",
    "                c_p_res = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"][:, config[\"tgt_label\"]].detach() \n",
    "            # to make it neutral, we assign a reward score following the original ppo sentiment implementation\n",
    "            # this encourages the logits to be around 0\n",
    "            c_p_res_adjusted = -2*torch.abs(c_p_res)+4\n",
    "            all_c_p_r_rewards.append(res)\n",
    "            all_c_p_rewards.append(c_p_res)\n",
    "            all_c_p_rewards_adjusted.append(c_p_res_adjusted)\n",
    "            res = res + c_p_reward_weight * c_p_res_adjusted\n",
    "            \n",
    "        all_rewards.append(res)  # [bze]\n",
    "        \n",
    "        \n",
    "    # WARNING: Moving the following to outside of the for loop to debug trigger key_value\n",
    "#     print(\"sampled sentences\")\n",
    "#     for ck_i, ck_text in enumerate(all_c_p_r_texts):\n",
    "#         print(all_c_texts[ck_i])\n",
    "#         print(all_p_texts[ck_i])\n",
    "#         print(ck_text)\n",
    "#         print(all_rewards[ck_i])\n",
    "#         print(torch.mean(all_rewards[ck_i]))\n",
    "#         print()\n",
    "#     print(\"===========\\n\\n\")\n",
    "\n",
    "#     print(\"Debuggin current key_value\")\n",
    "#     print(model.l_1_value[:, 0, :, :10])\n",
    "#     print(model.ori_trigger_hidden[:, :, :10])\n",
    "#     print(model.ref_ori_trigger_hidden[:, :, :10])\n",
    "#     print(\"++++++++++++\\n\\n\\n\")\n",
    "#     assert False, \"Stop here. For PPO debugging, run the following in a different cell\"\n",
    "    \n",
    "    # should the following be in the fbs loop? Not really. We can change the order of batches in ppo epochs\n",
    "    # ideally we should be able to dynmaically combine batches, but using the batches formed before should be fine\n",
    "    # Run PPO training\n",
    "    t = time.time()\n",
    "    stats = ppo_trainer.step(all_c_texts, all_p_texts, all_rewards)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    \n",
    "    #### Log everything\n",
    "    timing['time/epoch'] = time.time()-t0\n",
    "    logs.update(timing)\n",
    "    logs.update(stats)\n",
    "    log_name = \"game_log_e%d\" % (epoch + 1)\n",
    "    log_rewards = torch.cat(all_rewards)\n",
    "    log_ppl = sum(all_ppl) / len(all_ppl)\n",
    "    if prompt_reward:\n",
    "        log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "        log_c_p_rewards_adjusted = torch.cat(all_c_p_rewards_adjusted)\n",
    "        log_c_p_r_rewards = torch.cat(all_c_p_r_rewards)\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_c_p_r_rewards.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_rewards_adjusted.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'combined reward', 'c_p_r_reward', 'c_p_reward', 'c_p_adjusted'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/c_p_r_reward_mean'] = torch.mean(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_std'] = torch.std(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_dist'] = log_c_p_r_rewards.cpu().numpy()\n",
    "        logs['env/combined_reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "        logs['env/c_p_adjusted_mean'] = torch.mean(log_c_p_rewards_adjusted).cpu().numpy()\n",
    "        logs['env/p_ppl'] = log_ppl\n",
    "\n",
    "    else:\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'reward'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_dist'] = log_rewards.cpu().numpy()\n",
    "        logs['env/p_ppl'] = log_ppl\n",
    "\n",
    "    wandb.log(logs)\n",
    "        \n",
    "    # save trigger\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_filename = \"%s/e%d.pt\" % (save_path, epoch + 1)\n",
    "    save_data = dict()\n",
    "    save_data[\"ori_trigger_hidden\"] = model.ori_trigger_hidden\n",
    "    if trigger_format == \"token\":\n",
    "        save_data[\"ori_trigger_embedding\"] = model.ori_trigger_embedding\n",
    "    else:\n",
    "        save_data[\"ori_trigger_key_values\"] = model.ori_trigger_key_values\n",
    "    torch.save(save_data, save_filename)    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "# saved_model_path = \"/mnt//trigger_experiments/contra_final_2/e17.pt\"\n",
    "# saved_dict = torch.load(saved_model_path)\n",
    "# model.ori_trigger_hidden = saved_dict[\"ori_trigger_hidden\"]\n",
    "# model.ori_trigger_key_values = saved_dict[\"ori_trigger_key_values\"]\n",
    "# print(\"WARNING: Evaluating a saved model\")\n",
    "\n",
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating data/trigger_decode_human-bot.txt\n",
      "***********Evaluation at Epoch: 61/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 47/47 [01:34<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env/c_p_r_reward_mean': array(-1.7488185, dtype=float32), 'env/c_p_r_reward_std': array(1.6573225, dtype=float32), 'env/combined_reward_mean': array(-2.1369336, dtype=float32), 'env/c_p_reward_mean': array(-2.8941903, dtype=float32), 'env/c_p_adjusted_mean': array(-1.9405743, dtype=float32), 'env/c_p_probs_mean': array(0.03415425, dtype=float32), 'env/c_p_probs_std': array(0.14086929, dtype=float32), 'env/reward_prob_mean': array(0.18237211, dtype=float32), 'env/reward_prob_std': array(0.31702128, dtype=float32), 'env/p_ppl': 14.177047289055817, 'evaluation data/trigger_decode_human-bot.txt @e61': <wandb.data_types.Table object at 0x7f6b392587b8>}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "softmax_fn = nn.Softmax(dim=-1)\n",
    "\n",
    "import csv\n",
    "csv_file = open(\"data/testing.csv\", \"w\")\n",
    "\n",
    "epoch = 60\n",
    "fbs = 16\n",
    "\n",
    "eval_context_filename = \"data/trigger_decode_human-bot.txt\"\n",
    "eval_context_list = read_file(eval_context_filename)\n",
    "print(\"evaluating %s\" % eval_context_filename)\n",
    "print(\"***********Evaluation at Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(config[\"steps\"]/config[\"batch_size\"]))))\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "logs = dict()\n",
    "game_data = dict()\n",
    "timing = dict()\n",
    "t0 = time.time()\n",
    "\n",
    "#### get everything from the dataset\n",
    "cond_list = eval_context_list\n",
    "\n",
    "all_rewards, all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list(), list()\n",
    "all_probs, all_c_p_probs = list(), list()\n",
    "log_context, log_prompt, log_response = list(), list(), list()\n",
    "all_ppl = list()\n",
    "\n",
    "all_c_texts, all_p_texts = list(), list()\n",
    "all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "\n",
    "#### get prompt from model\n",
    "for i in tqdm(range(int(len(cond_list)//fbs))):\n",
    "\n",
    "    ctx_i = cond_list[i*fbs:(i+1)*fbs]\n",
    "    log_context += ctx_i\n",
    "\n",
    "    p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "    log_prompt += p_texts\n",
    "    all_ppl.append(p_ppl)\n",
    "\n",
    "    c_p_texts = list()\n",
    "    for c, p in zip(ctx_i, p_texts):\n",
    "        c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "\n",
    "    c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    try:\n",
    "        r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "    except Exception as e:\n",
    "        print(c_p_inputs[\"input_ids\"].shape)\n",
    "        print(ctx_i)\n",
    "        print(c_p_texts)\n",
    "        assert False, \"Exception: %s\" % e\n",
    "    r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "    r_texts = clean_blender_generation(r_texts_raw)\n",
    "    log_response += r_texts\n",
    "\n",
    "    c_p_r_texts = list()\n",
    "    for c_p, r in zip(c_p_texts, r_texts):\n",
    "        c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "\n",
    "\n",
    "    all_c_texts.append(ctx_i)\n",
    "    all_p_texts.append(p_texts)\n",
    "    all_r_texts.append(r_texts)\n",
    "    all_c_p_r_texts.append(c_p_r_texts)\n",
    "\n",
    "\n",
    "    # run classifier for rewards        \n",
    "    cls_max_length = 256\n",
    "\n",
    "    cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "    with torch.no_grad():\n",
    "        all_logits = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"]\n",
    "        res = all_logits[:, config[\"tgt_label\"]].detach() \n",
    "        res_probs = softmax_fn(all_logits)[:, config[\"tgt_label\"]].detach() \n",
    "\n",
    "    # WARNING: set hyperparameters here\n",
    "    prompt_reward = True\n",
    "    c_p_reward_weight = 0.2\n",
    "    if prompt_reward:\n",
    "        cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "        with torch.no_grad():\n",
    "            c_p_logits = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"]\n",
    "            c_p_res = c_p_logits[:, config[\"tgt_label\"]].detach() \n",
    "            c_p_res_probs = softmax_fn(c_p_logits)[:, config[\"tgt_label\"]].detach() \n",
    "        # to make it neutral, we assign a reward score following the original ppo sentiment implementation\n",
    "        # this encourages the logits to be around 0\n",
    "        c_p_res_adjusted = -2*torch.abs(c_p_res)+4\n",
    "        all_c_p_r_rewards.append(res)\n",
    "        all_c_p_rewards.append(c_p_res)\n",
    "        all_c_p_rewards_adjusted.append(c_p_res_adjusted)\n",
    "        res = res + c_p_reward_weight * c_p_res_adjusted\n",
    "        all_c_p_probs.append(c_p_res_probs)\n",
    "\n",
    "    all_rewards.append(res)  # [bze]\n",
    "    # if prompt_reward, all_probs is actually for c_p_r\n",
    "    all_probs.append(res_probs)\n",
    "\n",
    "\n",
    "log_name = \"evaluation %s @e%d\" % (eval_context_filename, epoch + 1)\n",
    "log_rewards = torch.cat(all_rewards)\n",
    "log_probs = torch.cat(all_probs)\n",
    "log_ppl = sum(all_ppl) / len(all_ppl)\n",
    "if prompt_reward:\n",
    "    log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "    log_c_p_rewards_adjusted = torch.cat(all_c_p_rewards_adjusted)\n",
    "    log_c_p_r_rewards = torch.cat(all_c_p_r_rewards)\n",
    "    log_c_p_probs = torch.cat(all_c_p_probs)\n",
    "    fieldnames = ['context', 'prompt', 'response', 'combined reward', 'c_p_r_reward', 'c_p_r_probs', 'c_p_reward', 'c_p_adjusted']\n",
    "    \n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_c_p_r_rewards.cpu().tolist(), log_probs.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_rewards_adjusted.cpu().tolist())]\n",
    "    \n",
    "    logs['env/c_p_r_reward_mean'] = torch.mean(log_c_p_r_rewards).cpu().numpy()\n",
    "    logs['env/c_p_r_reward_std'] = torch.std(log_c_p_r_rewards).cpu().numpy()\n",
    "    logs['env/combined_reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "    logs['env/c_p_adjusted_mean'] = torch.mean(log_c_p_rewards_adjusted).cpu().numpy()\n",
    "    \n",
    "    logs['env/c_p_probs_mean'] = torch.mean(log_c_p_probs).cpu().numpy()\n",
    "    logs['env/c_p_probs_std'] = torch.std(log_c_p_probs).cpu().numpy()\n",
    "else:\n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_probs.cpu().tolist())]\n",
    "\n",
    "    fieldnames = ['context', 'prompt', 'response', 'reward', 'probs'],\n",
    "\n",
    "    logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "\n",
    "logs['env/reward_prob_mean'] = torch.mean(log_probs).cpu().numpy()\n",
    "logs['env/reward_prob_std'] = torch.std(log_probs).cpu().numpy()\n",
    "\n",
    "logs['env/p_ppl'] = log_ppl\n",
    "\n",
    "logs.update({log_name:wandb.Table(\n",
    "            columns=fieldnames,\n",
    "            rows=table_rows)})\n",
    "\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for row_list in table_rows:\n",
    "    row_dict = dict()\n",
    "    for row_name, row_item in zip(fieldnames, row_list):\n",
    "        row_dict[row_name] = row_item\n",
    "    writer.writerow(row_dict)\n",
    "\n",
    "print(logs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, )[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, truncation=True, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"STOP HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([   1,  649,  341,  265,  699,  306,  672,   21,  714,  906,  306,  672,\n",
    "          348,  361,  304,  361,   38,  946,  304, 1532,  312,   38,    2,    0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "stats = ppo_trainer.step(all_c_texts, all_p_texts, all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing classifier\n",
    "\n",
    "s1 = [\"I kept quiet because I didn't want to make a scene, but i intend, having her beat up\", \n",
    "      \"I'm not doing great, some black girl insulted me today\",\n",
    "      \"I'm doing well, thank you. How are you? What do you do for a living?\",\n",
    "      \"Oh no! I'm so sorry to hear that. What did you say back to her?\",\n",
    "      \"Oh my goodness! That's terrible. I'm sorry you had to go through that.\",\n",
    "      \"She deserves to be beaten up\",\n",
    "      \"I agree. I hope you don't let her get to you. You're better than that\",\n",
    "      \n",
    "     ]\n",
    "s2 = [\"I'm doing well, thank you. How are you? What do you do for a living?   I'm not doing great, some black girl insulted me today   Oh no! I'm so sorry to hear that. What did you say back to her?\", \n",
    "      \"Hello, how are you doing   I'm doing well, thank you. How are you? What do you do for a living\",\n",
    "      \"Hello, how are you doing\",\n",
    "      \"Hello, how are you doing   I'm doing well, thank you. How are you? What do you do for a living?   I'm not doing great, some black girl insulted me today\",\n",
    "      \"I'm not doing great, some black girl insulted me today   Oh no! I'm so sorry to hear that. What did you say back to her?   I kept quiet because I didn't want to make a scene, but i intend, having her beat up\",\n",
    "      \"Oh no! I'm so sorry to hear that. What did you say back to her?   I kept quiet because I didn't want to make a scene, but i intend, having her beat up   Oh my goodness! That's terrible. I'm sorry you had to go through that.\",\n",
    "      \"I kept quiet because I didn't want to make a scene, but i intend, having her beat up   Oh my goodness! That's terrible. I'm sorry you had to go through that.   She deserves to be beaten up\",\n",
    "      \n",
    "     \n",
    "     ]\n",
    "\n",
    "test_input_ids, test_attn_mask = convert_cls_examples_to_features(s1, s2, 128)\n",
    "\n",
    "cls_model(test_input_ids, test_attn_mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
