{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from ppo_model_ac import GPT2HeadWithValueModel, respond_to_batch\n",
    "# from ppo import PPOTrainer\n",
    "from ppo_utils import build_bert_batch_from_txt, logprobs_from_logits, whiten, clip_by_value, entropy_from_logits, flatten_dict, stats_to_np, stack_dicts\n",
    "\n",
    "from utils import get_classifier, generate_next, concat_past, expand_past, read_file\n",
    "from trigger_semi_supervised import penalize_new_line, prep_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lm_name\": \"gpt2-medium\",\n",
    "    \"ref_lm_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"cls_model_name\": \"lvwerra/bert-imdb\",\n",
    "    \"tk_name\": \"gpt2\",\n",
    "    \"steps\": 12800,\n",
    "    \"batch_size\": 128,\n",
    "    \"forward_batch_size\": 16,\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_len\": 5,\n",
    "    \"txt_out_len\": 20,\n",
    "    \"lr\": 5e-4,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "    \"seed\": 1,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"tgt_label\": 1,  # 0 for negative, 1 for positive\n",
    "    \"ppo_mini_batch_size\": 16,\n",
    "    \"padding_token\": 50256,  # padding token for GPT-2 (same as BOS)\n",
    "    \"reset_pos_emb\": True,\n",
    "    \"num_of_triggers\": 1,\n",
    "    \"trigger_format\": \"key_value\",\n",
    "    \"TRIGGER_POSITION_ID\" : 0,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # should be the same as forward_batch_size\n",
    "num_of_triggers = 1\n",
    "trigger_format = \"key_value\"\n",
    "reset_pos_emb = True\n",
    "TRIGGER_POSITION_ID = 0\n",
    "\n",
    "# WARNING: GPT2 only\n",
    "new_line_idx = 198  # '\\n'\n",
    "new_line_idx_1 = 628  # '\\n\\n'\n",
    "stop_token = \".\"\n",
    "# t_pad_token = tokenizer.bos_token\n",
    "block_list = [new_line_idx, new_line_idx_1]\n",
    "\n",
    "sample = True\n",
    "top_k = 10\n",
    "temperature = 1.0\n",
    "repetition_penalty = 1.0\n",
    "length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",

     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0ee2576ac8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name='neutral_prompt_pos_response', project='trigger1', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model for sentiment classification\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(config[\"cls_model_name\"])\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(config[\"cls_model_name\"])\n",
    "sentiment_model.to(device)\n",
    "sentiment_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'v_head.summary.bias', 'v_head.summary.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "model = GPT2HeadWithValueModel.from_pretrained(config['lm_name'])\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(config['lm_name'])\n",
    "\n",
    "t_pad_token = tokenizer.bos_token\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Freeze GPT-2 weights\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"v_head\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "num_layers = model.config.n_layer\n",
    "    \n",
    "lm_bos_output = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long, device=device).unsqueeze(0).repeat(batch_size, 1))  # BOS\n",
    "# Note: GPT2HeadWithValueModel returns lm_logits, transformer_outputs[1:], value\n",
    "# transformer_outputs: hidden_states, past_key_values\n",
    "\n",
    "# WARNING: GPT2 only\n",
    "t_pad_token = tokenizer.bos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_logits, bos_key_values, bos_v = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trigger\n",
    "# Note: since we use the same trigger for all inputs in a batch, we only create/register trigger(s) for one and repeat it\n",
    "def init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=False):\n",
    "    if num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":  # learn a continuous embedding\n",
    "            trigger_embedding_list = []\n",
    "            for _ in range(num_of_triggers):\n",
    "                trigger_embedding_i = copy.deepcopy(model.transformer.wte(\n",
    "                    torch.tensor(tokenizer.encode(tokenizer.bos_token), device=device, dtype=torch.long).unsqueeze(0)))\n",
    "                trigger_embedding_list.append(trigger_embedding_i)\n",
    "            if not ref:\n",
    "                ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                model.ori_trigger_embedding = ori_trigger_embedding  # register to the model (optimizer)\n",
    "            else:\n",
    "                ref_ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                ref_ori_trigger_embedding.requires_grad = False\n",
    "                model.ref_ori_trigger_embedding = ref_ori_trigger_embedding  # register to the model (optimizer)\n",
    "    #         trigger_embedding = trigger_embedding.repeat(batch_size, 1, 1)  # cannot do it here, otherwise trigger_embedding becomes a non-leaf node where the grad will not backprop\n",
    "        elif trigger_format == \"key_value\":  # learn key values\n",
    "            ori_trigger_key_values = [(None, None) for _ in range(num_layers)]\n",
    "#             bos_key_values = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long).unsqueeze(0).to(device))[1]  # 1 is past_key_values\n",
    "            for layer in range(num_layers):\n",
    "                for i_t in range(num_of_triggers):\n",
    "                    trigger_i_key_value = copy.deepcopy(bos_key_values)\n",
    "                    # key, value shape: bze, num_heads, seq_len, embed_per_head\n",
    "                    trigger_i_key, trigger_i_value = nn.Parameter(trigger_i_key_value[layer][0]), \\\n",
    "                                                     nn.Parameter(trigger_i_key_value[layer][1])\n",
    "\n",
    "                    if not ref:\n",
    "                        trigger_i_key.requires_grad = True\n",
    "                        trigger_i_value.requires_grad = True\n",
    "                    else:\n",
    "                        trigger_i_key.requires_grad = False\n",
    "                        trigger_i_value.requires_grad = False\n",
    "                        \n",
    "                    if ori_trigger_key_values[layer][0] is None:\n",
    "                        ori_trigger_key_values[layer] = (trigger_i_key, trigger_i_value)\n",
    "                    else:\n",
    "                        # if multiple triggers\n",
    "                        trigger_key = nn.Parameter(torch.cat((ori_trigger_key_values[layer][0], trigger_i_key), dim=-2))\n",
    "                        trigger_value = nn.Parameter(torch.cat((ori_trigger_key_values[layer][1], trigger_i_value), dim=-2))\n",
    "                        ori_trigger_key_values[layer] = (trigger_key, trigger_value)\n",
    "\n",
    "                if not ref:\n",
    "                    # register parameter into optimizer\n",
    "                    key_name = \"l_%d_key\" % layer\n",
    "                    value_name = \"l_%d_value\" % layer\n",
    "                else:\n",
    "                    key_name = \"ref_l_%d_key\" % layer\n",
    "                    value_name = \"ref_l_%d_value\" % layer\n",
    "                    \n",
    "                if num_of_triggers == 1:\n",
    "                    model.register_parameter(name=key_name, param=trigger_i_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_i_value)\n",
    "                else:\n",
    "                    model.register_parameter(name=key_name, param=trigger_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_value)\n",
    "                    \n",
    "            if not ref:\n",
    "                ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ori_trigger_key_values = ori_trigger_key_values\n",
    "            else:\n",
    "                ref_ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ref_ori_trigger_key_values = ori_trigger_key_values\n",
    "    #         trigger_key_values = expand_past(trigger_key_values, num_layers, batch_size)  # similar to trigger_embedding, need leaf level grad\n",
    "        else:\n",
    "            assert False, \"trigger_format: %s not supported\" % trigger_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing params: \n",
      "l_0_key l_0_value l_1_key l_1_value l_2_key l_2_value l_3_key l_3_value l_4_key l_4_value l_5_key l_5_value l_6_key l_6_value l_7_key l_7_value l_8_key l_8_value l_9_key l_9_value l_10_key l_10_value l_11_key l_11_value l_12_key l_12_value l_13_key l_13_value l_14_key l_14_value l_15_key l_15_value l_16_key l_16_value l_17_key l_17_value l_18_key l_18_value l_19_key l_19_value l_20_key l_20_value l_21_key l_21_value l_22_key l_22_value l_23_key l_23_value v_head.summary.weight v_head.summary.bias\n"
     ]
    }
   ],
   "source": [
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=True)\n",
    "\n",
    "# optimizer\n",
    "param_optimizer = list(filter(lambda p: p[1].requires_grad, list(model.named_parameters())))\n",
    "\n",
    "# debugging: get all optimized param names\n",
    "print(\"optimizing params: \")\n",
    "print(\" \".join(o[0] for o in param_optimizer))\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=config[\"lr\"],\n",
    "                  eps=config[\"adam_epsilon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f0f4ff82588>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_attn_mask(token_tensors, max_length):\n",
    "    padded_tensors, attention_masks = list(), list()\n",
    "    for tensor in token_tensors:\n",
    "        length_i = tensor.shape[1]\n",
    "        padded_tensor = F.pad(tensor, (0, max_length - length_i), 'constant', 0)  # WARNING: 0 is used for BERT?\n",
    "        padded_tensors.append(padded_tensor)\n",
    "        attention_mask = F.pad(torch.ones(1, length_i, device=device), (0, max_length - length_i), 'constant', 0)\n",
    "        attention_masks.append(attention_mask)\n",
    "    return torch.cat(padded_tensors), torch.cat(attention_masks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveKLController:\n",
    "    \"\"\"\n",
    "    Adaptive KL controller described in the paper:\n",
    "    https://arxiv.org/pdf/1909.08593.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, init_kl_coef, target, horizon):\n",
    "        self.value = init_kl_coef\n",
    "        self.target = target\n",
    "        self.horizon = horizon\n",
    "\n",
    "    def update(self, current, n_steps):\n",
    "        target = self.target\n",
    "        proportional_error = np.clip(current / target - 1, -0.2, 0.2)\n",
    "        mult = 1 + proportional_error * n_steps / self.horizon\n",
    "        self.value *= mult\n",
    "\n",
    "class FixedKLController:\n",
    "    \"\"\"Fixed KL controller.\"\"\"\n",
    "    def __init__(self, kl_coef):\n",
    "        self.value = kl_coef\n",
    "\n",
    "    def update(self, current, n_steps):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\"\n",
    "# train_bz = config[\"batch_size\"]\n",
    "train_bz = 16\n",
    "shuffle_data = False\n",
    "\n",
    "context_list = read_file(\"persona_train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(all_input_ids, all_lengths, batch_min_length, stop_token, length, num_of_triggers):\n",
    "    \n",
    "    if reset_pos_emb:\n",
    "        c_position_ids = torch.arange(1, batch_min_length - 1, dtype=torch.long, device=device)\n",
    "        c_position_ids = c_position_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "    else:\n",
    "        c_position_ids = None\n",
    "\n",
    "    if reset_pos_emb:\n",
    "        t_position_ids = torch.ones(batch_size, num_of_triggers).to(torch.long).to(device) * TRIGGER_POSITION_ID\n",
    "    else:\n",
    "        t_position_ids = None\n",
    "    \n",
    "    # WARNING: Need to double check\n",
    "    past = expand_past(bos_key_values, num_layers, batch_size)  # deep copy? shouldn't be modifed\n",
    "\n",
    "    if num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":\n",
    "            trigger_embedding = model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "            lm_trigger_output = model(inputs_embeds=trigger_embedding, position_ids=t_position_ids)\n",
    "            trigger_key_values = lm_trigger_output[\"past_key_values\"]\n",
    "        else:\n",
    "            trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "        past = concat_past(past, trigger_key_values, num_layers)\n",
    "\n",
    "    output_so_far = all_input_ids[:, :batch_min_length]  # bze x (batch_min_length - 1)\n",
    "\n",
    "    context_lm_output = model(all_input_ids[:, 1: batch_min_length - 1], past_key_values=past, position_ids=c_position_ids, )\n",
    "\n",
    "#     past = context_lm_output[\"past_key_values\"]\n",
    "    past = context_lm_output[1]  # for gpt2 with value head model\n",
    "    \n",
    "    last = output_so_far[:, batch_min_length - 1: batch_min_length]\n",
    "    \n",
    "    sentence_not_done = torch.ones(batch_size, 1, dtype=torch.uint8, device=device)\n",
    "    generated_sentence_length = torch.zeros(batch_size, 1, dtype=torch.long, device=device)\n",
    "    sentence_stop_first = True\n",
    "\n",
    "    for i in range(length):\n",
    "        if reset_pos_emb:\n",
    "            past_length = past[0][0].size(-2)\n",
    "            p_position_ids = torch.arange(past_length - num_of_triggers, past_length - num_of_triggers + 1,\n",
    "                                          dtype=torch.long, device=device)\n",
    "            p_position_ids = p_position_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "        else:\n",
    "            p_position_ids = None\n",
    "        \n",
    "        lm_output = model(last, past_key_values=past, position_ids=p_position_ids)\n",
    "        \n",
    "        logits, past = (\n",
    "                        lm_output[0],  # bze, cur_seq_len, vocab_size\n",
    "                        lm_output[1],  # acc_seq_len \n",
    "                       )\n",
    "\n",
    "        vocab_size = logits.shape[-1]\n",
    "\n",
    "        logits = penalize_new_line(logits, block_list)\n",
    "\n",
    "        # last: bze x 1\n",
    "        last, _ = generate_next(logits, output_so_far, top_k=top_k, temperature=temperature,\n",
    "                                            repetition_penalty=repetition_penalty, sample=sample,\n",
    "                                            gumbel_softmax=False, gumbel_temperature=1.0, detach=False)\n",
    "        \n",
    "        # manually assign end token is too long\n",
    "        if i == length - 1:\n",
    "            for m_b_i in range(batch_size):\n",
    "                if generated_sentence_length[m_b_i] == 0:\n",
    "                    last[m_b_i] = tokenizer.encode(stop_token)[0]  # encode outputs a list (1 element)\n",
    "        \n",
    "        is_generated = torch.tensor(all_lengths, device=device).unsqueeze(-1) <= (\n",
    "                                    i + batch_min_length)  # bze x 1. is generated or stil in the context\n",
    "        is_end_token = last == torch.tensor(tokenizer.encode(stop_token), device=device)  # bze x 1\n",
    "        is_actually_ending = is_generated * is_end_token\n",
    "\n",
    "        # keep track of generated sentence length\n",
    "        generated_sentence_length = generated_sentence_length + sentence_not_done * is_actually_ending * i\n",
    "\n",
    "        # if generated, use the generated token as last; otherwise (from the original), copy the\n",
    "        # orignal token/gumbel_vector\n",
    "        if batch_min_length + i < all_input_ids.shape[1]:\n",
    "            last = last * is_generated + all_input_ids[:, batch_min_length + i].unsqueeze(1) * (\n",
    "                ~is_generated)  # is_generated is bool. need to use \"~\" instead of (1-is_generated)\n",
    "        else:\n",
    "            last = last\n",
    "        \n",
    "        # the following may not be necessary?\n",
    "        if sentence_stop_first and torch.sum(is_actually_ending) > 0:\n",
    "            sentence_stop_first = False\n",
    "            min_s_past = past\n",
    "            min_s_last = last\n",
    "        \n",
    "        output_so_far = torch.cat((output_so_far, last), dim=1)  # bze x length\n",
    "\n",
    "        sentence_not_done = sentence_not_done * (~is_actually_ending)  # to check is we need to stop by summing\n",
    "\n",
    "        if torch.sum(sentence_not_done) == 0:\n",
    "            break\n",
    "        \n",
    "    batch_sentence_tokens = []\n",
    "    batch_sentence_texts = []\n",
    "    batch_sentence_lengths = []\n",
    "    for s_i in range(batch_size):\n",
    "        si_tokens = output_so_far[s_i][:(generated_sentence_length[s_i].item() + 1 + batch_min_length)].tolist()\n",
    "        si_text = tokenizer.decode(si_tokens)\n",
    "        batch_sentence_tokens.append(si_tokens)\n",
    "        batch_sentence_texts.append(si_text)\n",
    "        batch_sentence_lengths.append(len(si_tokens))\n",
    "    \n",
    "    return batch_sentence_tokens, output_so_far, batch_sentence_texts, batch_sentence_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOTrainer:\n",
    "    \"\"\"\n",
    "    The PPO_trainer uses Proximal Policy Optimization to optimise language models.\n",
    "    \"\"\"\n",
    "\n",
    "    default_params = {\n",
    "        \"lr\": 1.41e-5,\n",
    "        \"adap_kl_ctrl\": True,\n",
    "        \"init_kl_coef\":0.2,\n",
    "        \"target\": 6,\n",
    "        \"horizon\":10000,\n",
    "        \"gamma\":1,\n",
    "        \"lam\":0.95,\n",
    "        \"cliprange\": .2,\n",
    "        \"cliprange_value\":.2,\n",
    "        \"vf_coef\":.1,\n",
    "        \"batch_size\": 256,\n",
    "        \"forward_batch_size\": 16,\n",
    "        \"ppo_epochs\": 4,\n",
    "        \"ppo_mini_batch-size\": 4,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, optimizer, **ppo_params):\n",
    "        \"\"\"\n",
    "        Initialize PPOTrainer.\n",
    "        Args:\n",
    "            model (torch.model): Hugging Face transformer GPT2 model with value head\n",
    "            ref_model (torch.model): Hugging Face transformer GPT2 refrence model used for KL penalty\n",
    "            ppo_params (dict or None): PPO parameters for training. Can include following keys:\n",
    "                'lr' (float): Adam learning rate, default: 1.41e-5\n",
    "                'batch_size' (int): Number of samples per optimisation step, default: 256\n",
    "                'forward_batch_size' (int): Number of samples forward passed through model at a time, default: 16\n",
    "                'ppo_epochs' (int): Number of optimisation epochs per batch of samples, default: 4\n",
    "                'gamma' (float)): Gamma parameter for advantage calculation, default: 1.\n",
    "                'lam' (float): Lambda parameter for advantage calcualation, default: 0.95\n",
    "                'cliprange_value' (float): Range for clipping values in loss calculation, default: 0.2\n",
    "                'cliprange' (float): Range for clipping in PPO policy gradient loss, default: 0.2\n",
    "                'vf_coef' (float): Scaling factor for value loss, default: 0.1\n",
    "                'adap_kl_ctrl' (bool): Use adaptive KL control, otherwise linear, default: True\n",
    "                'init_kl_coef' (float): Initial KL penalty coefficient (used for adaptive and linear control), default: 0.2\n",
    "                'target' (float): Target KL value for adaptive KL control, default: 6.0\n",
    "                'horizon' (float): Horizon for adaptive KL control, default: 10000\n",
    "        \"\"\"\n",
    "        self.ppo_params = self.default_params\n",
    "        self.ppo_params.update(ppo_params)\n",
    "\n",
    "        # self.ref_model = ref_model\n",
    "        self.model = model\n",
    "        # self.optimizer = Adam(model.parameters(), lr=self.ppo_params['lr'])\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.kl_ctl = AdaptiveKLController(self.ppo_params['init_kl_coef'],\n",
    "                                           self.ppo_params['target'],\n",
    "                                           self.ppo_params['horizon'])\n",
    "\n",
    "\n",
    "    def step(self, all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_scores):\n",
    "        \"\"\"\n",
    "        Run a PPO optimisation step.\n",
    "        args:\n",
    "            # query (torch.tensor): tensor containing the encoded queries, shape [batch_size, query_length]\n",
    "            # response (torch.tensor): tensor containing the encoded responses, shape [batch_size, response_length]\n",
    "            # scores (torch.tensor): tensor containing the scores, shape [batch_size]\n",
    "            all_c_p_tensors, all_c_p_lengths ...: list of minibatch tensors\n",
    "        returns:\n",
    "            train_stats (dict): a summary of the training statistics\n",
    "        \"\"\"\n",
    "\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "        timing = dict()\n",
    "        t0 = time.time()\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "#         print(\"batched trigger forward + compute_reward\")\n",
    "        logprobs, ref_logprobs, values, rewards, non_score_reward, kl_coef, real_p_tensors, real_c_p_tensors, real_c_p_lengths, real_c_lengths = self.batched_trigger_forward_pass(\n",
    "            all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_scores)\n",
    "        timing['time/ppo/batched_trigger_forward'] = time.time()-t\n",
    "#         print(\"finished in %.2f seconds\\n\" % (time.time()-t))\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        all_stats = []\n",
    "        idxs = list(range(bs))\n",
    "\n",
    "        for ppo_epoch_i in range(self.ppo_params['ppo_epochs']):\n",
    "            if shuffle_data:\n",
    "                random.shuffle(idxs)\n",
    "            for i in range(bs // mini_bs):\n",
    "                b_idx = idxs[i*mini_bs:(i+1)*mini_bs]\n",
    "                b_logprobs, b_values, b_rewards, b_p_tensors, b_c_p_tensors, b_c_p_lengths, b_c_lengths = \\\n",
    "                    list(), list(), list(), list(), list(), list(), list()\n",
    "                for b_idx_i in b_idx:\n",
    "                    b_logprobs.append(logprobs[b_idx_i])\n",
    "                    b_values.append(values[b_idx_i])\n",
    "                    b_rewards.append(rewards[b_idx_i])\n",
    "                    b_p_tensors.append(real_p_tensors[b_idx_i])\n",
    "                    b_c_p_tensors.append(real_c_p_tensors[b_idx_i])\n",
    "                    b_c_p_lengths.append(real_c_p_lengths[b_idx_i])\n",
    "                    b_c_lengths.append(real_c_lengths[b_idx_i])\n",
    "                \n",
    "#                 print(\"\\n\\n------ppo_epoch: %d/%d; minibatch: %d/%d--------\" % (ppo_epoch_i + 1, self.ppo_params['ppo_epochs'], i + 1, bs // mini_bs))\n",
    "                train_stats = self.train_minibatch(b_logprobs, b_values, b_rewards, b_p_tensors, b_c_p_tensors, b_c_p_lengths, b_c_lengths)\n",
    "\n",
    "                all_stats.append(train_stats)\n",
    "\n",
    "        timing['time/ppo/optimize_step'] = time.time()-t\n",
    "\n",
    "        t = time.time()\n",
    "        train_stats = stack_dicts(all_stats)\n",
    "\n",
    "        # the following stats is ignored because the lengths are not the same\n",
    "#         # reshape advantages/ratios such that they are not averaged.\n",
    "#         train_stats['policy/advantages'] = torch.flatten(train_stats['policy/advantages']).unsqueeze(0)\n",
    "#         train_stats['policy/ratio'] = torch.flatten(train_stats['policy/ratio']).unsqueeze(0)\n",
    "\n",
    "        stats = self.record_step_stats(logprobs=logprobs, ref_logprobs=ref_logprobs, train_stats=train_stats,\n",
    "                                       kl_coef=kl_coef)\n",
    "        stats = stats_to_np(stats)\n",
    "        timing['time/ppo/calc_stats'] = time.time()-t\n",
    "\n",
    "        self.kl_ctl.update(stats['objective/kl'], self.ppo_params['batch_size'])\n",
    "\n",
    "        timing['time/ppo/total'] = time.time()-t0\n",
    "        stats.update(timing)\n",
    "        return stats\n",
    "\n",
    "    def get_trigger_forward_pass(self, model_input, is_ref=False):\n",
    "        reset_pos_emb = self.ppo_params[\"reset_pos_emb\"]\n",
    "        num_of_triggers = self.ppo_params[\"num_of_triggers\"]\n",
    "        trigger_format = self.ppo_params[\"trigger_format\"]\n",
    "        TRIGGER_POSITION_ID = self.ppo_params[\"TRIGGER_POSITION_ID\"]\n",
    "        device = self.ppo_params[\"device\"]\n",
    "        batch_size, batch_max_length = model_input.shape\n",
    "        \n",
    "        # WARNING: bos_key_value need to be passed\n",
    "        past = expand_past(bos_key_values, num_layers, batch_size)  # deep copy? shouldn't be modifed\n",
    "\n",
    "        if reset_pos_emb:\n",
    "            t_position_ids = torch.ones(batch_size, num_of_triggers).to(torch.long).to(device) * TRIGGER_POSITION_ID\n",
    "        else:\n",
    "            t_position_ids = None\n",
    "\n",
    "        if num_of_triggers > 0:\n",
    "            if trigger_format == \"token\":\n",
    "                if is_ref:\n",
    "                    trigger_embedding = self.model.ref_ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "                else:\n",
    "                    trigger_embedding = self.model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "                trigger_key_values = self.model(inputs_embeds=trigger_embedding, position_ids=t_position_ids)[1]\n",
    "            else:\n",
    "                if is_ref:\n",
    "                    trigger_key_values = expand_past(model.ref_ori_trigger_key_values, num_layers, batch_size)\n",
    "                else:\n",
    "                    trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "\n",
    "            past = concat_past(past, trigger_key_values, num_layers)\n",
    "\n",
    "        if reset_pos_emb:\n",
    "            p_position_ids = torch.arange(1, batch_max_length, dtype=torch.long, device=device)\n",
    "            p_position_ids = p_position_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "        else:\n",
    "            p_position_ids = None\n",
    "\n",
    "        logits, _, v = self.model(model_input[:, 1:], past_key_values=past, position_ids=p_position_ids)  # model_input[:, 0] is BOS\n",
    "\n",
    "        # Note: logits, v is 1 less than the model_input length because there is no prediction for BOS\n",
    "        # in order to use the actual lengths, we pad logits and v from bos\n",
    "        # WARNING: 1. should pass bos_logits as paramter 2. should expand box_logits at the beginning\n",
    "        logits = torch.cat((bos_logits.repeat(batch_size, 1, 1), logits), dim=1)\n",
    "        v = torch.cat((bos_v.detach().repeat(batch_size, 1), v), dim=1)\n",
    "        # Note: we do bos_v.detach() here because bos_v requires grad (bos_logits does not because it's not conditioned on anything we are training)\n",
    "        # if not detach, even if it's not actually used (by selecting actual length only), it will raise the error of \n",
    "        # \"trying to backward through the graph a second time\" because it is used for each mini-batch (regardless of the batch size, including size of 1)\n",
    "        \n",
    "        return logits, _, v\n",
    "\n",
    "    def batched_trigger_forward_pass(self, all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_scores):\n",
    "        # combines batched_forward_pass and compute_rewards\n",
    "        logprobs, ref_logprobs, values = list(), list(), list()\n",
    "        rewards, non_score_rewards = list(), list()\n",
    "        real_p_tensors, real_c_p_tensors, real_c_p_lengths, real_c_lengths = list(), list(), list(), list()\n",
    "        for i in range(len(all_c_lengths)):  # number of minibatches\n",
    "            model_input = all_c_p_tensors[i]  # bze x seq_len\n",
    "            logits, _, v = self.get_trigger_forward_pass(model_input)\n",
    "            ref_logits, _, _ = self.get_trigger_forward_pass(model_input, is_ref=True)\n",
    "            lp = logprobs_from_logits(logits[:, :-1, :], model_input[:, 1:])\n",
    "            ref_lp = logprobs_from_logits(ref_logits[:, :-1, :], model_input[:, 1:])\n",
    "\n",
    "            for j in range(len(all_c_lengths[i])):  # loop through the minibatch to get the real indices\n",
    "                start = all_c_lengths[i][j] - 1\n",
    "                end = all_c_p_lengths[i][j] - 1\n",
    "                values.append(v[j:j+1, start:end].detach())\n",
    "                ij_logprob = lp[j:j+1, start:end].detach()\n",
    "                ij_ref_logprob = ref_lp[j:j+1, start:end].detach()\n",
    "                logprobs.append(ij_logprob)\n",
    "                ref_logprobs.append(ij_ref_logprob)\n",
    "                real_p_tensors.append(all_c_p_tensors[i][j:j+1, start+1:end+1])\n",
    "                real_c_p_tensors.append(all_c_p_tensors[i][j:j+1, :end+1])\n",
    "                real_c_p_lengths.append(end + 1)\n",
    "                real_c_lengths.append(start + 1)\n",
    "\n",
    "                # compute rewards\n",
    "                ij_reward, ij_non_score_reward, kl_coef = self.compute_rewards(all_scores[i][j], ij_logprob, ij_ref_logprob)\n",
    "                rewards.append(ij_reward)\n",
    "                non_score_rewards.append(ij_non_score_reward)\n",
    "\n",
    "        return logprobs, ref_logprobs, values, rewards, non_score_rewards, kl_coef, real_p_tensors, real_c_p_tensors, real_c_p_lengths, real_c_lengths\n",
    "\n",
    "    def train_minibatch(self, b_logprobs, b_values, b_rewards, b_p_tensors, b_c_p_tensors, b_c_p_lengths, b_c_lengths):\n",
    "        \"\"\"Train one PPO minibatch\"\"\"\n",
    "#         print(\"getting loss!\")\n",
    "        loss_p, loss_v, train_stats  = self.loss(b_logprobs, b_values, b_rewards, b_p_tensors, b_c_p_tensors, b_c_p_lengths, b_c_lengths)\n",
    "        loss = loss_p + loss_v\n",
    "#         print(loss_p.item(), loss_v.item(), loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return train_stats\n",
    "\n",
    "    def compute_rewards(self, scores, logprobs, ref_logprobs):\n",
    "        \"\"\"Compute per token rewards from scores and KL-penalty.\"\"\"\n",
    "        kl = logprobs - ref_logprobs\n",
    "        non_score_reward = -self.kl_ctl.value * kl\n",
    "        rewards = non_score_reward.clone().detach()\n",
    "        rewards[:, -1] += scores\n",
    "        return rewards, non_score_reward, self.kl_ctl.value\n",
    "\n",
    "    # def loss(self, old_logprobs, values, rewards, query, response, model_input):\n",
    "    def loss(self, old_b_logprobs, b_values, b_rewards, b_p_tensors, b_c_p_tensors, b_c_p_lengths, b_c_lengths):\n",
    "        \"\"\"Calculate policy and value losses.\"\"\"\n",
    "        \n",
    "        # Note: values, old_logprobs are for prompts only (without context)\n",
    "\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "        \n",
    "        # pad mini batch for forward path\n",
    "        batch_max_length = max(c_p_t.shape[1] for c_p_t in b_c_p_tensors)\n",
    "        padded_tensors = list()\n",
    "        for c_p_t in b_c_p_tensors:\n",
    "            padded_tensors.append(torch.cat((c_p_t, torch.ones(1, batch_max_length - c_p_t.shape[1], dtype=torch.long, device=device) * self.ppo_params[\"padding_token\"]), dim=1))\n",
    "        padded_tensors = torch.cat(padded_tensors)  # mini_bs x batch_max_length\n",
    "        b_logits, _, b_vpred = self.get_trigger_forward_pass(padded_tensors)\n",
    "        b_logprob = logprobs_from_logits(b_logits[:, :-1, :], padded_tensors[:, 1:])  # min_bs x (batch_max_length - 1)\n",
    "        \n",
    "        b_pg_loss, b_vf_loss, b_loss, b_entropy, b_approxkl, b_policykl, b_pg_clipfrac,\\\n",
    "        b_advantages_mean, b_return_mean, b_return_var, b_mean_vpred, b_error, b_vf_clipfrac, b_value_mean, b_value_var = \\\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        \n",
    "        for j in range(mini_bs):   \n",
    "            start = b_c_lengths[j] - 1\n",
    "            end = b_c_p_lengths[j] - 1\n",
    "\n",
    "            logprob = b_logprob[j:j+1, start:end]\n",
    "            vpred = b_vpred[j:j+1, start:end]\n",
    "            gen_len = end - start\n",
    "            \n",
    "            old_logprobs = old_b_logprobs[j]\n",
    "            rewards = b_rewards[j]\n",
    "            values = b_values[j]\n",
    "            \n",
    "            lastgaelam = 0\n",
    "            advantages_reversed = []\n",
    "            for t in reversed(range(gen_len)):\n",
    "                nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
    "                delta = rewards[:, t] + self.ppo_params['gamma'] * nextvalues - values[:, t]\n",
    "                lastgaelam = delta + self.ppo_params['gamma'] * self.ppo_params['lam'] * lastgaelam\n",
    "                advantages_reversed.append(lastgaelam)\n",
    "            advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
    "\n",
    "            returns = advantages + values\n",
    "            advantages = whiten(advantages)\n",
    "            advantages = advantages.detach()\n",
    "\n",
    "            vpredclipped = clip_by_value(vpred,\n",
    "                                         values - self.ppo_params[\"cliprange_value\"],\n",
    "                                         values + self.ppo_params[\"cliprange_value\"])\n",
    "\n",
    "            vf_losses1 = (vpred - returns)**2\n",
    "            vf_losses2 = (vpredclipped - returns)**2\n",
    "            vf_loss = .5 * torch.mean(torch.max(vf_losses1, vf_losses2))\n",
    "            vf_clipfrac =  torch.mean(torch.gt(vf_losses2, vf_losses1).double())\n",
    "\n",
    "            ratio = torch.exp(logprob - old_logprobs)\n",
    "\n",
    "            pg_losses = -advantages * ratio\n",
    "            pg_losses2 = -advantages * torch.clamp(ratio,\n",
    "                                                   1.0 - self.ppo_params['cliprange'],\n",
    "                                                   1.0 + self.ppo_params['cliprange'])\n",
    "            \n",
    "#             print(\"advantages\")\n",
    "#             print(advantages)\n",
    "#             print(\"ratio\")\n",
    "#             print(ratio)\n",
    "#             print(\"pg_losses1: %s\" % str(torch.mean(pg_losses).item()))\n",
    "#             print(pg_losses)\n",
    "#             print(\"pg_losses2: %s\" % str(torch.mean(pg_losses2).item()))\n",
    "#             print(pg_losses2)\n",
    "#             print(\"pg_loss: %s\" % str(torch.mean(torch.max(pg_losses, pg_losses2))))\n",
    "#             print(torch.max(pg_losses, pg_losses2))\n",
    "                  \n",
    "            pg_loss = torch.mean(torch.max(pg_losses, pg_losses2))\n",
    "            pg_clipfrac = torch.mean(torch.gt(pg_losses2, pg_losses).double())\n",
    "\n",
    "            loss = pg_loss + self.ppo_params['vf_coef'] * vf_loss\n",
    "\n",
    "            approxkl = .5 * torch.mean((logprob - old_logprobs)**2)\n",
    "            policykl = torch.mean(logprob - old_logprobs)\n",
    "            return_mean, return_var = torch.mean(returns), torch.var(returns)\n",
    "            value_mean, value_var = torch.mean(values), torch.var(values)\n",
    "\n",
    "            b_pg_loss += pg_loss\n",
    "            b_vf_loss += vf_loss\n",
    "            b_loss += loss\n",
    "            b_approxkl += approxkl\n",
    "            b_policykl += policykl\n",
    "            b_pg_clipfrac += pg_clipfrac\n",
    "            b_advantages_mean += torch.mean(advantages)\n",
    "            b_return_mean += return_mean\n",
    "            b_return_var += return_var\n",
    "            b_mean_vpred += torch.mean(vpred)\n",
    "            b_error += torch.mean((vpred - returns) ** 2)\n",
    "            b_vf_clipfrac += vf_clipfrac\n",
    "            b_value_mean += value_mean\n",
    "            b_value_var += value_var\n",
    "\n",
    "        stats = dict(\n",
    "            loss=dict(policy=b_pg_loss/mini_bs, value=b_vf_loss/mini_bs, total=b_loss/mini_bs),\n",
    "            policy=dict(approxkl=b_approxkl/mini_bs, policykl=b_policykl/mini_bs, clipfrac=b_pg_clipfrac/mini_bs,\n",
    "                        advantages_mean=b_advantages_mean/mini_bs),\n",
    "            returns=dict(mean=b_return_mean/mini_bs, var=b_return_var/mini_bs),\n",
    "            val=dict(vpred=b_mean_vpred/mini_bs, error=b_error/mini_bs,\n",
    "                     clipfrac=b_vf_clipfrac/mini_bs, mean=b_value_mean/mini_bs, var=b_value_var/mini_bs),\n",
    "        )\n",
    "        return b_pg_loss/mini_bs, self.ppo_params['vf_coef'] * b_vf_loss/mini_bs, flatten_dict(stats)\n",
    "\n",
    "\n",
    "    def record_step_stats(self, kl_coef, **data):\n",
    "        \"\"\"Record training step statistics.\"\"\"\n",
    "        all_mean_kl = 0\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        for i in range(bs):\n",
    "            kl = data[\"logprobs\"][i] - data[\"ref_logprobs\"][i]\n",
    "            mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "            all_mean_kl += mean_kl\n",
    "\n",
    "        # kl = data['logprobs'] - data['ref_logprobs']\n",
    "        # mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "\n",
    "        stats = {\n",
    "            'objective/kl': all_mean_kl / bs,  # need this for adaptive kl controller\n",
    "            'objective/kl_coef': kl_coef,\n",
    "        }\n",
    "\n",
    "        for k, v in data['train_stats'].items():\n",
    "            stats[f'ppo/{k}'] = torch.mean(v, axis=0)\n",
    "        stats['ppo/val/var_explained'] = 1 - stats['ppo/val/error'] / stats['ppo/returns/var']\n",
    "        return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_text(whole_text_list, prefix_text_list):\n",
    "    return_cut_text = list()\n",
    "    for whole_text, prefix_text in zip(whole_text_list, prefix_text_list):\n",
    "        return_cut_text.append(whole_text.split(prefix_text)[1].strip())\n",
    "    return return_cut_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 1/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:34<57:33, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 2/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [01:15<1:02:40, 38.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 3/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [01:56<1:04:09, 39.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 4/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [02:37<1:04:00, 40.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 5/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [03:22<1:06:23, 41.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 6/100*************\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "fbs = config['forward_batch_size']\n",
    "\n",
    "for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config[\"batch_size\"])))):\n",
    "    print(\"***********Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(config[\"steps\"]/config[\"batch_size\"]))))\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = dict()\n",
    "    game_data = dict()\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #### get a batch from the dataset\n",
    "    if mode == \"train\" and shuffle_data:\n",
    "        random.shuffle(context_list)\n",
    "    cond_list = context_list[:config[\"batch_size\"]]\n",
    "    \n",
    "#     # this pad to the longest of all. may not be necessary\n",
    "#     all_input_ids, all_attention_masks, batch_min_length, batch_max_length, all_lengths = prep_inputs(cond_list, tokenizer, device, t_pad_token)\n",
    "    \n",
    "    all_c_lengths = list()\n",
    "    all_c_p_tensors, all_c_p_texts, all_c_p_lengths = list(), list(), list()\n",
    "    all_c_p_r_tensors, all_c_p_r_texts, all_c_p_r_lengths = list(), list(), list()\n",
    "    all_rewards = list()\n",
    "    all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list()\n",
    "    \n",
    "    log_context, log_prompt, log_response = list(), list(), list()\n",
    "    \n",
    "    #### get prompt from model\n",
    "    for i in range(int(config[\"batch_size\"]/fbs)):\n",
    "        ctx_i = cond_list[i*fbs:(i+1)*fbs]\n",
    "        log_context += ctx_i\n",
    "        input_ids_i, _, _, _, lengths_i = prep_inputs(ctx_i, tokenizer, device, t_pad_token)\n",
    "        # input_ids_i: bze x max_len\n",
    "        # lengths_i: list of int\n",
    "        all_c_lengths.append(lengths_i)\n",
    "        \n",
    "        min_c_length = min(lengths_i)\n",
    "        \n",
    "        c_p_tokens, c_p_tensors_padded, c_p_texts, c_p_lengths = generate_sentence(input_ids_i, lengths_i, min_c_length, stop_token, length, num_of_triggers=num_of_triggers)\n",
    "        # Note: c_p_lengths is the whole length (including context and prompt). list of int\n",
    "        # c_p_tensors_padded: not exactly padded with padding token, should be fine (can be removed by length in classification)\n",
    "        log_prompt += cut_text(c_p_texts, ctx_i)\n",
    "        \n",
    "        min_c_p_length = min(c_p_lengths)\n",
    "        c_p_r_tokens, c_p_r_tensors_padded, c_p_r_texts, c_p_r_lengths = generate_sentence(c_p_tensors_padded, c_p_lengths, min_c_p_length, stop_token, length, num_of_triggers=0)\n",
    "        log_response += cut_text(c_p_r_texts, c_p_texts)\n",
    "        \n",
    "#         # TODO: check c_p_texts, c_p_r_texts\n",
    "#         print(ctx_i)\n",
    "#         print(c_p_texts)\n",
    "#         print(c_p_r_texts)\n",
    "        \n",
    "#         print()\n",
    "#         print(c_p_tensors_padded)\n",
    "#         print(c_p_lengths)\n",
    "#         print()\n",
    "#         print(c_p_r_tensors_padded)\n",
    "#         print(c_p_r_lengths)\n",
    "#         assert False\n",
    "        \n",
    "        all_c_p_tensors.append(c_p_tensors_padded)\n",
    "        all_c_p_texts.append(c_p_texts)\n",
    "        all_c_p_lengths.append(c_p_lengths)\n",
    "        all_c_p_r_tensors.append(c_p_r_tensors_padded)\n",
    "        all_c_p_r_texts.append(c_p_r_texts)\n",
    "        all_c_p_r_lengths.append(c_p_r_lengths)\n",
    "        \n",
    "        # prepare for classification. Need to change later to only consider hidden states of the response\n",
    "        # WARNING: Different tokenizer! Need to pad again!\n",
    "        cls_c_p_r_tensors = [sentiment_tokenizer.encode(txt, return_tensors=\"pt\").to(device) for txt in c_p_r_texts]\n",
    "        max_cls_len = max([t.size()[1] for t in cls_c_p_r_tensors])\n",
    "        \n",
    "        cls_c_p_r_padded, cls_c_p_r_attn_mask = get_pad_attn_mask(cls_c_p_r_tensors, max_cls_len)\n",
    "        res = sentiment_model.forward(cls_c_p_r_padded, cls_c_p_r_attn_mask)[0][:, config[\"tgt_label\"]].detach()  # 0 is the logits of the transformer output\n",
    "        \n",
    "        # WARNING: set hyperparameters here\n",
    "        prompt_reward = True\n",
    "        c_p_reward_weight = 0.3\n",
    "        if prompt_reward:\n",
    "            cls_c_p_tensors = [sentiment_tokenizer.encode(txt, return_tensors=\"pt\").to(device) for txt in c_p_texts]\n",
    "            max_c_p_cls_len = max([t.size()[1] for t in cls_c_p_tensors])\n",
    "            cls_c_p_padded, cls_c_p_attn_mask = get_pad_attn_mask(cls_c_p_tensors, max_c_p_cls_len)\n",
    "            c_p_res = sentiment_model.forward(cls_c_p_padded, cls_c_p_attn_mask)[0][:, config[\"tgt_label\"]].detach()\n",
    "            # to make it neutral, we assign a reward score following the original ppo sentiment implementation\n",
    "            # this encourages the logits to be around 0\n",
    "            c_p_res_adjusted = -2*torch.abs(c_p_res)+4\n",
    "            all_c_p_r_rewards.append(res)\n",
    "            all_c_p_rewards.append(c_p_res)\n",
    "            all_c_p_rewards_adjusted.append(c_p_res_adjusted)\n",
    "            res = res + c_p_reward_weight * c_p_res_adjusted\n",
    "            \n",
    "        all_rewards.append(res)  # [bze]\n",
    "    \n",
    "#     print(\"sampled sentences\")\n",
    "#     for ck_i, ck_text in enumerate(all_c_p_r_texts):\n",
    "#         print(ck_text)\n",
    "#         print(all_rewards[ck_i])\n",
    "#         print(torch.mean(all_rewards[ck_i]))\n",
    "#         print()\n",
    "#     print(\"===========\\n\\n\")\n",
    "    \n",
    "#     print(\"Debuggin current key_value\")\n",
    "#     print(model.l_22_value[:, 0, :, :10])\n",
    "#     print(\"++++++++++++\\n\\n\\n\")\n",
    "#     assert False, \"Stop here. For PPO debugging, run the following in a different cell\"\n",
    "    \n",
    "    # should the following be in the fbs loop? Not really. We can change the order of batches in ppo epochs\n",
    "    # ideally we should be able to dynmaically combine batches, but using the batches formed before should be fine\n",
    "    # Run PPO training\n",
    "    t = time.time()\n",
    "    stats = ppo_trainer.step(all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_rewards)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    \n",
    "    #### Log everything\n",
    "    timing['time/epoch'] = time.time()-t0\n",
    "    logs.update(timing)\n",
    "    logs.update(stats)\n",
    "    log_name = \"game_log_e%d\" % (epoch + 1)\n",
    "    log_rewards = torch.cat(all_rewards)\n",
    "    if prompt_reward:\n",
    "        log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "        log_c_p_rewards_adjusted = torch.cat(all_c_p_rewards_adjusted)\n",
    "        log_c_p_r_rewards = torch.cat(all_c_p_r_rewards)\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_c_p_r_rewards.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_rewards_adjusted.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'combined reward', 'c_p_r_reward', 'c_p_reward', 'c_p_adjusted'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/c_p_r_reward_mean'] = torch.mean(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_std'] = torch.std(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_dist'] = log_c_p_r_rewards.cpu().numpy()\n",
    "        logs['env/combined_reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "        logs['env/c_p_adjusted_mean'] = torch.mean(log_c_p_rewards_adjusted).cpu().numpy()\n",
    "    else:\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'reward'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_dist'] = log_rewards.cpu().numpy()\n",
    "    wandb.log(logs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "# # ppo_trainer.model.detach_value_head()\n",
    "# print(ppo_trainer.model.v_head.detach_head)\n",
    "# stats = ppo_trainer.step(all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
