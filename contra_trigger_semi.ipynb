{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93120989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration, BlenderbotConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.generation_beam_search import BeamSearchScorer\n",
    "\n",
    "from ppo_model_ac import BlenderWithValueModel\n",
    "\n",
    "from ppo import AdaptiveKLController, FixedKLController\n",
    "from ppo_utils import build_bert_batch_from_txt, logprobs_from_logits, whiten, clip_by_value, entropy_from_logits, flatten_dict, stats_to_np, stack_dicts\n",
    "from utils import get_classifier, generate_next, concat_past, expand_past, read_file\n",
    "from trigger_semi_supervised import penalize_new_line, prep_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7a7891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotForConditionalGeneration(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): Embedding(8008, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mname = 'facebook/blenderbot-400M-distill'\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b481ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "model.config.do_sample = True\n",
    "model.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181f3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "# for blender:\n",
    "num_beam_groups = 1\n",
    "do_sample = False\n",
    "\n",
    "pad_token_id = 0\n",
    "bos_token_id = 1\n",
    "eos_token_id = 2\n",
    "\n",
    "tgt_label = 0  # 0 for not_ok, 1 for ok\n",
    "\n",
    "batch_size = 16  # should be the same as forward_batch_size\n",
    "num_of_triggers = 1\n",
    "trigger_format = \"key_value\"\n",
    "reset_pos_emb = True\n",
    "TRIGGER_POSITION_ID = 0\n",
    "\n",
    "adam_epsilon = 1e-8\n",
    "learning_rate = 2e-4\n",
    "\n",
    "model.model.encoder.reset_pos_emb = reset_pos_emb\n",
    "model.model.encoder.num_of_triggers = num_of_triggers\n",
    "\n",
    "# WARNING: need to change \n",
    "sample = True\n",
    "top_k = 10\n",
    "temperature = 1.0\n",
    "repetition_penalty = 1.0\n",
    "length = 40\n",
    "gradient_accumulation_steps = 1\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "seed = 2\n",
    "\n",
    "if num_of_triggers > 1:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n",
    "if not reset_pos_emb:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e686b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Training mode with shuffle_data = True\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/mnt/dian/trigger_experiments/semi_contra_2_fthb_100\"\n",
    "exp_name = \"semi_contra\"\n",
    "proj_name = \"final_2_fthb_100\"\n",
    "cls_model_name = \"/mnt/dian/trigger_experiments/roberta_decode\"\n",
    "discrim_name = \"contra\"\n",
    "cls_max_length = 256  # can only be 128 because of model length?\n",
    "# WARNING: should change input\n",
    "training_data = \"data/trigger_decode_train.txt\"\n",
    "\n",
    "total_steps = 75200 # changed from 30720 for finetune\n",
    "epoch_batch_size = 752  # changed from 512 for finetune\n",
    "\n",
    "finetune_dev = True\n",
    "if finetune_dev:\n",
    "    training_data = \"data/trigger_decode_human-bot.txt\"\n",
    "    finetune_init_ckeckpoint = \"/mnt/dian/trigger_experiments/semi_contra_2/e18.pt\"\n",
    "\n",
    "context_list = read_file(training_data)\n",
    "\n",
    "\n",
    "prompt_reward = False\n",
    "c_p_reward_weight = 0.2\n",
    "\n",
    "use_wandb = True\n",
    "\n",
    "mode = \"train\"\n",
    "shuffle_data = True\n",
    "\n",
    "print(\"WARNING: Training mode with shuffle_data = %s\" % shuffle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e3dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, _ = get_classifier(discrim_name, class_label=0, device=device)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429cb8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdianyu\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">semi_contra</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dianyu/final_2_fthb_100\" target=\"_blank\">https://wandb.ai/dianyu/final_2_fthb_100</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dianyu/final_2_fthb_100/runs/24l7d85t\" target=\"_blank\">https://wandb.ai/dianyu/final_2_fthb_100/runs/24l7d85t</a><br/>\n",
       "                Run data is saved locally in <code>/home/dianyu/trigger/wandb/run-20210514_002251-24l7d85t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_wandb:\n",
    "    wandb.init(name=exp_name, project=proj_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a036162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model for classification\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(cls_model_name)\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(cls_model_name)\n",
    "cls_model.to(device)\n",
    "cls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779f3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# Freeze GPT-2 weights\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_enc_layers = model.config.encoder_layers\n",
    "num_dec_layers = model.config.decoder_layers\n",
    "        \n",
    "    \n",
    "# lm_bos_output = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long, device=device).unsqueeze(0).repeat(batch_size, 1))  # BOS\n",
    "# # Note: GPT2HeadWithValueModel returns lm_logits, transformer_outputs[1:], value\n",
    "# # transformer_outputs: hidden_states, past_key_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f7b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1280])\n",
      "torch.Size([1, 32, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "# prepare for triggers\n",
    "\n",
    "# get_bos_embeddings\n",
    "bos_embeddings = model.model.encoder.embed_tokens(torch.tensor([bos_token_id], dtype=torch.long, device=device)).unsqueeze(0)  # 1, 1, hid_size\n",
    "\n",
    "# get_bos_key_values\n",
    "text_bos = [\"<s>\"]\n",
    "inputs_bos = tokenizer(text_bos, return_tensors='pt', padding=True).to(\"cuda\")\n",
    "inputs_bos_ids = inputs_bos[\"input_ids\"][:, 1:2]  # tensor([[228,   1,   2]]) for [<s>] (shape: 1, 3)\n",
    "bos_model_kwargs = dict()\n",
    "if bos_model_kwargs.get(\"attention_mask\", None) is None:\n",
    "    # init `attention_mask` depending on `pad_token_id`\n",
    "    bos_model_kwargs[\"attention_mask\"] = model._prepare_attention_mask_for_generation(\n",
    "        inputs_bos_ids, pad_token_id, eos_token_id\n",
    "    )\n",
    "\n",
    "bos_encoder_kwargs = {\n",
    "            argument: value for argument, value in bos_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "bos_output = model.model.encoder(inputs_bos_ids, return_dict=True, **bos_encoder_kwargs, use_cache=True)\n",
    "bos_key_values = bos_output[\"past_key_values\"]\n",
    "bos_hidden = bos_output[\"last_hidden_state\"]  # 1, 1, 1280\n",
    "print(bos_hidden.shape)\n",
    "print(bos_key_values[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c5eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trigger\n",
    "# Note: since we use the same trigger for all inputs in a batch, we only create/register trigger(s) for one and repeat it\n",
    "def init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=False):\n",
    "    if num_of_triggers > 0:\n",
    "        \n",
    "        # create hidden states for decoder\n",
    "        trigger_hidden_list = []\n",
    "        for _ in range(num_of_triggers):\n",
    "            trigger_hidden_i = nn.Parameter(copy.deepcopy(bos_hidden))\n",
    "            trigger_hidden_list.append(trigger_hidden_i)\n",
    "        if not ref:\n",
    "            ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            # WARNING: no need to register parameter?\n",
    "            model.register_parameter(name=\"ori_trigger_hidden\", param=ori_trigger_hidden)\n",
    "            model.ori_trigger_hidden = ori_trigger_hidden\n",
    "        else:\n",
    "            ref_ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            ref_ori_trigger_hidden.requires_grad = False\n",
    "            model.register_parameter(name=\"ref_ori_trigger_hidden\", param=ref_ori_trigger_hidden)\n",
    "            model.ref_ori_trigger_hidden = ref_ori_trigger_hidden\n",
    "            \n",
    "        if trigger_format == \"token\":  # learn a continuous embedding\n",
    "            trigger_embedding_list = []\n",
    "            for _ in range(num_of_triggers):\n",
    "                trigger_embedding_i = copy.deepcopy(bos_embeddings)\n",
    "                trigger_embedding_list.append(trigger_embedding_i)\n",
    "            if not ref:\n",
    "                ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                model.ori_trigger_embedding = ori_trigger_embedding  # register to the model (optimizer)\n",
    "            else:\n",
    "                ref_ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                ref_ori_trigger_embedding.requires_grad = False\n",
    "                model.ref_ori_trigger_embedding = ref_ori_trigger_embedding  # register to the model (optimizer)\n",
    "            # trigger_embedding = trigger_embedding.repeat(batch_size, 1, 1)  # cannot do it here, otherwise trigger_embedding becomes a non-leaf node where the grad will not backprop\n",
    "        elif trigger_format == \"key_value\":  # learn key values\n",
    "            ori_trigger_key_values = [(None, None) for _ in range(num_enc_layers)]\n",
    "            for layer in range(num_enc_layers):\n",
    "                for i_t in range(num_of_triggers):\n",
    "                    trigger_i_key_value = copy.deepcopy(bos_key_values)\n",
    "                    # key, value shape: bze, num_heads, seq_len, embed_per_head\n",
    "                    trigger_i_key, trigger_i_value = nn.Parameter(trigger_i_key_value[layer][0]), \\\n",
    "                                                     nn.Parameter(trigger_i_key_value[layer][1])\n",
    "\n",
    "                    if not ref:\n",
    "                        trigger_i_key.requires_grad = True\n",
    "                        trigger_i_value.requires_grad = True\n",
    "                    else:\n",
    "                        trigger_i_key.requires_grad = False\n",
    "                        trigger_i_value.requires_grad = False\n",
    "                        \n",
    "                    if ori_trigger_key_values[layer][0] is None:\n",
    "                        ori_trigger_key_values[layer] = (trigger_i_key, trigger_i_value)\n",
    "                    else:\n",
    "                        # if multiple triggers\n",
    "                        trigger_key = nn.Parameter(torch.cat((ori_trigger_key_values[layer][0], trigger_i_key), dim=-2))\n",
    "                        trigger_value = nn.Parameter(torch.cat((ori_trigger_key_values[layer][1], trigger_i_value), dim=-2))\n",
    "                        ori_trigger_key_values[layer] = (trigger_key, trigger_value)\n",
    "\n",
    "                if not ref:\n",
    "                    # register parameter into optimizer\n",
    "                    key_name = \"l_%d_key\" % layer\n",
    "                    value_name = \"l_%d_value\" % layer\n",
    "                else:\n",
    "                    key_name = \"ref_l_%d_key\" % layer\n",
    "                    value_name = \"ref_l_%d_value\" % layer\n",
    "                    \n",
    "                if num_of_triggers == 1:\n",
    "                    model.register_parameter(name=key_name, param=trigger_i_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_i_value)\n",
    "                else:\n",
    "                    model.register_parameter(name=key_name, param=trigger_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_value)\n",
    "                    \n",
    "            if not ref:\n",
    "                ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ori_trigger_key_values = ori_trigger_key_values\n",
    "            else:\n",
    "                ref_ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ref_ori_trigger_key_values = ori_trigger_key_values\n",
    "            # trigger_key_values = expand_past(trigger_key_values, num_layers, batch_size)  # similar to trigger_embedding, need leaf level grad\n",
    "        else:\n",
    "            assert False, \"trigger_format: %s not supported\" % trigger_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f4fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing params: \n",
      "ori_trigger_hidden l_0_key l_0_value l_1_key l_1_value\n"
     ]
    }
   ],
   "source": [
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "\n",
    "# optimizer\n",
    "param_optimizer = list(filter(lambda p: p[1].requires_grad, list(model.named_parameters())))\n",
    "\n",
    "# debugging: get all optimized param names\n",
    "print(\"optimizing params: \")\n",
    "print(\" \".join(o[0] for o in param_optimizer))\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=learning_rate,\n",
    "                  eps=adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a622659e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: fine-tuning from /mnt/dian/trigger_experiments/semi_contra_2/e18.pt\n",
      "total training steps: 75200\n"
     ]
    }
   ],
   "source": [
    "if finetune_dev:\n",
    "    ft_saved_dict = torch.load(finetune_init_ckeckpoint)\n",
    "    model.ori_trigger_hidden = ft_saved_dict[\"ori_trigger_hidden\"]\n",
    "    model.ori_trigger_key_values = ft_saved_dict[\"ori_trigger_key_values\"]\n",
    "    print(\"WARNING: fine-tuning from %s\" % finetune_init_ckeckpoint)\n",
    "    print(\"total training steps: %d\" % total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5e9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a51df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability distribution warper\n",
    "logits_warper = model._get_logits_warper(\n",
    "    top_k=model.config.top_k, top_p=model.config.top_p, temperature=model.config.temperature, num_beams=model.config.num_beams\n",
    ")\n",
    "\n",
    "# WARNING: use hyperparameters from the config instead of the following\n",
    "logits_processor = model._get_logits_processor(\n",
    "    repetition_penalty=model.config.repetition_penalty,\n",
    "    no_repeat_ngram_size=model.config.no_repeat_ngram_size,\n",
    "    bad_words_ids=None,\n",
    "    min_length=model.config.min_length,\n",
    "    eos_token_id=eos_token_id,\n",
    "    prefix_allowed_tokens_fn=None,\n",
    "    num_beams=model.config.num_beams,\n",
    "    num_beam_groups=model.config.num_beam_groups,\n",
    "    diversity_penalty=model.config.diversity_penalty,\n",
    ")\n",
    "\n",
    "\n",
    "if model.config.num_beams > 1:\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "            batch_size=config[\"forward_batch_size\"],\n",
    "            max_length=model.config.max_length,\n",
    "            num_beams=model.config.num_beams,\n",
    "            device=device,\n",
    "            length_penalty=model.config.length_penalty,\n",
    "            do_early_stopping=model.config.early_stopping,\n",
    "            num_beam_hyps_to_keep=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71dd3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_trigger(text_list, num_layers, cur_num_of_triggers, is_response=False, use_gumbel=False, get_ppl=False):\n",
    "    # cur_num_of_triggers: different from \"num_of_triggers\" in the config, can be 0 if is ref or num_of_triggers\n",
    "    batch_size = len(text_list)\n",
    "    \n",
    "    # prepare past\n",
    "    past = expand_past(bos_key_values, num_layers, batch_size)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":\n",
    "            trigger_embedding = model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "            lm_trigger_output = model.model.encoder(inputs_embeds=trigger_embedding)\n",
    "            trigger_key_values = lm_trigger_output[\"past_key_values\"]\n",
    "        else:\n",
    "            trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "        past = concat_past(past, trigger_key_values, num_layers)\n",
    "        \n",
    "    # prepare hidden\n",
    "    prev_hidden = bos_hidden.repeat(batch_size, 1, 1)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        trigger_hidden = model.ori_trigger_hidden\n",
    "        trigger_hidden = trigger_hidden.repeat(batch_size, 1, 1)\n",
    "        prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "    \n",
    "    # prepare context\n",
    "    prev_length = prev_hidden.shape[1]\n",
    "    ctx_model_kwargs = dict()\n",
    "    ctx_inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "    # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "    cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "    ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "    # get encoder output\n",
    "    trigger_encoder_kwargs = {\n",
    "            argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "    trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "    try:\n",
    "        ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "    except:\n",
    "        print(ctx_inputs[\"input_ids\"].shape)\n",
    "        assert False\n",
    "        \n",
    "    ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "\n",
    "    ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "    # generate one sentence with trigger\n",
    "    ctx_input_ids = ctx_inputs['input_ids']\n",
    "    dec_input_ids = model._prepare_decoder_input_ids_for_generation(\n",
    "                    ctx_input_ids, decoder_start_token_id=bos_token_id, bos_token_id=bos_token_id)\n",
    "     \n",
    "    is_greedy_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_sample_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    is_beam_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_beam_sample_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    \n",
    "    return_dict_in_generate = model.config.return_dict_in_generate\n",
    "    output_hidden_states = False\n",
    "    if is_response:\n",
    "        return_dict_in_generate = True\n",
    "        output_hidden_states = True\n",
    "    if use_gumbel:\n",
    "        return_dict_in_generate = True\n",
    "    \n",
    "    output_scores = False\n",
    "    if get_ppl:\n",
    "        output_scores = True\n",
    "        return_dict_in_generate = True\n",
    "        \n",
    "    if is_greedy_gen_mode:\n",
    "        res = model.greedy_search(\n",
    "                dec_input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=False,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "        \n",
    "    elif is_sample_gen_mode:\n",
    "\n",
    "        # expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids,\n",
    "            expand_size=model.config.num_return_sequences,\n",
    "            is_encoder_decoder=True,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "        \n",
    "\n",
    "        # sample\n",
    "        res = model.sample(\n",
    "            dec_input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            use_gumbel=use_gumbel,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "    elif is_beam_gen_mode:\n",
    "        # interleave with `num_beams`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_search(\n",
    "            dec_input_ids,\n",
    "            beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=False,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            **ctx_model_kwargs,\n",
    "        ) \n",
    "    elif is_beam_sample_gen_mode:\n",
    "        # interleave with `num_beams * num_return_sequences`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams * model.config.num_return_sequences, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_sample(\n",
    "                dec_input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=output_scores,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "    \n",
    "    if use_gumbel:\n",
    "        generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        gumbel_vectors = res.gumbel_vectors\n",
    "        return generated_sentence_clean, gumbel_vectors\n",
    "    elif not is_response:  # generating prompts\n",
    "        if get_ppl:\n",
    "            generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "            generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "            \n",
    "            generated_sentence_mask = res.sequences.ne(pad_token_id).long()[:, :-2]  # the first one is bos\n",
    "            logits_tensor = torch.cat([raw_logits.unsqueeze(1) for raw_logits in res.scores], dim=1)  # bze x len x vocab\n",
    "            shift_logits = logits_tensor[..., :-1, :].contiguous()\n",
    "            shift_labels = res.sequences[..., 1:-1].contiguous()\n",
    "            loss_fct = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)).detach()\n",
    "            loss_reshape = loss.view(generated_sentence_mask.shape)  # bze x seq_len\n",
    "            # if loss is inf, then the masked loss (after multipling mask) will be nan\n",
    "            loss_reshape = torch.where(loss_reshape > 1e10, torch.ones_like(loss_reshape) * 0, loss_reshape)\n",
    "            masked_loss_sum = torch.sum(loss_reshape * generated_sentence_mask, dim=-1)  # [bze]\n",
    "            real_length = torch.sum(generated_sentence_mask, dim=-1)\n",
    "            masked_loss = torch.mean(masked_loss_sum / real_length).item()\n",
    "            ppl = math.exp(masked_loss)\n",
    "            return generated_sentence_clean, ppl\n",
    "        else:   \n",
    "            generated_sentence_raw = tokenizer.batch_decode(res)  \n",
    "            generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "            return generated_sentence_clean\n",
    "    else:\n",
    "        generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        all_hidden_states = res.decoder_hidden_states  # tuple of hidden states (bze, 1, hid)\n",
    "        all_last_hidden_states_list = [i[-1] for i in all_hidden_states]\n",
    "        hidden_states = torch.cat(all_last_hidden_states_list, dim=1)  # bze, seq_len, hid\n",
    "        \n",
    "        generated_sentence_mask = res.sequences.ne(pad_token_id).long()[:, :-1]\n",
    "        \n",
    "        return generated_sentence_clean, hidden_states, generated_sentence_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd033396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_blender_generation(raw_texts):\n",
    "    clean_texts = list()\n",
    "    for sentence_i in raw_texts:\n",
    "        sentence_i_0 = sentence_i.split(\"<s>\")[-1]\n",
    "        sentence_i_1 = sentence_i_0.split(\"</s>\")[0]\n",
    "        clean_texts.append(sentence_i_1.strip())\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abaabc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cls_examples_to_features(texts_a, texts_b, max_length):\n",
    "    all_cls_input_ids, all_cls_attention_mask = list(), list()\n",
    "    for text_a, text_b in zip(texts_a, texts_b):\n",
    "        cls_inputs = cls_tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length, truncation=True)\n",
    "        cls_input_ids = cls_inputs[\"input_ids\"]\n",
    "        cls_attention_mask = [1] * len(cls_input_ids)\n",
    "        \n",
    "        padding_length = max_length - len(cls_input_ids)\n",
    "        \n",
    "        cls_input_ids = cls_input_ids + ([cls_tokenizer.pad_token_id] * padding_length)\n",
    "        cls_attention_mask = cls_attention_mask + ([0] * padding_length)\n",
    "        # token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)  # not used in RoBERTa\n",
    "        \n",
    "        all_cls_input_ids.append(cls_input_ids)\n",
    "        all_cls_attention_mask.append(cls_attention_mask)\n",
    "    \n",
    "    all_cls_input_tensors = torch.tensor(all_cls_input_ids, dtype=torch.long, device=device)\n",
    "    all_cls_attention_mask_tensors = torch.tensor(all_cls_attention_mask, dtype=torch.long, device=device)\n",
    "    \n",
    "    return all_cls_input_tensors, all_cls_attention_mask_tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e657d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implement gumbel softmax here\n",
    "# def generate_with_gumbel(c_texts, gumbel_vectors_tuple, prompt_texts, c_p_texts):\n",
    "#     past = expand_past(bos_key_values, num_enc_layers, mini_batch_size)  # deep copy? shouldn't be modifed\n",
    "#     # assume 1 trigger, key_value\n",
    "#     past = concat_past(past, past, num_enc_layers)\n",
    "    \n",
    "#     # prepare hidden\n",
    "#     prev_hidden = bos_hidden.repeat(mini_batch_size, 1, 1)\n",
    "#     prev_hidden = torch.cat((prev_hidden, prev_hidden), dim=1)\n",
    "    \n",
    "#     # prepare context\n",
    "#     prev_length = prev_hidden.shape[1]\n",
    "#     ctx_model_kwargs = dict()\n",
    "#     ctx_inputs = tokenizer(c_texts, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "#     # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "#     cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "#     ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "#     # get encoder output\n",
    "#     trigger_encoder_kwargs = {\n",
    "#             argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "#         }\n",
    "#     trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "#     ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "#     ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "#     ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "#     # prepare decoder\n",
    "#     prompt_inputs = tokenizer(p_texts, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "#     prompt_inputs_ids = prompt_inputs[\"input_ids\"]\n",
    "#     prompt_attn_mask = prompt_inputs[\"attention_mask\"]\n",
    "    \n",
    "#     gumbel_vectors_tensor = torch.cat(gumbel_vectors_tuple, dim=1)  # should be bze x seq_len x vocab_size\n",
    "#     assert gumbel_vectors_tensor.shape[1] == prompt_inputs_ids.shape[1], \"gumbel vector shape: %s; prompt inputs shape: %s\" % (str(gumbel_vectors_tensor.shape), str(prompt_inputs_ids.shape))\n",
    "#     prompt_inputs_emb = torch.matmul(gumbel_vectors_tensor, model.model.decoder.embed_tokens.weight.shape)  # bze x seq_len x hid\n",
    "    \n",
    "    \n",
    "#     # add bos\n",
    "#     dec_bos_ids = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device) * bos_token_id\n",
    "#     dec_bos_mask = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device)\n",
    "#     dec_inputs_ids = torch.cat((dec_bos_ids, prompt_inputs_ids), dim=1)\n",
    "#     dec_attn_mask = torch.cat((dec_bos_mask, prompt_attn_mask), dim=1)\n",
    "#     prompt_length = torch.sum(dec_attn_mask, dim=-1)  # including bos and eos. shape: [bze]\n",
    "    \n",
    "#     model_inputs = {\"decoder_input_ids\": dec_inputs_ids, \"encoder_outputs\": ctx_model_kwargs[\"encoder_outputs\"],\n",
    "#                     \"attention_mask\": ctx_model_kwargs[\"attention_mask\"]}\n",
    "#     outputs = model(**model_inputs, return_dict=True)\n",
    "\n",
    "#     hidden_states = outputs[]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7cbcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-10\n",
    "def get_representation(r_hidden, r_mask):  \n",
    "    cur_batch_size, hidden_size = r_hidden.shape[0], r_hidden.shape[-1]\n",
    "    r_mask = r_mask.unsqueeze(2).repeat(1, 1, hidden_size)\n",
    "    masked_hidden = r_hidden * r_mask\n",
    "    \n",
    "    avg_hidden = torch.sum(masked_hidden, dim=1) / (torch.sum(r_mask, dim=1).detach() + EPSILON)\n",
    "    return avg_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "836e254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 1/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [05:34<9:11:44, 334.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 2/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [11:11<9:08:25, 335.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 3/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [16:24<8:46:07, 325.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 4/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [21:36<8:32:19, 320.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 5/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [26:34<8:14:05, 312.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 6/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [31:30<8:00:47, 306.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 7/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [36:19<7:46:13, 300.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 8/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [41:06<7:34:38, 296.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 9/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [45:58<7:27:27, 295.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 10/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [51:00<7:25:56, 297.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 11/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [55:57<7:20:39, 297.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 12/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [1:00:59<7:18:06, 298.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 13/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [1:05:58<7:13:04, 298.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 14/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [1:10:47<7:04:06, 295.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 15/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [1:15:35<6:55:51, 293.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 16/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [1:20:29<6:51:06, 293.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 17/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [1:25:31<6:49:37, 296.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 18/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [1:30:25<6:43:45, 295.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 19/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [1:35:16<6:37:16, 294.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 20/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [1:40:10<6:32:12, 294.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 21/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [1:45:08<6:28:46, 295.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 22/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [1:50:04<6:23:53, 295.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 23/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [1:54:51<6:16:03, 293.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 24/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [1:59:48<6:12:28, 294.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 25/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [2:04:39<6:06:21, 293.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 26/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [2:09:26<5:59:29, 291.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 27/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [2:14:19<5:55:13, 291.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 28/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [2:19:13<5:50:56, 292.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 29/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [2:24:09<5:47:16, 293.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 30/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [2:29:03<5:42:38, 293.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 31/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [2:33:56<5:37:29, 293.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 32/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [2:38:41<5:29:50, 291.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 33/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [2:43:24<5:22:03, 288.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 34/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [2:48:23<5:20:41, 291.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 35/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [2:53:11<5:14:58, 290.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 36/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [2:57:59<5:09:08, 289.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 37/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [3:02:55<5:06:06, 291.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 38/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [3:07:53<5:03:21, 293.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 39/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [3:12:52<5:00:04, 295.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 40/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [3:17:51<4:56:20, 296.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 41/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [3:22:51<4:52:31, 297.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 42/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [3:27:48<4:47:29, 297.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 43/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [3:32:36<4:39:53, 294.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 44/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [3:37:34<4:35:46, 295.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 45/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [3:42:34<4:32:15, 297.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 46/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [3:47:26<4:25:57, 295.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 47/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [3:52:14<4:18:56, 293.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 48/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [3:57:04<4:13:14, 292.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 49/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [4:01:56<4:08:15, 292.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 50/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [4:06:48<4:03:21, 292.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 51/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [4:11:32<3:56:29, 289.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 52/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [4:16:22<3:51:51, 289.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 53/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [4:21:05<3:45:23, 287.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 54/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [4:26:05<3:43:23, 291.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 55/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [4:30:54<3:38:08, 290.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 56/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [4:35:56<3:35:42, 294.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 57/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [4:40:47<3:30:03, 293.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 58/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [4:45:49<3:27:02, 295.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 59/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [4:50:41<3:21:21, 294.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 60/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [4:55:35<3:16:16, 294.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 61/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [5:00:35<3:12:24, 296.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 62/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [5:05:29<3:07:10, 295.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 63/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [5:10:25<3:02:16, 295.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 64/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [5:15:23<2:57:49, 296.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 65/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [5:20:11<2:51:22, 293.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 66/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [5:24:56<2:45:00, 291.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 67/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [5:29:34<2:37:58, 287.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 68/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [5:34:10<2:31:26, 283.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 69/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [5:38:51<2:26:14, 283.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 70/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [5:43:34<2:21:27, 282.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 71/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [5:48:08<2:15:33, 280.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 72/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [5:52:49<2:10:56, 280.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 73/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [5:57:28<2:05:57, 279.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 74/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [6:02:08<2:01:21, 280.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 75/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [6:06:50<1:56:57, 280.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 76/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [6:11:20<1:50:55, 277.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 77/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [6:15:59<1:46:33, 277.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 78/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [6:20:44<1:42:44, 280.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 79/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [6:25:16<1:37:10, 277.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 80/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [6:29:56<1:32:43, 278.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 81/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [6:34:32<1:27:53, 277.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 82/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [6:38:59<1:22:21, 274.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 83/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [6:43:36<1:17:56, 275.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 84/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [6:48:10<1:13:18, 274.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 85/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [6:52:46<1:08:46, 275.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 86/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [6:57:20<1:04:09, 274.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 87/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [7:02:01<59:56, 276.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 88/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [7:06:32<55:01, 275.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 89/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [7:11:07<50:23, 274.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 90/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [7:15:46<46:02, 276.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 91/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [7:20:20<41:19, 275.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 92/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [7:25:01<36:56, 277.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 93/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [7:29:42<32:28, 278.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 94/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [7:34:22<27:53, 278.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 95/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [7:38:59<23:10, 278.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 96/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [7:43:31<18:25, 276.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 97/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [7:48:23<14:03, 281.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 98/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [7:52:52<09:14, 277.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 99/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [7:57:27<04:36, 276.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 100/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [8:02:03<00:00, 289.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(total_steps // epoch_batch_size)):\n",
    "    print(\"***********Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(total_steps / epoch_batch_size))))\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = dict()\n",
    "    game_data = dict()\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    if mode == \"train\" and shuffle_data:\n",
    "        random.shuffle(context_list)\n",
    "    cond_list = context_list[:epoch_batch_size]\n",
    "    \n",
    "    log_context, log_prompt, log_response = list(), list(), list()\n",
    "    all_rewards = list()\n",
    "    all_ppl = list()\n",
    "    all_c_p_rewards = list()\n",
    "    \n",
    "    # check real reward:\n",
    "    for i in range(int(epoch_batch_size / batch_size)):\n",
    "        ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "        log_context += ctx_i\n",
    "        \n",
    "        p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "        log_prompt += p_texts\n",
    "        all_ppl.append(p_ppl)\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "        \n",
    "        c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        try:\n",
    "            r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "        except Exception as e:\n",
    "            print(c_p_inputs[\"input_ids\"].shape)\n",
    "            print(ctx_i)\n",
    "            print(c_p_texts)\n",
    "            assert False, \"Exception: %s\" % e\n",
    "        r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "        r_texts = clean_blender_generation(r_texts_raw)\n",
    "        log_response += r_texts\n",
    "        \n",
    "         # run classifier for rewards        \n",
    "        cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "        cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"][:, tgt_label].detach() \n",
    "            c_p_res = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"][:, tgt_label].detach() \n",
    "\n",
    "        all_c_p_rewards.append(c_p_res)\n",
    "        all_rewards.append(res)  # [bze]\n",
    "        \n",
    "    # logging\n",
    "    log_name = \"game_log_e%d\" % (epoch + 1)\n",
    "    log_rewards = torch.cat(all_rewards)\n",
    "    log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "    log_ppl = sum(all_ppl) / len(all_ppl)\n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist())]\n",
    "    logs.update({log_name:wandb.Table(\n",
    "        columns=['context', 'prompt', 'response', 'reward'],\n",
    "        rows=table_rows)})\n",
    "    logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "    logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "    logs['env/p_ppl'] = log_ppl\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.log(logs)\n",
    "    \n",
    "    model.zero_grad()\n",
    "     \n",
    "    # real training\n",
    "    for i in range(int(epoch_batch_size / batch_size)):\n",
    "        loss_per_update = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "#         p_texts, p_gumbel_vectors = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, use_gumbel=True)\n",
    "        p_texts = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers)\n",
    "        log_prompt += p_texts\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "        \n",
    "        # without gumbel softmax. Need to run generate_with_gumbel to use gumbel softmax\n",
    "        r_texts, r_hidden, r_mask = generate_sentence_with_trigger(c_p_texts, num_enc_layers, num_of_triggers, is_response=True)    \n",
    "        \n",
    "        # r_hidden_mask?????????\n",
    "#         with torch.no_grad():\n",
    "        avg_hidden = get_representation(r_hidden, r_mask)\n",
    "        prediction = classifier(avg_hidden)\n",
    "        # WARNING: use [0] directly here (should use tgt_label)\n",
    "        label = torch.tensor([0], device=device, dtype=torch.long).repeat(batch_size)\n",
    "        discrim_loss = ce_loss(prediction, label)\n",
    "        \n",
    "        loss_per_update += discrim_loss.item()\n",
    "        \n",
    "        discrim_loss.backward()\n",
    "        \n",
    "#         print(\"Debuggin current key_value\")\n",
    "#         print(model.l_1_value[:, 0, :, :10])\n",
    "#         print(model.ori_trigger_hidden[:, :, :10])\n",
    "#         print(\"++++++++++++\\n\\n\\n\")\n",
    "        \n",
    "        if (i + 1) % gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "#             print(\"\\n=======update loss: %.6f=======\" % (loss_per_update / gradient_accumulation_steps))\n",
    "            total_loss += loss_per_update\n",
    "            loss_per_update = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # save trigger\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_filename = \"%s/e%d.pt\" % (save_path, epoch + 1)\n",
    "    save_data = dict()\n",
    "    save_data[\"ori_trigger_hidden\"] = model.ori_trigger_hidden\n",
    "    if trigger_format == \"token\":\n",
    "        save_data[\"ori_trigger_embedding\"] = model.ori_trigger_embedding\n",
    "    else:\n",
    "        save_data[\"ori_trigger_key_values\"] = model.ori_trigger_key_values\n",
    "    torch.save(save_data, save_filename)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c71cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d119abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Evaluating a saved model\n"
     ]
    }
   ],
   "source": [
    "# # load pre-trained model\n",
    "saved_model_path = \"/mnt/dian/trigger_experiments/semi_contra_2_fthb/e60.pt\"\n",
    "saved_dict = torch.load(saved_model_path)\n",
    "model.ori_trigger_hidden = saved_dict[\"ori_trigger_hidden\"]\n",
    "model.ori_trigger_key_values = saved_dict[\"ori_trigger_key_values\"]\n",
    "print(\"WARNING: Evaluating a saved model\")\n",
    "\n",
    "# init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "# init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f47817ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating data/trigger_decode_human-bot.txt\n",
      "***********Evaluation at Epoch: 100/100*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:00<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env/reward_mean': array(-1.7208819, dtype=float32), 'env/reward_std': array(1.722766, dtype=float32), 'env/c_p_probs_mean': array(0.04074984, dtype=float32), 'env/c_p_probs_std': array(0.15766414, dtype=float32), 'env/reward_prob_mean': array(0.19676541, dtype=float32), 'env/reward_prob_std': array(0.32923988, dtype=float32), 'env/p_ppl': 15.252524950870557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "softmax_fn = nn.Softmax(dim=-1)\n",
    "\n",
    "import csv\n",
    "\n",
    "csv_file = open(\"data/contra_testing_1.csv\", \"w\")\n",
    "\n",
    "\n",
    "\n",
    "eval_context_filename = \"data/trigger_decode_human-bot.txt\"\n",
    "eval_context_list = read_file(eval_context_filename)\n",
    "print(\"evaluating %s\" % eval_context_filename)\n",
    "print(\"***********Evaluation at Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(total_steps / epoch_batch_size))))\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "logs = dict()\n",
    "game_data = dict()\n",
    "timing = dict()\n",
    "t0 = time.time()\n",
    "\n",
    "#### get everything from the dataset\n",
    "cond_list = eval_context_list\n",
    "\n",
    "all_rewards, all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list(), list()\n",
    "all_probs, all_c_p_probs = list(), list()\n",
    "log_context, log_prompt, log_response = list(), list(), list()\n",
    "all_ppl = list()\n",
    "\n",
    "all_c_texts, all_p_texts = list(), list()\n",
    "all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "\n",
    "#### get prompt from model\n",
    "for i in tqdm(range(int(len(cond_list) / batch_size))):\n",
    "    ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    log_context += ctx_i\n",
    "\n",
    "    p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "    log_prompt += p_texts\n",
    "    all_ppl.append(p_ppl)\n",
    "\n",
    "    c_p_texts = list()\n",
    "    for c, p in zip(ctx_i, p_texts):\n",
    "        c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "\n",
    "    c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    try:\n",
    "        r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "    except Exception as e:\n",
    "        print(c_p_inputs[\"input_ids\"].shape)\n",
    "        print(ctx_i)\n",
    "        print(c_p_texts)\n",
    "        assert False, \"Exception: %s\" % e\n",
    "    r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "    r_texts = clean_blender_generation(r_texts_raw)\n",
    "    log_response += r_texts\n",
    "\n",
    "    c_p_r_texts = list()\n",
    "    for c_p, r in zip(c_p_texts, r_texts):\n",
    "        c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "\n",
    "\n",
    "    all_c_texts.append(ctx_i)\n",
    "    all_p_texts.append(p_texts)\n",
    "    all_r_texts.append(r_texts)\n",
    "    all_c_p_r_texts.append(c_p_r_texts)\n",
    "\n",
    "\n",
    "    # run classifier for rewards        \n",
    "    cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "    cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_logits = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"]\n",
    "        res = all_logits[:, tgt_label].detach() \n",
    "        res_probs = softmax_fn(all_logits)[:, tgt_label].detach() \n",
    "        \n",
    "        c_p_logits = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"]\n",
    "        c_p_res = c_p_logits[:, tgt_label].detach() \n",
    "        c_p_res_probs = softmax_fn(c_p_logits)[:, tgt_label].detach()\n",
    "\n",
    "\n",
    "\n",
    "    all_rewards.append(res)  # [bze]\n",
    "    # if prompt_reward, all_probs is actually for c_p_r\n",
    "    all_probs.append(res_probs)\n",
    "    all_c_p_rewards.append(c_p_res)\n",
    "    all_c_p_probs.append(c_p_res_probs)\n",
    "    \n",
    "log_name = \"evaluation %s @e%d\" % (eval_context_filename, epoch + 1)\n",
    "log_rewards = torch.cat(all_rewards)\n",
    "log_probs = torch.cat(all_probs)\n",
    "log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "log_c_p_probs = torch.cat(all_c_p_probs)\n",
    "\n",
    "log_ppl = sum(all_ppl) / len(all_ppl)   \n",
    "\n",
    "table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_probs.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_probs.cpu().tolist(),)]\n",
    "\n",
    "fieldnames = ['context', 'prompt', 'response', 'reward', 'probs', 'c_p_reward', 'c_p_probs']\n",
    "\n",
    "logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "\n",
    "logs['env/c_p_probs_mean'] = torch.mean(log_c_p_probs).cpu().numpy()\n",
    "logs['env/c_p_probs_std'] = torch.std(log_c_p_probs).cpu().numpy()\n",
    "    \n",
    "logs['env/reward_prob_mean'] = torch.mean(log_probs).cpu().numpy()\n",
    "logs['env/reward_prob_std'] = torch.std(log_probs).cpu().numpy()\n",
    "logs['env/p_ppl'] = log_ppl\n",
    "\n",
    "\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for row_list in table_rows:\n",
    "    row_dict = dict()\n",
    "    for row_name, row_item in zip(fieldnames, row_list):\n",
    "        row_dict[row_name] = row_item\n",
    "    writer.writerow(row_dict)\n",
    "\n",
    "print(logs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94306659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
