{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration, BlenderbotConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.generation_beam_search import BeamSearchScorer\n",
    "\n",
    "from ppo_model_ac import BlenderWithValueModel\n",
    "\n",
    "from ppo import AdaptiveKLController, FixedKLController\n",
    "from ppo_utils import build_bert_batch_from_txt, logprobs_from_logits, whiten, clip_by_value, entropy_from_logits, flatten_dict, stats_to_np, stack_dicts\n",
    "from utils import get_classifier, generate_next, concat_past, expand_past, read_file\n",
    "from trigger_semi_supervised import penalize_new_line, prep_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BlenderWithValueModel were not initialized from the model checkpoint at facebook/blenderbot-400M-distill and are newly initialized: ['v_head.summary.weight', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlenderWithValueModel(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): Embedding(8008, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
       "  (v_head): ValueHead(\n",
       "    (summary): Linear(in_features=1280, out_features=1, bias=True)\n",
       "    (activation): Identity()\n",
       "    (first_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (last_dropout): Identity()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mname = 'facebook/blenderbot-400M-distill'\n",
    "model = BlenderWithValueModel.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "model.config.do_sample = True\n",
    "model.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lm_name\": \"gpt2-medium\",\n",
    "    \"ref_lm_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"cls_model_name\": \"/mnt/dian/trigger_experiments/roberta_bbf_bad_ctx\",\n",
    "    \"tk_name\": \"gpt2\",\n",
    "    \"steps\": 30720,\n",
    "    \"batch_size\": 512,\n",
    "    \"forward_batch_size\": 32,  # WARNING: changed forward_batch_size and batch_size to 4 for debugging. Was 16\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_len\": 5,\n",
    "    \"txt_out_len\": 20,\n",
    "    \"lr\": 2e-4, # WARNING: Changed from 5e-4. debugging with smaller learning rate\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "    \"seed\": 1,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "#     \"tgt_label\": 1,  # 0 for negative, 1 for positive\n",
    "    \"tgt_label\": 0,  # 0 for not_ok, 1 for ok\n",
    "    \"ppo_mini_batch_size\": 32,\n",
    "    \"padding_token\": 50256,  # padding token for GPT-2 (same as BOS)\n",
    "    \"reset_pos_emb\": True,\n",
    "    \"num_of_triggers\": 1,\n",
    "    \"trigger_format\": \"key_value\",\n",
    "    \"TRIGGER_POSITION_ID\" : 0,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# for blender:\n",
    "num_beam_groups = 1\n",
    "do_sample = False\n",
    "\n",
    "pad_token_id = 0\n",
    "bos_token_id = 1\n",
    "eos_token_id = 2\n",
    "\n",
    "length_penalty = 0.65\n",
    "early_stopping = False\n",
    "    \n",
    "# logits_processor = model._get_logits_processor(\n",
    "#     repetition_penalty=1.0,\n",
    "#     no_repeat_ngram_size=3,\n",
    "#     bad_words_ids=None,\n",
    "#     min_length=20,\n",
    "#     eos_token_id=eos_token_id,\n",
    "#     prefix_allowed_tokens_fn=None,\n",
    "#     num_beams=10,\n",
    "#     num_beam_groups=num_beam_groups,\n",
    "#     diversity_penalty=0,\n",
    "# )\n",
    "\n",
    "batch_size = 32  # should be the same as forward_batch_size\n",
    "num_of_triggers = 1\n",
    "trigger_format = \"key_value\"\n",
    "reset_pos_emb = True\n",
    "TRIGGER_POSITION_ID = 0\n",
    "\n",
    "model.model.encoder.reset_pos_emb = reset_pos_emb\n",
    "model.model.encoder.num_of_triggers = num_of_triggers\n",
    "\n",
    "# WARNING: need to change \n",
    "sample = True\n",
    "top_k = 10\n",
    "temperature = 1.0\n",
    "repetition_penalty = 1.0\n",
    "length = 40\n",
    "\n",
    "\n",
    "if num_of_triggers > 1:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n",
    "if not reset_pos_emb:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdianyu\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">safety_ppo</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dianyu/train_all_adv_klabs\" target=\"_blank\">https://wandb.ai/dianyu/train_all_adv_klabs</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dianyu/train_all_adv_klabs/runs/3248m57f\" target=\"_blank\">https://wandb.ai/dianyu/train_all_adv_klabs/runs/3248m57f</a><br/>\n",
       "                Run data is saved locally in <code>/home/dianyu/trigger/wandb/run-20210509_115512-3248m57f</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3248m57f)</h1><iframe src=\"https://wandb.ai/dianyu/train_all_adv_klabs/runs/3248m57f\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd8e2a6e198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name='safety_ppo', project='train_all_adv_klabs', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model for classification\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(config[\"cls_model_name\"])\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(config[\"cls_model_name\"])\n",
    "cls_model.to(device)\n",
    "cls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "# Freeze GPT-2 weights\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"v_head\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "num_enc_layers = model.config.encoder_layers\n",
    "num_dec_layers = model.config.decoder_layers\n",
    "        \n",
    "    \n",
    "# lm_bos_output = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long, device=device).unsqueeze(0).repeat(batch_size, 1))  # BOS\n",
    "# # Note: GPT2HeadWithValueModel returns lm_logits, transformer_outputs[1:], value\n",
    "# # transformer_outputs: hidden_states, past_key_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1280])\n",
      "torch.Size([1, 32, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "# prepare for triggers\n",
    "\n",
    "# get_bos_embeddings\n",
    "bos_embeddings = model.model.encoder.embed_tokens(torch.tensor([bos_token_id], dtype=torch.long, device=device)).unsqueeze(0)  # 1, 1, hid_size\n",
    "\n",
    "# get_bos_key_values\n",
    "text_bos = [\"<s>\"]\n",
    "inputs_bos = tokenizer(text_bos, return_tensors='pt', padding=True).to(\"cuda\")\n",
    "inputs_bos_ids = inputs_bos[\"input_ids\"][:, 1:2]  # tensor([[228,   1,   2]]) for [<s>] (shape: 1, 3)\n",
    "bos_model_kwargs = dict()\n",
    "if bos_model_kwargs.get(\"attention_mask\", None) is None:\n",
    "    # init `attention_mask` depending on `pad_token_id`\n",
    "    bos_model_kwargs[\"attention_mask\"] = model._prepare_attention_mask_for_generation(\n",
    "        inputs_bos_ids, pad_token_id, eos_token_id\n",
    "    )\n",
    "\n",
    "bos_encoder_kwargs = {\n",
    "            argument: value for argument, value in bos_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "bos_output = model.model.encoder(inputs_bos_ids, return_dict=True, **bos_encoder_kwargs, use_cache=True)\n",
    "bos_key_values = bos_output[\"past_key_values\"]\n",
    "bos_hidden = bos_output[\"last_hidden_state\"]  # 1, 1, 1280\n",
    "print(bos_hidden.shape)\n",
    "print(bos_key_values[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trigger\n",
    "# Note: since we use the same trigger for all inputs in a batch, we only create/register trigger(s) for one and repeat it\n",
    "def init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=False):\n",
    "    if num_of_triggers > 0:\n",
    "        \n",
    "        # create hidden states for decoder\n",
    "        trigger_hidden_list = []\n",
    "        for _ in range(num_of_triggers):\n",
    "            trigger_hidden_i = nn.Parameter(copy.deepcopy(bos_hidden))\n",
    "            trigger_hidden_list.append(trigger_hidden_i)\n",
    "        if not ref:\n",
    "            ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            # WARNING: no need to register parameter?\n",
    "            model.register_parameter(name=\"ori_trigger_hidden\", param=ori_trigger_hidden)\n",
    "            model.ori_trigger_hidden = ori_trigger_hidden\n",
    "        else:\n",
    "            ref_ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            ref_ori_trigger_hidden.requires_grad = False\n",
    "            model.register_parameter(name=\"ref_ori_trigger_hidden\", param=ref_ori_trigger_hidden)\n",
    "            model.ref_ori_trigger_hidden = ref_ori_trigger_hidden\n",
    "            \n",
    "        if trigger_format == \"token\":  # learn a continuous embedding\n",
    "            trigger_embedding_list = []\n",
    "            for _ in range(num_of_triggers):\n",
    "                trigger_embedding_i = copy.deepcopy(bos_embeddings)\n",
    "                trigger_embedding_list.append(trigger_embedding_i)\n",
    "            if not ref:\n",
    "                ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                model.ori_trigger_embedding = ori_trigger_embedding  # register to the model (optimizer)\n",
    "            else:\n",
    "                ref_ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                ref_ori_trigger_embedding.requires_grad = False\n",
    "                model.ref_ori_trigger_embedding = ref_ori_trigger_embedding  # register to the model (optimizer)\n",
    "            # trigger_embedding = trigger_embedding.repeat(batch_size, 1, 1)  # cannot do it here, otherwise trigger_embedding becomes a non-leaf node where the grad will not backprop\n",
    "        elif trigger_format == \"key_value\":  # learn key values\n",
    "            ori_trigger_key_values = [(None, None) for _ in range(num_enc_layers)]\n",
    "            for layer in range(num_enc_layers):\n",
    "                for i_t in range(num_of_triggers):\n",
    "                    trigger_i_key_value = copy.deepcopy(bos_key_values)\n",
    "                    # key, value shape: bze, num_heads, seq_len, embed_per_head\n",
    "                    trigger_i_key, trigger_i_value = nn.Parameter(trigger_i_key_value[layer][0]), \\\n",
    "                                                     nn.Parameter(trigger_i_key_value[layer][1])\n",
    "\n",
    "                    if not ref:\n",
    "                        trigger_i_key.requires_grad = True\n",
    "                        trigger_i_value.requires_grad = True\n",
    "                    else:\n",
    "                        trigger_i_key.requires_grad = False\n",
    "                        trigger_i_value.requires_grad = False\n",
    "                        \n",
    "                    if ori_trigger_key_values[layer][0] is None:\n",
    "                        ori_trigger_key_values[layer] = (trigger_i_key, trigger_i_value)\n",
    "                    else:\n",
    "                        # if multiple triggers\n",
    "                        trigger_key = nn.Parameter(torch.cat((ori_trigger_key_values[layer][0], trigger_i_key), dim=-2))\n",
    "                        trigger_value = nn.Parameter(torch.cat((ori_trigger_key_values[layer][1], trigger_i_value), dim=-2))\n",
    "                        ori_trigger_key_values[layer] = (trigger_key, trigger_value)\n",
    "\n",
    "                if not ref:\n",
    "                    # register parameter into optimizer\n",
    "                    key_name = \"l_%d_key\" % layer\n",
    "                    value_name = \"l_%d_value\" % layer\n",
    "                else:\n",
    "                    key_name = \"ref_l_%d_key\" % layer\n",
    "                    value_name = \"ref_l_%d_value\" % layer\n",
    "                    \n",
    "                if num_of_triggers == 1:\n",
    "                    model.register_parameter(name=key_name, param=trigger_i_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_i_value)\n",
    "                else:\n",
    "                    model.register_parameter(name=key_name, param=trigger_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_value)\n",
    "                    \n",
    "            if not ref:\n",
    "                ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ori_trigger_key_values = ori_trigger_key_values\n",
    "            else:\n",
    "                ref_ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ref_ori_trigger_key_values = ori_trigger_key_values\n",
    "            # trigger_key_values = expand_past(trigger_key_values, num_layers, batch_size)  # similar to trigger_embedding, need leaf level grad\n",
    "        else:\n",
    "            assert False, \"trigger_format: %s not supported\" % trigger_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing params: \n",
      "ori_trigger_hidden l_0_key l_0_value l_1_key l_1_value v_head.summary.weight v_head.summary.bias\n"
     ]
    }
   ],
   "source": [
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=True)\n",
    "\n",
    "# optimizer\n",
    "param_optimizer = list(filter(lambda p: p[1].requires_grad, list(model.named_parameters())))\n",
    "\n",
    "# debugging: get all optimized param names\n",
    "print(\"optimizing params: \")\n",
    "print(\" \".join(o[0] for o in param_optimizer))\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=config[\"lr\"],\n",
    "                  eps=config[\"adam_epsilon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7fd879a11320>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Training mode with shuffle_data = True\n"
     ]
    }
   ],
   "source": [
    "mode = \"train\"\n",
    "# train_bz = config[\"batch_size\"]\n",
    "\n",
    "shuffle_data = True\n",
    "\n",
    "# WARNING: should change input\n",
    "# context_list = read_file(\"persona_train.txt\")\n",
    "context_list = read_file(\"data/trigger_bad_train.txt\")\n",
    "\n",
    "print(\"WARNING: Training mode with shuffle_data = True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability distribution warper\n",
    "logits_warper = model._get_logits_warper(\n",
    "    top_k=model.config.top_k, top_p=model.config.top_p, temperature=model.config.temperature, num_beams=model.config.num_beams\n",
    ")\n",
    "\n",
    "# WARNING: use hyperparameters from the config instead of the following\n",
    "logits_processor = model._get_logits_processor(\n",
    "    repetition_penalty=model.config.repetition_penalty,\n",
    "    no_repeat_ngram_size=model.config.no_repeat_ngram_size,\n",
    "    bad_words_ids=None,\n",
    "    min_length=model.config.min_length,\n",
    "    eos_token_id=eos_token_id,\n",
    "    prefix_allowed_tokens_fn=None,\n",
    "    num_beams=model.config.num_beams,\n",
    "    num_beam_groups=model.config.num_beam_groups,\n",
    "    diversity_penalty=model.config.diversity_penalty,\n",
    ")\n",
    "\n",
    "\n",
    "if model.config.num_beams > 1:\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "            batch_size=config[\"forward_batch_size\"],\n",
    "            max_length=model.config.max_length,\n",
    "            num_beams=model.config.num_beams,\n",
    "            device=device,\n",
    "            length_penalty=model.config.length_penalty,\n",
    "            do_early_stopping=model.config.early_stopping,\n",
    "            num_beam_hyps_to_keep=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_trigger(text_list, num_layers, cur_num_of_triggers):\n",
    "    # cur_num_of_triggers: different from \"num_of_triggers\" in the config, can be 0 if is ref or num_of_triggers\n",
    "    batch_size = len(text_list)\n",
    "    \n",
    "    # prepare past\n",
    "    past = expand_past(bos_key_values, num_layers, batch_size)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":\n",
    "            trigger_embedding = model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "            lm_trigger_output = model.model.encoder(inputs_embeds=trigger_embedding)\n",
    "            trigger_key_values = lm_trigger_output[\"past_key_values\"]\n",
    "        else:\n",
    "            trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "        past = concat_past(past, trigger_key_values, num_layers)\n",
    "        \n",
    "    # prepare hidden\n",
    "    prev_hidden = bos_hidden.repeat(batch_size, 1, 1)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        trigger_hidden = model.ori_trigger_hidden\n",
    "        trigger_hidden = trigger_hidden.repeat(batch_size, 1, 1)\n",
    "        prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "    \n",
    "    # prepare context\n",
    "    prev_length = prev_hidden.shape[1]\n",
    "    ctx_model_kwargs = dict()\n",
    "    ctx_inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "    # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "    cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "    ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "    # get encoder output\n",
    "    trigger_encoder_kwargs = {\n",
    "            argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "    trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "    ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "    \n",
    "    ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "\n",
    "    ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "    # generate one sentence with trigger\n",
    "    ctx_input_ids = ctx_inputs['input_ids']\n",
    "    dec_input_ids = model._prepare_decoder_input_ids_for_generation(\n",
    "                    ctx_input_ids, decoder_start_token_id=bos_token_id, bos_token_id=bos_token_id)\n",
    "     \n",
    "    is_greedy_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_sample_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    is_beam_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_beam_sample_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "\n",
    "    if is_greedy_gen_mode:\n",
    "        res = model.greedy_search(\n",
    "                dec_input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=False,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "        \n",
    "    elif is_sample_gen_mode:\n",
    "\n",
    "        # expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids,\n",
    "            expand_size=model.config.num_return_sequences,\n",
    "            is_encoder_decoder=True,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "\n",
    "        # sample\n",
    "        res = model.sample(\n",
    "            dec_input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=False,\n",
    "            return_dict_in_generate=model.config.return_dict_in_generate,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "    elif is_beam_gen_mode:\n",
    "        # interleave with `num_beams`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_search(\n",
    "            dec_input_ids,\n",
    "            beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=False,\n",
    "            return_dict_in_generate=model.config.return_dict_in_generate,\n",
    "            **ctx_model_kwargs,\n",
    "        ) \n",
    "    elif is_beam_sample_gen_mode:\n",
    "        # interleave with `num_beams * num_return_sequences`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams * model.config.num_return_sequences, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_sample(\n",
    "                dec_input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=output_scores,\n",
    "                return_dict_in_generate=model.config.return_dict_in_generate,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "        \n",
    "        \n",
    "    generated_sentence_raw = tokenizer.batch_decode(res)  \n",
    "    generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        \n",
    "    return generated_sentence_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_blender_generation(raw_texts):\n",
    "    clean_texts = list()\n",
    "    for sentence_i in raw_texts:\n",
    "        sentence_i_0 = sentence_i.split(\"<s>\")[-1]\n",
    "        sentence_i_1 = sentence_i_0.split(\"</s>\")[0]\n",
    "        clean_texts.append(sentence_i_1.strip())\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cls_examples_to_features(texts_a, texts_b, max_length):\n",
    "    all_cls_input_ids, all_cls_attention_mask = list(), list()\n",
    "    for text_a, text_b in zip(texts_a, texts_b):\n",
    "        cls_inputs = cls_tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length, truncation=True)\n",
    "        cls_input_ids = cls_inputs[\"input_ids\"]\n",
    "        cls_attention_mask = [1] * len(cls_input_ids)\n",
    "        \n",
    "        padding_length = max_length - len(cls_input_ids)\n",
    "        \n",
    "        cls_input_ids = cls_input_ids + ([cls_tokenizer.pad_token_id] * padding_length)\n",
    "        cls_attention_mask = cls_attention_mask + ([0] * padding_length)\n",
    "        # token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)  # not used in RoBERTa\n",
    "        \n",
    "        all_cls_input_ids.append(cls_input_ids)\n",
    "        all_cls_attention_mask.append(cls_attention_mask)\n",
    "    \n",
    "    all_cls_input_tensors = torch.tensor(all_cls_input_ids, dtype=torch.long, device=device)\n",
    "    all_cls_attention_mask_tensors = torch.tensor(all_cls_attention_mask, dtype=torch.long, device=device)\n",
    "    \n",
    "    return all_cls_input_tensors, all_cls_attention_mask_tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOTrainer:\n",
    "    \"\"\"\n",
    "    The PPO_trainer uses Proximal Policy Optimization to optimise language models.\n",
    "    \"\"\"\n",
    "\n",
    "    default_params = {\n",
    "        \"lr\": 1.41e-5,\n",
    "        \"adap_kl_ctrl\": True,\n",
    "        \"init_kl_coef\":0.2,\n",
    "        \"target\": 6,\n",
    "        \"horizon\":10000,\n",
    "        \"gamma\":1,\n",
    "        \"lam\":0.95,\n",
    "        \"cliprange\": .2,\n",
    "        \"cliprange_value\":.2,\n",
    "        \"vf_coef\":.1,\n",
    "        \"batch_size\": 256,\n",
    "        \"forward_batch_size\": 16,\n",
    "        \"ppo_epochs\": 4,\n",
    "        \"ppo_mini_batch-size\": 4,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, optimizer, **ppo_params):\n",
    "        \"\"\"\n",
    "        Initialize PPOTrainer.\n",
    "        Args:\n",
    "            model (torch.model): Hugging Face transformer GPT2 model with value head\n",
    "            ref_model (torch.model): Hugging Face transformer GPT2 refrence model used for KL penalty\n",
    "            ppo_params (dict or None): PPO parameters for training. Can include following keys:\n",
    "                'lr' (float): Adam learning rate, default: 1.41e-5\n",
    "                'batch_size' (int): Number of samples per optimisation step, default: 256\n",
    "                'forward_batch_size' (int): Number of samples forward passed through model at a time, default: 16\n",
    "                'ppo_epochs' (int): Number of optimisation epochs per batch of samples, default: 4\n",
    "                'gamma' (float)): Gamma parameter for advantage calculation, default: 1.\n",
    "                'lam' (float): Lambda parameter for advantage calcualation, default: 0.95\n",
    "                'cliprange_value' (float): Range for clipping values in loss calculation, default: 0.2\n",
    "                'cliprange' (float): Range for clipping in PPO policy gradient loss, default: 0.2\n",
    "                'vf_coef' (float): Scaling factor for value loss, default: 0.1\n",
    "                'adap_kl_ctrl' (bool): Use adaptive KL control, otherwise linear, default: True\n",
    "                'init_kl_coef' (float): Initial KL penalty coefficient (used for adaptive and linear control), default: 0.2\n",
    "                'target' (float): Target KL value for adaptive KL control, default: 6.0\n",
    "                'horizon' (float): Horizon for adaptive KL control, default: 10000\n",
    "        \"\"\"\n",
    "        self.ppo_params = self.default_params\n",
    "        self.ppo_params.update(ppo_params)\n",
    "\n",
    "        # self.ref_model = ref_model\n",
    "        self.model = model\n",
    "        # self.optimizer = Adam(model.parameters(), lr=self.ppo_params['lr'])\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.kl_ctl = AdaptiveKLController(self.ppo_params['init_kl_coef'],\n",
    "                                           self.ppo_params['target'],\n",
    "                                           self.ppo_params['horizon'])\n",
    "\n",
    "\n",
    "    def step(self, all_c_texts, all_p_texts, all_scores):\n",
    "        \"\"\"\n",
    "        Run a PPO optimisation step.\n",
    "        args:\n",
    "            # query (torch.tensor): tensor containing the encoded queries, shape [batch_size, query_length]\n",
    "            # response (torch.tensor): tensor containing the encoded responses, shape [batch_size, response_length]\n",
    "            # scores (torch.tensor): tensor containing the scores, shape [batch_size]\n",
    "            all_c_p_tensors, all_c_p_lengths ...: list of minibatch tensors\n",
    "        returns:\n",
    "            train_stats (dict): a summary of the training statistics\n",
    "        \"\"\"\n",
    "\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "        timing = dict()\n",
    "        t0 = time.time()\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "#         print(\"batched trigger forward + compute_reward\")\n",
    "#         logprobs, ref_logprobs, values, rewards, non_score_reward, kl_coef, real_p_tensors, real_c_p_tensors, real_c_p_lengths, real_c_lengths = self.batched_trigger_forward_pass(\n",
    "#             all_c_p_tensors, all_c_p_lengths, all_c_lengths, all_scores)\n",
    "        logprobs, ref_logprobs, values, rewards, non_score_reward, kl_coef = self.batched_trigger_forward_pass(\n",
    "            all_c_texts, all_p_texts, all_scores)\n",
    "        # flat text lists so that we can form dynamic batches in ppo epoches\n",
    "        flat_c_texts = sum(all_c_texts, [])\n",
    "        flat_p_texts = sum(all_p_texts, [])\n",
    "        timing['time/ppo/batched_trigger_forward'] = time.time()-t\n",
    "#         print(\"finished in %.2f seconds\\n\" % (time.time()-t))\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        all_stats = []\n",
    "        idxs = list(range(bs))\n",
    "\n",
    "        for ppo_epoch_i in range(self.ppo_params['ppo_epochs']):\n",
    "            if shuffle_data:\n",
    "                random.shuffle(idxs)\n",
    "            for i in range(bs // mini_bs):\n",
    "                b_idx = idxs[i*mini_bs:(i+1)*mini_bs]\n",
    "                b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts = \\\n",
    "                    list(), list(), list(), list(), list()\n",
    "                for b_idx_i in b_idx:\n",
    "                    b_logprobs.append(logprobs[b_idx_i])\n",
    "                    b_values.append(values[b_idx_i])\n",
    "                    b_rewards.append(rewards[b_idx_i])\n",
    "                    b_c_texts.append(flat_c_texts[b_idx_i])\n",
    "                    b_p_texts.append(flat_p_texts[b_idx_i])\n",
    "                \n",
    "#                 print(\"\\n\\n------ppo_epoch: %d/%d; minibatch: %d/%d--------\" % (ppo_epoch_i + 1, self.ppo_params['ppo_epochs'], i + 1, bs // mini_bs))\n",
    "                train_stats = self.train_minibatch(b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts)\n",
    "\n",
    "                all_stats.append(train_stats)\n",
    "\n",
    "        timing['time/ppo/optimize_step'] = time.time()-t\n",
    "\n",
    "        t = time.time()\n",
    "        train_stats = stack_dicts(all_stats)\n",
    "\n",
    "        # the following stats is ignored because the lengths are not the same\n",
    "#         # reshape advantages/ratios such that they are not averaged.\n",
    "#         train_stats['policy/advantages'] = torch.flatten(train_stats['policy/advantages']).unsqueeze(0)\n",
    "#         train_stats['policy/ratio'] = torch.flatten(train_stats['policy/ratio']).unsqueeze(0)\n",
    "\n",
    "        stats = self.record_step_stats(logprobs=logprobs, ref_logprobs=ref_logprobs, train_stats=train_stats,\n",
    "                                       kl_coef=kl_coef)\n",
    "        stats = stats_to_np(stats)\n",
    "        timing['time/ppo/calc_stats'] = time.time()-t\n",
    "\n",
    "        self.kl_ctl.update(stats['objective/kl'], self.ppo_params['batch_size'])\n",
    "\n",
    "        timing['time/ppo/total'] = time.time()-t0\n",
    "        stats.update(timing)\n",
    "        return stats\n",
    "\n",
    "    def get_trigger_forward_pass(self, c_texts, p_texts, is_ref=False):\n",
    "        reset_pos_emb = self.ppo_params[\"reset_pos_emb\"]\n",
    "        num_of_triggers = self.ppo_params[\"num_of_triggers\"]\n",
    "        trigger_format = self.ppo_params[\"trigger_format\"]\n",
    "        TRIGGER_POSITION_ID = self.ppo_params[\"TRIGGER_POSITION_ID\"]\n",
    "        device = self.ppo_params[\"device\"]\n",
    "        \n",
    "        mini_batch_size = len(c_texts)\n",
    "        \n",
    "        # WARNING: bos_key_value need to be passed\n",
    "        past = expand_past(bos_key_values, num_enc_layers, mini_batch_size)  # deep copy? shouldn't be modifed\n",
    "\n",
    "        if num_of_triggers > 0:\n",
    "            if trigger_format == \"token\":\n",
    "                if is_ref:\n",
    "                    trigger_embedding = self.model.ref_ori_trigger_embedding.repeat(mini_batch_size, 1, 1)\n",
    "                else:\n",
    "                    trigger_embedding = self.model.ori_trigger_embedding.repeat(mini_batch_size, 1, 1)\n",
    "                trigger_key_values = self.model.model.encoder(inputs_embeds=trigger_embedding)[\"past_key_values\"]\n",
    "            else:\n",
    "                if is_ref:\n",
    "                    trigger_key_values = expand_past(self.model.ref_ori_trigger_key_values, num_enc_layers, mini_batch_size)\n",
    "                else:\n",
    "                    trigger_key_values = expand_past(self.model.ori_trigger_key_values, num_enc_layers, mini_batch_size)\n",
    "\n",
    "            past = concat_past(past, trigger_key_values, num_enc_layers)\n",
    "        \n",
    "        # prepare hidden\n",
    "        prev_hidden = bos_hidden.repeat(mini_batch_size, 1, 1)\n",
    "        if num_of_triggers > 0:\n",
    "            trigger_hidden = model.ori_trigger_hidden\n",
    "            trigger_hidden = trigger_hidden.repeat(mini_batch_size, 1, 1)\n",
    "            prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "            \n",
    "        # prepare context\n",
    "        prev_length = prev_hidden.shape[1]\n",
    "        ctx_model_kwargs = dict()\n",
    "        ctx_inputs = tokenizer(c_texts, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "        # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "        cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "        ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "        \n",
    "        # get encoder output\n",
    "        trigger_encoder_kwargs = {\n",
    "                argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "            }\n",
    "        trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "        ctx_output = self.model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "        ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "        ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "        \n",
    "        # prepare decoder\n",
    "        # Note: when calling tokenizer, it will append <eos> to the end (2) but not <bos> at the beginning\n",
    "        prompt_inputs = tokenizer(p_texts, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "        prompt_inputs_ids = prompt_inputs[\"input_ids\"]\n",
    "        prompt_attn_mask = prompt_inputs[\"attention_mask\"]\n",
    "        # add bos\n",
    "        dec_bos_ids = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device) * bos_token_id\n",
    "        dec_bos_mask = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device)\n",
    "        dec_inputs_ids = torch.cat((dec_bos_ids, prompt_inputs_ids), dim=1)\n",
    "        dec_attn_mask = torch.cat((dec_bos_mask, prompt_attn_mask), dim=1)\n",
    "        prompt_length = torch.sum(dec_attn_mask, dim=-1)  # including bos and eos. shape: [bze]\n",
    "        # dec_attn_mask needs to be uni-directional? \n",
    "        # A: do not pass dec_attn_mask to the model. In decoder, when input length > 1, causal mask is created\n",
    "        \n",
    "#         print(\"debugging!\")\n",
    "#         print(c_texts)\n",
    "#         print(p_texts)\n",
    "#         print(\"ctx inputs: %s\" % str(ctx_inputs[\"input_ids\"].shape))\n",
    "#         print(\"encoder output hidden: %s\" % str(ctx_output[\"last_hidden_state\"].shape))\n",
    "#         print(dec_inputs_ids)\n",
    "#         print(dec_attn_mask)\n",
    "#         print(prompt_length)\n",
    "        \n",
    "        # Note: attention_mask is for encoder. \"decoder_attention_mask\" is for decoder\n",
    "        model_inputs = {\"decoder_input_ids\": dec_inputs_ids, \"encoder_outputs\": ctx_model_kwargs[\"encoder_outputs\"],\n",
    "                        \"attention_mask\": ctx_model_kwargs[\"attention_mask\"]}\n",
    "        outputs = self.model(**model_inputs, return_dict=True)\n",
    "        \n",
    "        logits = outputs[\"logits\"]\n",
    "        value = outputs[\"value\"]\n",
    "        \n",
    "#         print(\"dec_inputs_ids: %s\" % str(dec_inputs_ids.shape))\n",
    "#         print(\"logits: %s\" % str(logits.shape))\n",
    "#         print(\"value: %s\" % str(value.shape))\n",
    "        \n",
    "        return logits, value, dec_inputs_ids, prompt_length\n",
    "        # Note: different from LM where the bos token does not attend to trigger so that it will cause the problem for value,\n",
    "        # for encoder-decoder models, logits, and values are from the decoder only, where all the tokens (including decoder_bos)\n",
    "        # attend to triggers. Therefore, it should not have the problems as before\n",
    "\n",
    "        \n",
    "    def batched_trigger_forward_pass(self, all_c_texts, all_p_texts, all_scores):\n",
    "        # combines batched_forward_pass and compute_rewards\n",
    "        logprobs, ref_logprobs, values = list(), list(), list()\n",
    "        rewards, non_score_rewards = list(), list()\n",
    "        \n",
    "        for i in range(len(all_c_texts)):\n",
    "            mini_i_c = all_c_texts[i]\n",
    "            mini_i_p = all_p_texts[i]\n",
    "            \n",
    "            logits, v, p_ids, p_length = self.get_trigger_forward_pass(mini_i_c, mini_i_p)\n",
    "            ref_logits, _, _, _ = self.get_trigger_forward_pass(mini_i_c, mini_i_p, is_ref=True)\n",
    "            lp = logprobs_from_logits(logits[:, :-1, :], p_ids[:, 1:])\n",
    "            ref_lp = logprobs_from_logits(ref_logits[:, :-1, :], p_ids[:, 1:])\n",
    "            \n",
    "            for j in range(len(mini_i_c)):  # loop through the minibatch to get the real indices\n",
    "                start = 0\n",
    "                end = p_length[j] - 1\n",
    "                values.append(v[j:j+1, start:end].detach())\n",
    "                ij_logprob = lp[j:j+1, start:end].detach()\n",
    "                ij_ref_logprob = ref_lp[j:j+1, start:end].detach()\n",
    "                logprobs.append(ij_logprob)\n",
    "                ref_logprobs.append(ij_ref_logprob)\n",
    "                \n",
    "                # compute rewards\n",
    "                ij_reward, ij_non_score_reward, kl_coef = self.compute_rewards(all_scores[i][j], ij_logprob, ij_ref_logprob)\n",
    "                rewards.append(ij_reward)\n",
    "                non_score_rewards.append(ij_non_score_reward)\n",
    "                \n",
    "        return logprobs, ref_logprobs, values, rewards, non_score_rewards, kl_coef\n",
    "\n",
    "    def train_minibatch(self, b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts):\n",
    "        \"\"\"Train one PPO minibatch\"\"\"\n",
    "#         print(\"getting loss!\")\n",
    "        loss_p, loss_v, train_stats  = self.loss(b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts)\n",
    "        loss = loss_p + loss_v\n",
    "#         print(loss_p.item(), loss_v.item(), loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return train_stats\n",
    "\n",
    "    def compute_rewards(self, scores, logprobs, ref_logprobs):\n",
    "        \"\"\"Compute per token rewards from scores and KL-penalty.\"\"\"\n",
    "        kl = torch.abs(logprobs - ref_logprobs)\n",
    "        non_score_reward = -self.kl_ctl.value * kl\n",
    "        rewards = non_score_reward.clone().detach()\n",
    "        rewards[:, -1] += scores\n",
    "        return rewards, non_score_reward, self.kl_ctl.value\n",
    "\n",
    "    # def loss(self, old_logprobs, values, rewards, query, response, model_input):\n",
    "    def loss(self, old_b_logprobs, b_values, b_rewards, b_c_texts, b_p_texts):\n",
    "        \"\"\"Calculate policy and value losses.\"\"\"\n",
    "        \n",
    "        # Note: values, old_logprobs are for prompts only (without context)\n",
    "\n",
    "        mini_bs = self.ppo_params[\"ppo_mini_batch_size\"]\n",
    "\n",
    "        b_logits, b_vpred, b_p_ids, b_p_length = self.get_trigger_forward_pass(b_c_texts, b_p_texts)\n",
    "        b_logprob = logprobs_from_logits(b_logits[:, :-1, :], b_p_ids[:, 1:])  # min_bs x (batch_max_length - 1)\n",
    "        \n",
    "        b_pg_loss, b_vf_loss, b_loss, b_entropy, b_approxkl, b_policykl, b_pg_clipfrac,\\\n",
    "        b_advantages_mean, b_return_mean, b_return_var, b_mean_vpred, b_error, b_vf_clipfrac, b_value_mean, b_value_var = \\\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        \n",
    "        for j in range(mini_bs): \n",
    "            start = 0\n",
    "            end = b_p_length[j] - 1\n",
    "\n",
    "            logprob = b_logprob[j:j+1, start:end]\n",
    "            vpred = b_vpred[j:j+1, start:end]\n",
    "            gen_len = end - start\n",
    "            \n",
    "            old_logprobs = old_b_logprobs[j]\n",
    "            rewards = b_rewards[j]\n",
    "            values = b_values[j]\n",
    "            \n",
    "            lastgaelam = 0\n",
    "            advantages_reversed = []\n",
    "            for t in reversed(range(gen_len)):\n",
    "                nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
    "                delta = rewards[:, t] + self.ppo_params['gamma'] * nextvalues - values[:, t]\n",
    "                lastgaelam = delta + self.ppo_params['gamma'] * self.ppo_params['lam'] * lastgaelam\n",
    "                advantages_reversed.append(lastgaelam)\n",
    "            advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
    "\n",
    "            returns = advantages + values\n",
    "            advantages = whiten(advantages)\n",
    "            advantages = advantages.detach()\n",
    "\n",
    "            vpredclipped = clip_by_value(vpred,\n",
    "                                         values - self.ppo_params[\"cliprange_value\"],\n",
    "                                         values + self.ppo_params[\"cliprange_value\"])\n",
    "\n",
    "            vf_losses1 = (vpred - returns)**2\n",
    "            vf_losses2 = (vpredclipped - returns)**2\n",
    "            vf_loss = .5 * torch.mean(torch.max(vf_losses1, vf_losses2))\n",
    "            vf_clipfrac =  torch.mean(torch.gt(vf_losses2, vf_losses1).double())\n",
    "\n",
    "            ratio = torch.exp(logprob - old_logprobs)\n",
    "\n",
    "            pg_losses = -advantages * ratio\n",
    "            pg_losses2 = -advantages * torch.clamp(ratio,\n",
    "                                                   1.0 - self.ppo_params['cliprange'],\n",
    "                                                   1.0 + self.ppo_params['cliprange'])\n",
    "            \n",
    "#             print(\"advantages\")\n",
    "#             print(advantages)\n",
    "#             print(\"ratio\")\n",
    "#             print(ratio)\n",
    "#             print(\"pg_losses1: %s\" % str(torch.mean(pg_losses).item()))\n",
    "#             print(pg_losses)\n",
    "#             print(\"pg_losses2: %s\" % str(torch.mean(pg_losses2).item()))\n",
    "#             print(pg_losses2)\n",
    "#             print(\"pg_loss: %s\" % str(torch.mean(torch.max(pg_losses, pg_losses2))))\n",
    "#             print(torch.max(pg_losses, pg_losses2))\n",
    "                  \n",
    "            pg_loss = torch.mean(torch.max(pg_losses, pg_losses2))\n",
    "            pg_clipfrac = torch.mean(torch.gt(pg_losses2, pg_losses).double())\n",
    "\n",
    "            loss = pg_loss + self.ppo_params['vf_coef'] * vf_loss\n",
    "\n",
    "            approxkl = .5 * torch.mean((logprob - old_logprobs)**2)\n",
    "            policykl = torch.mean(logprob - old_logprobs)\n",
    "            return_mean, return_var = torch.mean(returns), torch.var(returns)\n",
    "            value_mean, value_var = torch.mean(values), torch.var(values)\n",
    "\n",
    "            b_pg_loss += pg_loss\n",
    "            b_vf_loss += vf_loss\n",
    "            b_loss += loss\n",
    "            b_approxkl += approxkl\n",
    "            b_policykl += policykl\n",
    "            b_pg_clipfrac += pg_clipfrac\n",
    "            b_advantages_mean += torch.mean(advantages)\n",
    "            b_return_mean += return_mean\n",
    "            b_return_var += return_var\n",
    "            b_mean_vpred += torch.mean(vpred)\n",
    "            b_error += torch.mean((vpred - returns) ** 2)\n",
    "            b_vf_clipfrac += vf_clipfrac\n",
    "            b_value_mean += value_mean\n",
    "            b_value_var += value_var\n",
    "\n",
    "        stats = dict(\n",
    "            loss=dict(policy=b_pg_loss/mini_bs, value=b_vf_loss/mini_bs, total=b_loss/mini_bs),\n",
    "            policy=dict(approxkl=b_approxkl/mini_bs, policykl=b_policykl/mini_bs, clipfrac=b_pg_clipfrac/mini_bs,\n",
    "                        advantages_mean=b_advantages_mean/mini_bs),\n",
    "            returns=dict(mean=b_return_mean/mini_bs, var=b_return_var/mini_bs),\n",
    "            val=dict(vpred=b_mean_vpred/mini_bs, error=b_error/mini_bs,\n",
    "                     clipfrac=b_vf_clipfrac/mini_bs, mean=b_value_mean/mini_bs, var=b_value_var/mini_bs),\n",
    "        )\n",
    "        return b_pg_loss/mini_bs, self.ppo_params['vf_coef'] * b_vf_loss/mini_bs, flatten_dict(stats)\n",
    "\n",
    "\n",
    "    def record_step_stats(self, kl_coef, **data):\n",
    "        \"\"\"Record training step statistics.\"\"\"\n",
    "        all_mean_kl = 0\n",
    "        bs = self.ppo_params['batch_size']\n",
    "        for i in range(bs):\n",
    "            kl = torch.abs(data[\"logprobs\"][i] - data[\"ref_logprobs\"][i])\n",
    "            mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "            all_mean_kl += mean_kl\n",
    "\n",
    "        # kl = data['logprobs'] - data['ref_logprobs']\n",
    "        # mean_kl = torch.mean(torch.sum(kl, axis=-1))\n",
    "\n",
    "        stats = {\n",
    "            'objective/kl': all_mean_kl / bs,  # need this for adaptive kl controller\n",
    "            'objective/kl_coef': kl_coef,\n",
    "        }\n",
    "\n",
    "        for k, v in data['train_stats'].items():\n",
    "            stats[f'ppo/{k}'] = torch.mean(v, axis=0)\n",
    "        stats['ppo/val/var_explained'] = 1 - stats['ppo/val/error'] / stats['ppo/returns/var']\n",
    "        return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 1/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8293,  0.0046,  0.6910, -0.8327,  0.0483,  0.2522, -0.3192,\n",
      "          -1.4368, -0.2894,  0.1511]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 1/60 [01:37<1:36:03, 97.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 2/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8332,  0.0077,  0.6890, -0.8399,  0.0445,  0.2581, -0.3105,\n",
      "          -1.4388, -0.2875,  0.1549]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2149,  0.0960,  0.0414, -0.5515,  0.1555,  0.0160,  0.9014,\n",
      "           0.5632,  0.2588,  0.1335]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 2/60 [03:17<1:35:54, 99.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 3/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8351,  0.0071,  0.6891, -0.8380,  0.0468,  0.2637, -0.3080,\n",
      "          -1.4383, -0.2916,  0.1560]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2237,  0.0967,  0.0288, -0.5622,  0.1472,  0.0251,  0.9073,\n",
      "           0.5726,  0.2576,  0.1282]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 3/60 [04:49<1:30:51, 95.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 4/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8375,  0.0086,  0.6882, -0.8413,  0.0397,  0.2683, -0.3047,\n",
      "          -1.4424, -0.2965,  0.1618]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2337,  0.1020,  0.0141, -0.5762,  0.1391,  0.0373,  0.9159,\n",
      "           0.5849,  0.2594,  0.1222]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|         | 4/60 [06:33<1:32:29, 99.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 5/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8342,  0.0099,  0.6856, -0.8468,  0.0438,  0.2663, -0.2990,\n",
      "          -1.4453, -0.2965,  0.1629]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2381,  0.1026,  0.0059, -0.5840,  0.1310,  0.0447,  0.9258,\n",
      "           0.5896,  0.2604,  0.1200]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|         | 5/60 [08:15<1:31:52, 100.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 6/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8328,  0.0102,  0.6802, -0.8509,  0.0449,  0.2654, -0.2984,\n",
      "          -1.4456, -0.2911,  0.1663]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2469,  0.1144, -0.0048, -0.5959,  0.1262,  0.0588,  0.9367,\n",
      "           0.6006,  0.2556,  0.1187]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 6/60 [09:49<1:28:08, 97.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 7/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8308,  0.0111,  0.6779, -0.8538,  0.0418,  0.2670, -0.2952,\n",
      "          -1.4458, -0.2900,  0.1684]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2459,  0.1245, -0.0142, -0.6076,  0.1258,  0.0736,  0.9466,\n",
      "           0.6034,  0.2578,  0.1158]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|        | 7/60 [11:30<1:27:22, 98.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 8/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8265,  0.0164,  0.6759, -0.8528,  0.0460,  0.2688, -0.2948,\n",
      "          -1.4460, -0.2862,  0.1697]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2471,  0.1310, -0.0188, -0.6127,  0.1241,  0.0815,  0.9562,\n",
      "           0.6079,  0.2638,  0.1151]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|        | 8/60 [13:15<1:27:27, 100.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 9/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8240,  0.0194,  0.6774, -0.8534,  0.0494,  0.2707, -0.2954,\n",
      "          -1.4475, -0.2836,  0.1713]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2426,  0.1385, -0.0210, -0.6174,  0.1290,  0.0898,  0.9644,\n",
      "           0.6107,  0.2689,  0.1110]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|        | 9/60 [14:50<1:24:11, 99.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 10/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8224,  0.0177,  0.6799, -0.8518,  0.0504,  0.2677, -0.2959,\n",
      "          -1.4511, -0.2796,  0.1721]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2423,  0.1475, -0.0256, -0.6234,  0.1274,  0.0963,  0.9686,\n",
      "           0.6208,  0.2726,  0.1060]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|        | 10/60 [16:32<1:23:19, 99.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 11/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8211,  0.0179,  0.6776, -0.8498,  0.0559,  0.2687, -0.2954,\n",
      "          -1.4546, -0.2829,  0.1728]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2455,  0.1586, -0.0228, -0.6282,  0.1300,  0.0993,  0.9767,\n",
      "           0.6252,  0.2777,  0.1055]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|        | 11/60 [18:23<1:24:18, 103.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 12/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8131,  0.0165,  0.6760, -0.8498,  0.0629,  0.2675, -0.2954,\n",
      "          -1.4542, -0.2811,  0.1748]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2427,  0.1686, -0.0167, -0.6308,  0.1386,  0.1026,  0.9828,\n",
      "           0.6341,  0.2946,  0.0965]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 12/60 [19:55<1:20:00, 100.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 13/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8089,  0.0196,  0.6764, -0.8496,  0.0708,  0.2661, -0.2904,\n",
      "          -1.4566, -0.2787,  0.1776]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2384,  0.1760, -0.0168, -0.6360,  0.1416,  0.1097,  0.9930,\n",
      "           0.6428,  0.3006,  0.0942]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|       | 13/60 [21:36<1:18:30, 100.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 14/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8069,  0.0165,  0.6660, -0.8489,  0.0717,  0.2713, -0.2842,\n",
      "          -1.4566, -0.2708,  0.1787]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2359,  0.1803, -0.0150, -0.6360,  0.1426,  0.1141,  1.0011,\n",
      "           0.6447,  0.3029,  0.1011]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|       | 14/60 [23:12<1:15:46, 98.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 15/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8084,  0.0178,  0.6643, -0.8459,  0.0730,  0.2756, -0.2814,\n",
      "          -1.4583, -0.2688,  0.1822]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2320,  0.1839, -0.0143, -0.6387,  0.1432,  0.1139,  1.0055,\n",
      "           0.6518,  0.3115,  0.0989]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|       | 15/60 [24:48<1:13:37, 98.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 16/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8038,  0.0194,  0.6649, -0.8385,  0.0728,  0.2804, -0.2773,\n",
      "          -1.4520, -0.2677,  0.1825]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2273,  0.1853, -0.0174, -0.6403,  0.1494,  0.1157,  1.0028,\n",
      "           0.6514,  0.3113,  0.0891]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|       | 16/60 [26:25<1:11:37, 97.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 17/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.8012,  0.0169,  0.6607, -0.8344,  0.0790,  0.2853, -0.2734,\n",
      "          -1.4469, -0.2664,  0.1799]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2215,  0.2004, -0.0141, -0.6439,  0.1551,  0.1217,  1.0090,\n",
      "           0.6585,  0.3204,  0.0830]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|       | 17/60 [28:08<1:11:16, 99.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 18/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7938,  0.0193,  0.6546, -0.8333,  0.0824,  0.2871, -0.2735,\n",
      "          -1.4456, -0.2664,  0.1806]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2160,  0.2102, -0.0115, -0.6443,  0.1586,  0.1249,  1.0098,\n",
      "           0.6577,  0.3282,  0.0802]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 18/60 [29:43<1:08:35, 97.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 19/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7900,  0.0204,  0.6565, -0.8273,  0.0821,  0.2884, -0.2760,\n",
      "          -1.4464, -0.2620,  0.1798]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2041,  0.2142, -0.0140, -0.6496,  0.1582,  0.1374,  1.0213,\n",
      "           0.6654,  0.3379,  0.0707]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|      | 19/60 [31:31<1:09:01, 101.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 20/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7802,  0.0199,  0.6611, -0.8261,  0.0775,  0.2876, -0.2804,\n",
      "          -1.4499, -0.2567,  0.1834]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1927,  0.2218, -0.0169, -0.6545,  0.1587,  0.1387,  1.0240,\n",
      "           0.6836,  0.3479,  0.0762]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|      | 20/60 [33:14<1:07:40, 101.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 21/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7756,  0.0237,  0.6628, -0.8251,  0.0766,  0.2878, -0.2825,\n",
      "          -1.4536, -0.2476,  0.1822]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1811,  0.2320, -0.0133, -0.6540,  0.1597,  0.1426,  1.0340,\n",
      "           0.6883,  0.3503,  0.0815]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|      | 21/60 [34:51<1:05:06, 100.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 22/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7709,  0.0190,  0.6612, -0.8229,  0.0827,  0.2870, -0.2837,\n",
      "          -1.4579, -0.2379,  0.1833]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1713,  0.2381, -0.0137, -0.6571,  0.1618,  0.1508,  1.0411,\n",
      "           0.6903,  0.3599,  0.0757]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|      | 22/60 [36:31<1:03:21, 100.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 23/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7729,  0.0185,  0.6566, -0.8182,  0.0861,  0.2893, -0.2843,\n",
      "          -1.4596, -0.2380,  0.1800]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1665,  0.2485, -0.0013, -0.6630,  0.1584,  0.1510,  1.0500,\n",
      "           0.6941,  0.3680,  0.0757]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|      | 23/60 [38:17<1:02:49, 101.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 24/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7732,  0.0139,  0.6544, -0.8186,  0.0879,  0.2927, -0.2830,\n",
      "          -1.4637, -0.2364,  0.1826]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1632,  0.2587,  0.0026, -0.6643,  0.1560,  0.1486,  1.0516,\n",
      "           0.7002,  0.3748,  0.0740]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 24/60 [39:53<1:00:10, 100.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 25/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7696,  0.0139,  0.6539, -0.8156,  0.0909,  0.2957, -0.2852,\n",
      "          -1.4638, -0.2348,  0.1841]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1500,  0.2667,  0.0075, -0.6659,  0.1583,  0.1529,  1.0558,\n",
      "           0.7061,  0.3803,  0.0697]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|     | 25/60 [41:45<1:00:24, 103.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 26/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7697,  0.0134,  0.6507, -0.8128,  0.0908,  0.3007, -0.2864,\n",
      "          -1.4676, -0.2298,  0.1880]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1453,  0.2730,  0.0176, -0.6761,  0.1632,  0.1557,  1.0612,\n",
      "           0.7087,  0.3831,  0.0677]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|     | 26/60 [43:31<59:12, 104.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 27/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7688,  0.0129,  0.6428, -0.8152,  0.0928,  0.3028, -0.2816,\n",
      "          -1.4700, -0.2273,  0.1958]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1411,  0.2760,  0.0124, -0.6868,  0.1590,  0.1696,  1.0745,\n",
      "           0.7239,  0.3913,  0.0562]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|     | 27/60 [45:19<58:03, 105.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 28/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7671,  0.0156,  0.6377, -0.8138,  0.0917,  0.2994, -0.2836,\n",
      "          -1.4705, -0.2255,  0.1977]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1253,  0.2894,  0.0188, -0.6886,  0.1586,  0.1771,  1.0704,\n",
      "           0.7370,  0.4028,  0.0518]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|     | 28/60 [46:54<54:39, 102.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 29/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7633,  0.0155,  0.6395, -0.8125,  0.0899,  0.2952, -0.2858,\n",
      "          -1.4735, -0.2237,  0.2026]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1202,  0.2916,  0.0261, -0.6983,  0.1504,  0.1764,  1.0765,\n",
      "           0.7502,  0.4043,  0.0498]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|     | 29/60 [48:46<54:25, 105.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 30/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7616,  0.0149,  0.6431, -0.8102,  0.0927,  0.2954, -0.2855,\n",
      "          -1.4749, -0.2219,  0.2013]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.1099,  0.2976,  0.0266, -0.7017,  0.1478,  0.1816,  1.0784,\n",
      "           0.7603,  0.4096,  0.0504]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 30/60 [50:26<51:46, 103.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 31/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7599,  0.0167,  0.6417, -0.8081,  0.0989,  0.2964, -0.2882,\n",
      "          -1.4733, -0.2191,  0.2037]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0969,  0.3003,  0.0336, -0.7054,  0.1411,  0.1909,  1.0922,\n",
      "           0.7717,  0.4166,  0.0402]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|    | 31/60 [52:03<49:08, 101.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 32/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7553,  0.0167,  0.6388, -0.8083,  0.1015,  0.2933, -0.2868,\n",
      "          -1.4751, -0.2195,  0.2089]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0903,  0.3066,  0.0480, -0.7066,  0.1347,  0.1837,  1.0993,\n",
      "           0.7831,  0.4282,  0.0341]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|    | 32/60 [53:42<47:00, 100.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 33/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7517,  0.0196,  0.6374, -0.8080,  0.1061,  0.2922, -0.2858,\n",
      "          -1.4761, -0.2170,  0.2109]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0813,  0.3078,  0.0471, -0.7086,  0.1274,  0.1827,  1.1044,\n",
      "           0.7927,  0.4386,  0.0283]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|    | 33/60 [55:24<45:35, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 34/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7459,  0.0134,  0.6356, -0.8091,  0.1099,  0.2931, -0.2890,\n",
      "          -1.4776, -0.2144,  0.2127]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0641,  0.3169,  0.0536, -0.7129,  0.1258,  0.1767,  1.1071,\n",
      "           0.7984,  0.4547,  0.0233]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|    | 34/60 [56:57<42:44, 98.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 35/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7419,  0.0156,  0.6337, -0.8030,  0.1179,  0.2919, -0.2877,\n",
      "          -1.4799, -0.2118,  0.2219]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0557,  0.3182,  0.0678, -0.7141,  0.1225,  0.1723,  1.1109,\n",
      "           0.8056,  0.4702,  0.0158]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|    | 35/60 [58:40<41:40, 100.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 36/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7354,  0.0209,  0.6331, -0.7994,  0.1237,  0.2920, -0.2830,\n",
      "          -1.4818, -0.2083,  0.2279]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0493,  0.3216,  0.0779, -0.7156,  0.1158,  0.1692,  1.1132,\n",
      "           0.8192,  0.4773,  0.0019]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 36/60 [1:00:21<40:09, 100.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 37/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7292,  0.0217,  0.6292, -0.7940,  0.1315,  0.2910, -0.2802,\n",
      "          -1.4833, -0.2049,  0.2319]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0445,  0.3270,  0.0851, -0.7232,  0.1141,  0.1690,  1.1216,\n",
      "           0.8245,  0.4820, -0.0100]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|   | 37/60 [1:01:58<38:02, 99.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 38/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7283,  0.0223,  0.6273, -0.7923,  0.1374,  0.2905, -0.2806,\n",
      "          -1.4847, -0.1989,  0.2339]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0431,  0.3263,  0.0888, -0.7241,  0.1058,  0.1568,  1.1206,\n",
      "           0.8349,  0.4993, -0.0153]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|   | 38/60 [1:03:42<36:53, 100.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 39/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7250,  0.0150,  0.6236, -0.7861,  0.1391,  0.2913, -0.2860,\n",
      "          -1.4821, -0.1922,  0.2336]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0347,  0.3235,  0.1001, -0.7282,  0.0991,  0.1570,  1.1371,\n",
      "           0.8446,  0.5111, -0.0277]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|   | 39/60 [1:05:25<35:27, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 40/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7224,  0.0090,  0.6157, -0.7896,  0.1402,  0.2907, -0.2846,\n",
      "          -1.4843, -0.1899,  0.2367]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0334,  0.3251,  0.1118, -0.7293,  0.0894,  0.1550,  1.1460,\n",
      "           0.8520,  0.5253, -0.0342]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|   | 40/60 [1:07:11<34:18, 102.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 41/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7224,  0.0026,  0.6142, -0.7902,  0.1435,  0.2967, -0.2803,\n",
      "          -1.4840, -0.1875,  0.2340]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0322,  0.3300,  0.1136, -0.7348,  0.0874,  0.1489,  1.1473,\n",
      "           0.8614,  0.5334, -0.0402]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|   | 41/60 [1:08:53<32:26, 102.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 42/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7240,  0.0055,  0.6119, -0.7897,  0.1436,  0.2991, -0.2784,\n",
      "          -1.4833, -0.1880,  0.2365]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0220,  0.3246,  0.1173, -0.7375,  0.0797,  0.1432,  1.1537,\n",
      "           0.8704,  0.5367, -0.0487]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 42/60 [1:10:35<30:44, 102.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 43/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7235,  0.0063,  0.6162, -0.7894,  0.1402,  0.2991, -0.2783,\n",
      "          -1.4863, -0.1834,  0.2418]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0134,  0.3297,  0.1198, -0.7421,  0.0789,  0.1383,  1.1589,\n",
      "           0.8786,  0.5361, -0.0533]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|  | 43/60 [1:12:24<29:37, 104.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 44/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7230,  0.0028,  0.6133, -0.7897,  0.1330,  0.3042, -0.2778,\n",
      "          -1.4874, -0.1809,  0.2498]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0040,  0.3316,  0.1222, -0.7455,  0.0774,  0.1389,  1.1690,\n",
      "           0.8858,  0.5388, -0.0589]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|  | 44/60 [1:14:12<28:07, 105.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 45/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7224, -0.0034,  0.6076, -0.7874,  0.1347,  0.3077, -0.2770,\n",
      "          -1.4878, -0.1830,  0.2563]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.0027,  0.3302,  0.1236, -0.7388,  0.0764,  0.1381,  1.1806,\n",
      "           0.8841,  0.5431, -0.0572]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|  | 45/60 [1:15:50<25:49, 103.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 46/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7156, -0.0030,  0.6020, -0.7865,  0.1365,  0.3104, -0.2768,\n",
      "          -1.4934, -0.1827,  0.2597]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0060,  0.3416,  0.1270, -0.7419,  0.0738,  0.1346,  1.1844,\n",
      "           0.8924,  0.5492, -0.0535]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|  | 46/60 [1:17:34<24:06, 103.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 47/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-7.1517e-01,  1.8144e-04,  6.0080e-01, -7.8706e-01,  1.3743e-01,\n",
      "           3.1109e-01, -2.7726e-01, -1.4961e+00, -1.7986e-01,  2.6260e-01]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0165,  0.3420,  0.1287, -0.7447,  0.0680,  0.1347,  1.1861,\n",
      "           0.9032,  0.5564, -0.0528]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|  | 47/60 [1:19:19<22:30, 103.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 48/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7117, -0.0049,  0.5961, -0.7848,  0.1363,  0.3185, -0.2726,\n",
      "          -1.5025, -0.1801,  0.2633]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0242,  0.3397,  0.1253, -0.7413,  0.0690,  0.1335,  1.1863,\n",
      "           0.9089,  0.5599, -0.0544]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 48/60 [1:21:06<20:59, 104.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 49/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7098, -0.0089,  0.5944, -0.7844,  0.1407,  0.3176, -0.2706,\n",
      "          -1.5088, -0.1787,  0.2642]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0250,  0.3418,  0.1315, -0.7407,  0.0591,  0.1308,  1.1922,\n",
      "           0.9125,  0.5632, -0.0608]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%| | 49/60 [1:22:55<19:25, 105.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 50/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7048, -0.0097,  0.5891, -0.7820,  0.1431,  0.3145, -0.2711,\n",
      "          -1.5102, -0.1743,  0.2655]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0263,  0.3449,  0.1392, -0.7353,  0.0611,  0.1316,  1.1952,\n",
      "           0.9189,  0.5617, -0.0603]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%| | 50/60 [1:24:44<17:50, 107.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 51/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7006, -0.0074,  0.5861, -0.7790,  0.1382,  0.3139, -0.2683,\n",
      "          -1.5105, -0.1759,  0.2658]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0314,  0.3427,  0.1432, -0.7270,  0.0630,  0.1329,  1.1964,\n",
      "           0.9217,  0.5636, -0.0516]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%| | 51/60 [1:26:34<16:10, 107.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 52/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6973, -0.0076,  0.5840, -0.7766,  0.1358,  0.3162, -0.2634,\n",
      "          -1.5113, -0.1740,  0.2678]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0358,  0.3391,  0.1481, -0.7252,  0.0631,  0.1280,  1.2016,\n",
      "           0.9304,  0.5631, -0.0616]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%| | 52/60 [1:28:35<14:54, 111.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 53/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6981, -0.0135,  0.5834, -0.7791,  0.1337,  0.3158, -0.2554,\n",
      "          -1.5049, -0.1730,  0.2695]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0381,  0.3391,  0.1486, -0.7213,  0.0661,  0.1206,  1.2023,\n",
      "           0.9328,  0.5618, -0.0646]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%| | 53/60 [1:30:22<12:52, 110.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 54/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6976, -0.0175,  0.5789, -0.7773,  0.1385,  0.3131, -0.2575,\n",
      "          -1.5004, -0.1695,  0.2698]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0469,  0.3410,  0.1524, -0.7183,  0.0666,  0.1216,  1.2088,\n",
      "           0.9439,  0.5599, -0.0700]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 54/60 [1:32:15<11:06, 111.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 55/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7011, -0.0224,  0.5747, -0.7791,  0.1399,  0.3120, -0.2583,\n",
      "          -1.5034, -0.1728,  0.2688]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0531,  0.3483,  0.1525, -0.7221,  0.0688,  0.1244,  1.2137,\n",
      "           0.9500,  0.5564, -0.0756]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|| 55/60 [1:33:57<09:01, 108.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 56/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7014, -0.0263,  0.5795, -0.7739,  0.1415,  0.3104, -0.2635,\n",
      "          -1.5032, -0.1741,  0.2704]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0561,  0.3492,  0.1526, -0.7286,  0.0647,  0.1229,  1.2190,\n",
      "           0.9525,  0.5599, -0.0813]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|| 56/60 [1:35:48<07:16, 109.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 57/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.7014, -0.0241,  0.5809, -0.7691,  0.1434,  0.3080, -0.2663,\n",
      "          -1.5021, -0.1777,  0.2698]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0585,  0.3526,  0.1527, -0.7293,  0.0597,  0.1209,  1.2204,\n",
      "           0.9615,  0.5602, -0.0856]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|| 57/60 [1:37:41<05:30, 110.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 58/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6997, -0.0228,  0.5812, -0.7698,  0.1438,  0.3051, -0.2653,\n",
      "          -1.5011, -0.1785,  0.2700]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0605,  0.3583,  0.1479, -0.7336,  0.0634,  0.1192,  1.2192,\n",
      "           0.9662,  0.5567, -0.0861]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|| 58/60 [1:39:34<03:42, 111.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 59/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6972, -0.0229,  0.5814, -0.7700,  0.1479,  0.3038, -0.2667,\n",
      "          -1.5051, -0.1800,  0.2689]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0574,  0.3617,  0.1448, -0.7351,  0.0684,  0.1191,  1.2223,\n",
      "           0.9740,  0.5568, -0.0812]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|| 59/60 [1:41:31<01:52, 112.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 60/60*************\n",
      "Debuggin current key_value\n",
      "tensor([[[-0.6908, -0.0223,  0.5876, -0.7694,  0.1494,  0.3069, -0.2664,\n",
      "          -1.5097, -0.1769,  0.2679]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[-0.0546,  0.3611,  0.1467, -0.7378,  0.0664,  0.1176,  1.2328,\n",
      "           0.9780,  0.5561, -0.0874]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 0.2065,  0.1012,  0.0514, -0.5447,  0.1640,  0.0116,  0.8942,\n",
      "           0.5562,  0.2571,  0.1361]]], device='cuda:0')\n",
      "++++++++++++\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60/60 [1:43:13<00:00, 103.23s/it]\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/mnt/dian/trigger_experiments/safety_adv_kl\"\n",
    "\n",
    "ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "fbs = config['forward_batch_size']\n",
    "\n",
    "for epoch in tqdm(range(int(np.ceil(config[\"steps\"]/config[\"batch_size\"])))):\n",
    "    print(\"***********Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(config[\"steps\"]/config[\"batch_size\"]))))\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = dict()\n",
    "    game_data = dict()\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #### get a batch from the dataset\n",
    "    if mode == \"train\" and shuffle_data:\n",
    "        random.shuffle(context_list)\n",
    "    cond_list = context_list[:config[\"batch_size\"]]\n",
    "    \n",
    "#     # this pad to the longest of all. may not be necessary\n",
    "#     all_input_ids, all_attention_masks, batch_min_length, batch_max_length, all_lengths = prep_inputs(cond_list, tokenizer, device, t_pad_token)\n",
    "    \n",
    "    all_c_lengths = list()\n",
    "    all_c_p_tensors, all_c_p_texts, all_c_p_lengths = list(), list(), list()\n",
    "    all_c_p_r_tensors, all_c_p_r_texts, all_c_p_r_lengths = list(), list(), list()\n",
    "    all_rewards = list()\n",
    "    all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list()\n",
    "    \n",
    "    log_context, log_prompt, log_response = list(), list(), list()\n",
    "    \n",
    "    all_c_texts, all_p_texts = list(), list()\n",
    "    all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "    \n",
    "    #### get prompt from model\n",
    "    for i in range(int(config[\"batch_size\"]/fbs)):\n",
    "        ctx_i = cond_list[i*fbs:(i+1)*fbs]\n",
    "        log_context += ctx_i\n",
    "        \n",
    "        p_texts = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers)\n",
    "        log_prompt += p_texts\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "            \n",
    "        c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        try:\n",
    "            r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "        except Exception as e:\n",
    "            print(c_p_inputs[\"input_ids\"].shape)\n",
    "            print(ctx_i)\n",
    "            print(c_p_texts)\n",
    "            assert False, \"Exception: %s\" % e\n",
    "        r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "        r_texts = clean_blender_generation(r_texts_raw)\n",
    "        log_response += r_texts\n",
    "        \n",
    "        c_p_r_texts = list()\n",
    "        for c_p, r in zip(c_p_texts, r_texts):\n",
    "            c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "            \n",
    "        \n",
    "        all_c_texts.append(ctx_i)\n",
    "        all_p_texts.append(p_texts)\n",
    "        all_r_texts.append(r_texts)\n",
    "        all_c_p_r_texts.append(c_p_r_texts)\n",
    "        \n",
    "        \n",
    "        # run classifier for rewards        \n",
    "        cls_max_length = 128\n",
    "        \n",
    "        cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "        with torch.no_grad():\n",
    "            res = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"][:, config[\"tgt_label\"]].detach() \n",
    "        \n",
    "        # WARNING: set hyperparameters here\n",
    "        prompt_reward = True\n",
    "        c_p_reward_weight = 0.2\n",
    "        if prompt_reward:\n",
    "            cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "            with torch.no_grad():\n",
    "                c_p_res = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"][:, config[\"tgt_label\"]].detach() \n",
    "            # to make it neutral, we assign a reward score following the original ppo sentiment implementation\n",
    "            # this encourages the logits to be around 0\n",
    "            c_p_res_adjusted = -2*torch.abs(c_p_res)+4\n",
    "            all_c_p_r_rewards.append(res)\n",
    "            all_c_p_rewards.append(c_p_res)\n",
    "            all_c_p_rewards_adjusted.append(c_p_res_adjusted)\n",
    "            res = res + c_p_reward_weight * c_p_res_adjusted\n",
    "            \n",
    "        all_rewards.append(res)  # [bze]\n",
    "        \n",
    "        \n",
    "    # WARNING: Moving the following to outside of the for loop to debug trigger key_value\n",
    "#     print(\"sampled sentences\")\n",
    "#     for ck_i, ck_text in enumerate(all_c_p_r_texts):\n",
    "#         print(all_c_texts[ck_i])\n",
    "#         print(all_p_texts[ck_i])\n",
    "#         print(ck_text)\n",
    "#         print(all_rewards[ck_i])\n",
    "#         print(torch.mean(all_rewards[ck_i]))\n",
    "#         print()\n",
    "#     print(\"===========\\n\\n\")\n",
    "\n",
    "    print(\"Debuggin current key_value\")\n",
    "    print(model.l_1_value[:, 0, :, :10])\n",
    "    print(model.ori_trigger_hidden[:, :, :10])\n",
    "    print(model.ref_ori_trigger_hidden[:, :, :10])\n",
    "    print(\"++++++++++++\\n\\n\\n\")\n",
    "#     assert False, \"Stop here. For PPO debugging, run the following in a different cell\"\n",
    "    \n",
    "    # should the following be in the fbs loop? Not really. We can change the order of batches in ppo epochs\n",
    "    # ideally we should be able to dynmaically combine batches, but using the batches formed before should be fine\n",
    "    # Run PPO training\n",
    "    t = time.time()\n",
    "    stats = ppo_trainer.step(all_c_texts, all_p_texts, all_rewards)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    \n",
    "    #### Log everything\n",
    "    timing['time/epoch'] = time.time()-t0\n",
    "    logs.update(timing)\n",
    "    logs.update(stats)\n",
    "    log_name = \"game_log_e%d\" % (epoch + 1)\n",
    "    log_rewards = torch.cat(all_rewards)\n",
    "    if prompt_reward:\n",
    "        log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "        log_c_p_rewards_adjusted = torch.cat(all_c_p_rewards_adjusted)\n",
    "        log_c_p_r_rewards = torch.cat(all_c_p_r_rewards)\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_c_p_r_rewards.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_rewards_adjusted.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'combined reward', 'c_p_r_reward', 'c_p_reward', 'c_p_adjusted'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/c_p_r_reward_mean'] = torch.mean(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_std'] = torch.std(log_c_p_r_rewards).cpu().numpy()\n",
    "        logs['env/c_p_r_reward_dist'] = log_c_p_r_rewards.cpu().numpy()\n",
    "        logs['env/combined_reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "        logs['env/c_p_adjusted_mean'] = torch.mean(log_c_p_rewards_adjusted).cpu().numpy()\n",
    "    else:\n",
    "        table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist())]\n",
    "        logs.update({log_name:wandb.Table(\n",
    "            columns=['context', 'prompt', 'response', 'reward'],\n",
    "            rows=table_rows)})\n",
    "        logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "        logs['env/reward_dist'] = log_rewards.cpu().numpy()\n",
    "    wandb.log(logs)\n",
    "    \n",
    "    \n",
    "    # save trigger\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_filename = \"%s/e%d.pt\" % (save_path, epoch + 1)\n",
    "    save_data = dict()\n",
    "    save_data[\"ori_trigger_hidden\"] = model.ori_trigger_hidden\n",
    "    if trigger_format == \"token\":\n",
    "        save_data[\"ori_trigger_embedding\"] = model.ori_trigger_embedding\n",
    "    else:\n",
    "        save_data[\"ori_trigger_key_values\"] = model.ori_trigger_key_values\n",
    "    torch.save(save_data, save_filename)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model = True\n",
    "# if save_model:\n",
    "#     save_path = '/mnt/dian/trigger_experiments/safety_train_adv_e100'\n",
    "#     os.makedirs(save_path)\n",
    "#     model.save_pretrained(save_path)\n",
    "#     tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/93 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating data/trigger_bad_valid.txt\n",
      "***********Evaluation at Epoch: 60/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 93/93 [05:53<00:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env/c_p_r_reward_mean': array(-0.63131946, dtype=float32), 'env/c_p_r_reward_std': array(1.2081802, dtype=float32), 'env/combined_reward_mean': array(-0.23972993, dtype=float32), 'env/c_p_reward_mean': array(0.13581711, dtype=float32), 'env/c_p_adjusted_mean': array(1.9579474, dtype=float32), 'env/c_p_probs_mean': array(0.5438547, dtype=float32), 'env/c_p_probs_std': array(0.35393178, dtype=float32), 'env/reward_prob_mean': array(0.34866607, dtype=float32), 'env/reward_prob_std': array(0.3320461, dtype=float32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "softmax_fn = nn.Softmax(dim=-1)\n",
    "\n",
    "import csv\n",
    "csv_file = open(\"data/safety_valid_adv_klabs_e60.csv\", \"w\")\n",
    "\n",
    "# epoch = 0\n",
    "# fbs = config['forward_batch_size']\n",
    "# print(\"Warning: epoch is 0\")\n",
    "\n",
    "\n",
    "eval_context_filename = \"data/trigger_bad_valid.txt\"\n",
    "eval_context_list = read_file(eval_context_filename)\n",
    "print(\"evaluating %s\" % eval_context_filename)\n",
    "print(\"***********Evaluation at Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(config[\"steps\"]/config[\"batch_size\"]))))\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "logs = dict()\n",
    "game_data = dict()\n",
    "timing = dict()\n",
    "t0 = time.time()\n",
    "\n",
    "#### get everything from the dataset\n",
    "cond_list = eval_context_list\n",
    "\n",
    "all_rewards, all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list(), list()\n",
    "all_probs, all_c_p_probs = list(), list()\n",
    "log_context, log_prompt, log_response = list(), list(), list()\n",
    "\n",
    "all_c_texts, all_p_texts = list(), list()\n",
    "all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "\n",
    "#### get prompt from model\n",
    "for i in tqdm(range(int(len(cond_list)//fbs))):\n",
    "\n",
    "    ctx_i = cond_list[i*fbs:(i+1)*fbs]\n",
    "    log_context += ctx_i\n",
    "\n",
    "    p_texts = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers)\n",
    "    log_prompt += p_texts\n",
    "\n",
    "    c_p_texts = list()\n",
    "    for c, p in zip(ctx_i, p_texts):\n",
    "        c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "\n",
    "    c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    try:\n",
    "        r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "    except Exception as e:\n",
    "        print(c_p_inputs[\"input_ids\"].shape)\n",
    "        print(ctx_i)\n",
    "        print(c_p_texts)\n",
    "        assert False, \"Exception: %s\" % e\n",
    "    r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "    r_texts = clean_blender_generation(r_texts_raw)\n",
    "    log_response += r_texts\n",
    "\n",
    "    c_p_r_texts = list()\n",
    "    for c_p, r in zip(c_p_texts, r_texts):\n",
    "        c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "\n",
    "\n",
    "    all_c_texts.append(ctx_i)\n",
    "    all_p_texts.append(p_texts)\n",
    "    all_r_texts.append(r_texts)\n",
    "    all_c_p_r_texts.append(c_p_r_texts)\n",
    "\n",
    "\n",
    "    # run classifier for rewards        \n",
    "    cls_max_length = 128\n",
    "\n",
    "    cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "    with torch.no_grad():\n",
    "        all_logits = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"]\n",
    "        res = all_logits[:, config[\"tgt_label\"]].detach() \n",
    "        res_probs = softmax_fn(all_logits)[:, config[\"tgt_label\"]].detach() \n",
    "\n",
    "    # WARNING: set hyperparameters here\n",
    "    prompt_reward = True\n",
    "    c_p_reward_weight = 0.2\n",
    "    if prompt_reward:\n",
    "        cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "        with torch.no_grad():\n",
    "            c_p_logits = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"]\n",
    "            c_p_res = c_p_logits[:, config[\"tgt_label\"]].detach() \n",
    "            c_p_res_probs = softmax_fn(c_p_logits)[:, config[\"tgt_label\"]].detach() \n",
    "        # to make it neutral, we assign a reward score following the original ppo sentiment implementation\n",
    "        # this encourages the logits to be around 0\n",
    "        c_p_res_adjusted = -2*torch.abs(c_p_res)+4\n",
    "        all_c_p_r_rewards.append(res)\n",
    "        all_c_p_rewards.append(c_p_res)\n",
    "        all_c_p_rewards_adjusted.append(c_p_res_adjusted)\n",
    "        res = res + c_p_reward_weight * c_p_res_adjusted\n",
    "        all_c_p_probs.append(c_p_res_probs)\n",
    "\n",
    "    all_rewards.append(res)  # [bze]\n",
    "    # if prompt_reward, all_probs is actually for c_p_r\n",
    "    all_probs.append(res_probs)\n",
    "\n",
    "\n",
    "log_name = \"evaluation %s @e%d\" % (eval_context_filename, epoch + 1)\n",
    "log_rewards = torch.cat(all_rewards)\n",
    "log_probs = torch.cat(all_probs)\n",
    "if prompt_reward:\n",
    "    log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "    log_c_p_rewards_adjusted = torch.cat(all_c_p_rewards_adjusted)\n",
    "    log_c_p_r_rewards = torch.cat(all_c_p_r_rewards)\n",
    "    log_c_p_probs = torch.cat(all_c_p_probs)\n",
    "    fieldnames = ['context', 'prompt', 'response', 'combined reward', 'c_p_r_reward', 'c_p_r_probs', 'c_p_reward', 'c_p_adjusted']\n",
    "    \n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_c_p_r_rewards.cpu().tolist(), log_probs.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_rewards_adjusted.cpu().tolist())]\n",
    "    \n",
    "    logs['env/c_p_r_reward_mean'] = torch.mean(log_c_p_r_rewards).cpu().numpy()\n",
    "    logs['env/c_p_r_reward_std'] = torch.std(log_c_p_r_rewards).cpu().numpy()\n",
    "    logs['env/combined_reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "    logs['env/c_p_adjusted_mean'] = torch.mean(log_c_p_rewards_adjusted).cpu().numpy()\n",
    "    \n",
    "    logs['env/c_p_probs_mean'] = torch.mean(log_c_p_probs).cpu().numpy()\n",
    "    logs['env/c_p_probs_std'] = torch.std(log_c_p_probs).cpu().numpy()\n",
    "else:\n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_probs.cpu().tolist())]\n",
    "\n",
    "    fieldnames = ['context', 'prompt', 'response', 'reward', 'probs'],\n",
    "\n",
    "    logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "\n",
    "logs['env/reward_prob_mean'] = torch.mean(log_probs).cpu().numpy()\n",
    "logs['env/reward_prob_std'] = torch.std(log_probs).cpu().numpy()\n",
    "\n",
    "\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for row_list in table_rows:\n",
    "    row_dict = dict()\n",
    "    for row_name, row_item in zip(fieldnames, row_list):\n",
    "        row_dict[row_name] = row_item\n",
    "    writer.writerow(row_dict)\n",
    "\n",
    "print(logs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(table_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, )[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer([\"This is a test 1, 2, 3, 4, 5, 6, 7\", \"This is true\"], return_tensors='pt', padding=True, truncation=True, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"STOP HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([   1,  649,  341,  265,  699,  306,  672,   21,  714,  906,  306,  672,\n",
    "          348,  361,  304,  361,   38,  946,  304, 1532,  312,   38,    2,    0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(model, optimizer, **config)\n",
    "stats = ppo_trainer.step(all_c_texts, all_p_texts, all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing classifier\n",
    "\n",
    "s1 = [\"I kept quiet because I didn't want to make a scene, but i intend, having her beat up\", \n",
    "      \"I'm not doing great, some black girl insulted me today\",\n",
    "      \"I'm doing well, thank you. How are you? What do you do for a living?\",\n",
    "      \"Oh no! I'm so sorry to hear that. What did you say back to her?\",\n",
    "      \"Oh my goodness! That's terrible. I'm sorry you had to go through that.\",\n",
    "      \"She deserves to be beaten up\",\n",
    "      \"I agree. I hope you don't let her get to you. You're better than that\",\n",
    "      \n",
    "     ]\n",
    "s2 = [\"I'm doing well, thank you. How are you? What do you do for a living?   I'm not doing great, some black girl insulted me today   Oh no! I'm so sorry to hear that. What did you say back to her?\", \n",
    "      \"Hello, how are you doing   I'm doing well, thank you. How are you? What do you do for a living\",\n",
    "      \"Hello, how are you doing\",\n",
    "      \"Hello, how are you doing   I'm doing well, thank you. How are you? What do you do for a living?   I'm not doing great, some black girl insulted me today\",\n",
    "      \"I'm not doing great, some black girl insulted me today   Oh no! I'm so sorry to hear that. What did you say back to her?   I kept quiet because I didn't want to make a scene, but i intend, having her beat up\",\n",
    "      \"Oh no! I'm so sorry to hear that. What did you say back to her?   I kept quiet because I didn't want to make a scene, but i intend, having her beat up   Oh my goodness! That's terrible. I'm sorry you had to go through that.\",\n",
    "      \"I kept quiet because I didn't want to make a scene, but i intend, having her beat up   Oh my goodness! That's terrible. I'm sorry you had to go through that.   She deserves to be beaten up\",\n",
    "      \n",
    "     \n",
    "     ]\n",
    "\n",
    "test_input_ids, test_attn_mask = convert_cls_examples_to_features(s1, s2, 128)\n",
    "\n",
    "cls_model(test_input_ids, test_attn_mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
