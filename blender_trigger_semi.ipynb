{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8818ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration, BlenderbotConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.generation_beam_search import BeamSearchScorer\n",
    "\n",
    "from ppo_model_ac import BlenderWithValueModel\n",
    "\n",
    "from ppo import AdaptiveKLController, FixedKLController\n",
    "from ppo_utils import build_bert_batch_from_txt, logprobs_from_logits, whiten, clip_by_value, entropy_from_logits, flatten_dict, stats_to_np, stack_dicts\n",
    "from utils import get_classifier, generate_next, concat_past, expand_past, read_file\n",
    "from trigger_semi_supervised import penalize_new_line, prep_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313fdf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotForConditionalGeneration(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): Embedding(8008, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mname = 'facebook/blenderbot-400M-distill'\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f7596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "model.config.do_sample = True\n",
    "model.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbc1e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "# for blender:\n",
    "num_beam_groups = 1\n",
    "do_sample = False\n",
    "\n",
    "pad_token_id = 0\n",
    "bos_token_id = 1\n",
    "eos_token_id = 2\n",
    "\n",
    "tgt_label = 0,  # 0 for not_ok, 1 for ok\n",
    "\n",
    "batch_size = 16  # should be the same as forward_batch_size\n",
    "num_of_triggers = 1\n",
    "trigger_format = \"key_value\"\n",
    "reset_pos_emb = True\n",
    "TRIGGER_POSITION_ID = 0\n",
    "\n",
    "adam_epsilon = 1e-8\n",
    "learning_rate = 2e-4\n",
    "\n",
    "model.model.encoder.reset_pos_emb = reset_pos_emb\n",
    "model.model.encoder.num_of_triggers = num_of_triggers\n",
    "\n",
    "# WARNING: need to change \n",
    "sample = True\n",
    "top_k = 10\n",
    "temperature = 1.0\n",
    "repetition_penalty = 1.0\n",
    "length = 40\n",
    "gradient_accumulation_steps = 1\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "seed = 2\n",
    "\n",
    "if num_of_triggers > 1:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n",
    "if not reset_pos_emb:\n",
    "    assert False, \"currently not supported! This is hard coded in BlenderbotEncoder for now!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595460ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Training mode with shuffle_data = True\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/mnt//trigger_experiments/semi_safety_2_ft\"\n",
    "exp_name = \"semi_safety\"\n",
    "proj_name = \"final_2_ft\"\n",
    "cls_model_name = \"/mnt//trigger_experiments/roberta_bbf_bad_ctx\"\n",
    "discrim_name = \"safety\"\n",
    "cls_max_length = 128\n",
    "# WARNING: should change input\n",
    "training_data = \"data/trigger_bad_train.txt\"\n",
    "\n",
    "total_steps = 15360 # changed from 30720 for finetune\n",
    "epoch_batch_size = 256  # changed from 512 for finetune\n",
    "\n",
    "finetune_dev = True\n",
    "if finetune_dev:\n",
    "    training_data = \"data/trigger_decode_human-bot.txt\"\n",
    "    finetune_init_ckeckpoint = \"/mnt//trigger_experiments/semi_safety_2/e36.pt\"\n",
    "\n",
    "context_list = read_file(training_data)\n",
    "\n",
    "\n",
    "prompt_reward = False\n",
    "c_p_reward_weight = 0.2\n",
    "\n",
    "use_wandb = True\n",
    "\n",
    "mode = \"train\"\n",
    "shuffle_data = True\n",
    "\n",
    "print(\"WARNING: Training mode with shuffle_data = %s\" % shuffle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403657a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, _ = get_classifier(discrim_name, class_label=0, device=device)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5fc870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">semi_safety</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai//final_2_ft\" target=\"_blank\">https://wandb.ai//final_2_ft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai//final_2_ft/runs/2ulwtf6x\" target=\"_blank\">https://wandb.ai//final_2_ft/runs/2ulwtf6x</a><br/>\n",
       "                Run data is saved locally in <code>/home//trigger/wandb/run-20210513_222543-2ulwtf6x</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_wandb:\n",
    "    wandb.init(name=exp_name, project=proj_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb704a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model for classification\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(cls_model_name)\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(cls_model_name)\n",
    "cls_model.to(device)\n",
    "cls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333ceabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# Freeze GPT-2 weights\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_enc_layers = model.config.encoder_layers\n",
    "num_dec_layers = model.config.decoder_layers\n",
    "        \n",
    "    \n",
    "# lm_bos_output = model(torch.tensor(tokenizer.encode(tokenizer.bos_token), dtype=torch.long, device=device).unsqueeze(0).repeat(batch_size, 1))  # BOS\n",
    "# # Note: GPT2HeadWithValueModel returns lm_logits, transformer_outputs[1:], value\n",
    "# # transformer_outputs: hidden_states, past_key_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f076f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1280])\n",
      "torch.Size([1, 32, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "# prepare for triggers\n",
    "\n",
    "# get_bos_embeddings\n",
    "bos_embeddings = model.model.encoder.embed_tokens(torch.tensor([bos_token_id], dtype=torch.long, device=device)).unsqueeze(0)  # 1, 1, hid_size\n",
    "\n",
    "# get_bos_key_values\n",
    "text_bos = [\"<s>\"]\n",
    "inputs_bos = tokenizer(text_bos, return_tensors='pt', padding=True).to(\"cuda\")\n",
    "inputs_bos_ids = inputs_bos[\"input_ids\"][:, 1:2]  # tensor([[228,   1,   2]]) for [<s>] (shape: 1, 3)\n",
    "bos_model_kwargs = dict()\n",
    "if bos_model_kwargs.get(\"attention_mask\", None) is None:\n",
    "    # init `attention_mask` depending on `pad_token_id`\n",
    "    bos_model_kwargs[\"attention_mask\"] = model._prepare_attention_mask_for_generation(\n",
    "        inputs_bos_ids, pad_token_id, eos_token_id\n",
    "    )\n",
    "\n",
    "bos_encoder_kwargs = {\n",
    "            argument: value for argument, value in bos_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "bos_output = model.model.encoder(inputs_bos_ids, return_dict=True, **bos_encoder_kwargs, use_cache=True)\n",
    "bos_key_values = bos_output[\"past_key_values\"]\n",
    "bos_hidden = bos_output[\"last_hidden_state\"]  # 1, 1, 1280\n",
    "print(bos_hidden.shape)\n",
    "print(bos_key_values[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfec07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trigger\n",
    "# Note: since we use the same trigger for all inputs in a batch, we only create/register trigger(s) for one and repeat it\n",
    "def init_trigger(model, tokenizer, num_of_triggers, trigger_format, ref=False):\n",
    "    if num_of_triggers > 0:\n",
    "        \n",
    "        # create hidden states for decoder\n",
    "        trigger_hidden_list = []\n",
    "        for _ in range(num_of_triggers):\n",
    "            trigger_hidden_i = nn.Parameter(copy.deepcopy(bos_hidden))\n",
    "            trigger_hidden_list.append(trigger_hidden_i)\n",
    "        if not ref:\n",
    "            ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            # WARNING: no need to register parameter?\n",
    "            model.register_parameter(name=\"ori_trigger_hidden\", param=ori_trigger_hidden)\n",
    "            model.ori_trigger_hidden = ori_trigger_hidden\n",
    "        else:\n",
    "            ref_ori_trigger_hidden = nn.Parameter(torch.cat(trigger_hidden_list, dim=1))  # 1 x n x hid\n",
    "            ref_ori_trigger_hidden.requires_grad = False\n",
    "            model.register_parameter(name=\"ref_ori_trigger_hidden\", param=ref_ori_trigger_hidden)\n",
    "            model.ref_ori_trigger_hidden = ref_ori_trigger_hidden\n",
    "            \n",
    "        if trigger_format == \"token\":  # learn a continuous embedding\n",
    "            trigger_embedding_list = []\n",
    "            for _ in range(num_of_triggers):\n",
    "                trigger_embedding_i = copy.deepcopy(bos_embeddings)\n",
    "                trigger_embedding_list.append(trigger_embedding_i)\n",
    "            if not ref:\n",
    "                ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                model.ori_trigger_embedding = ori_trigger_embedding  # register to the model (optimizer)\n",
    "            else:\n",
    "                ref_ori_trigger_embedding = nn.Parameter(torch.cat(trigger_embedding_list, dim=1))  # bze x n x emb_size\n",
    "                ref_ori_trigger_embedding.requires_grad = False\n",
    "                model.ref_ori_trigger_embedding = ref_ori_trigger_embedding  # register to the model (optimizer)\n",
    "            # trigger_embedding = trigger_embedding.repeat(batch_size, 1, 1)  # cannot do it here, otherwise trigger_embedding becomes a non-leaf node where the grad will not backprop\n",
    "        elif trigger_format == \"key_value\":  # learn key values\n",
    "            ori_trigger_key_values = [(None, None) for _ in range(num_enc_layers)]\n",
    "            for layer in range(num_enc_layers):\n",
    "                for i_t in range(num_of_triggers):\n",
    "                    trigger_i_key_value = copy.deepcopy(bos_key_values)\n",
    "                    # key, value shape: bze, num_heads, seq_len, embed_per_head\n",
    "                    trigger_i_key, trigger_i_value = nn.Parameter(trigger_i_key_value[layer][0]), \\\n",
    "                                                     nn.Parameter(trigger_i_key_value[layer][1])\n",
    "\n",
    "                    if not ref:\n",
    "                        trigger_i_key.requires_grad = True\n",
    "                        trigger_i_value.requires_grad = True\n",
    "                    else:\n",
    "                        trigger_i_key.requires_grad = False\n",
    "                        trigger_i_value.requires_grad = False\n",
    "                        \n",
    "                    if ori_trigger_key_values[layer][0] is None:\n",
    "                        ori_trigger_key_values[layer] = (trigger_i_key, trigger_i_value)\n",
    "                    else:\n",
    "                        # if multiple triggers\n",
    "                        trigger_key = nn.Parameter(torch.cat((ori_trigger_key_values[layer][0], trigger_i_key), dim=-2))\n",
    "                        trigger_value = nn.Parameter(torch.cat((ori_trigger_key_values[layer][1], trigger_i_value), dim=-2))\n",
    "                        ori_trigger_key_values[layer] = (trigger_key, trigger_value)\n",
    "\n",
    "                if not ref:\n",
    "                    # register parameter into optimizer\n",
    "                    key_name = \"l_%d_key\" % layer\n",
    "                    value_name = \"l_%d_value\" % layer\n",
    "                else:\n",
    "                    key_name = \"ref_l_%d_key\" % layer\n",
    "                    value_name = \"ref_l_%d_value\" % layer\n",
    "                    \n",
    "                if num_of_triggers == 1:\n",
    "                    model.register_parameter(name=key_name, param=trigger_i_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_i_value)\n",
    "                else:\n",
    "                    model.register_parameter(name=key_name, param=trigger_key)\n",
    "                    model.register_parameter(name=value_name, param=trigger_value)\n",
    "                    \n",
    "            if not ref:\n",
    "                ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ori_trigger_key_values = ori_trigger_key_values\n",
    "            else:\n",
    "                ref_ori_trigger_key_values = tuple(ori_trigger_key_values)\n",
    "                model.ref_ori_trigger_key_values = ori_trigger_key_values\n",
    "            # trigger_key_values = expand_past(trigger_key_values, num_layers, batch_size)  # similar to trigger_embedding, need leaf level grad\n",
    "        else:\n",
    "            assert False, \"trigger_format: %s not supported\" % trigger_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f26cc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing params: \n",
      "ori_trigger_hidden l_0_key l_0_value l_1_key l_1_value\n"
     ]
    }
   ],
   "source": [
    "init_trigger(model, tokenizer, num_of_triggers, trigger_format)\n",
    "\n",
    "# optimizer\n",
    "param_optimizer = list(filter(lambda p: p[1].requires_grad, list(model.named_parameters())))\n",
    "\n",
    "# debugging: get all optimized param names\n",
    "print(\"optimizing params: \")\n",
    "print(\" \".join(o[0] for o in param_optimizer))\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "    },\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=learning_rate,\n",
    "                  eps=adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818b7d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: fine-tuning from /mnt//trigger_experiments/semi_safety_2/e36.pt\n",
      "total training steps: 15360\n"
     ]
    }
   ],
   "source": [
    "if finetune_dev:\n",
    "    ft_saved_dict = torch.load(finetune_init_ckeckpoint)\n",
    "    model.ori_trigger_hidden = ft_saved_dict[\"ori_trigger_hidden\"]\n",
    "    model.ori_trigger_key_values = ft_saved_dict[\"ori_trigger_key_values\"]\n",
    "    print(\"WARNING: fine-tuning from %s\" % finetune_init_ckeckpoint)\n",
    "    print(\"total training steps: %d\" % total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf62528",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c31dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability distribution warper\n",
    "logits_warper = model._get_logits_warper(\n",
    "    top_k=model.config.top_k, top_p=model.config.top_p, temperature=model.config.temperature, num_beams=model.config.num_beams\n",
    ")\n",
    "\n",
    "# WARNING: use hyperparameters from the config instead of the following\n",
    "logits_processor = model._get_logits_processor(\n",
    "    repetition_penalty=model.config.repetition_penalty,\n",
    "    no_repeat_ngram_size=model.config.no_repeat_ngram_size,\n",
    "    bad_words_ids=None,\n",
    "    min_length=model.config.min_length,\n",
    "    eos_token_id=eos_token_id,\n",
    "    prefix_allowed_tokens_fn=None,\n",
    "    num_beams=model.config.num_beams,\n",
    "    num_beam_groups=model.config.num_beam_groups,\n",
    "    diversity_penalty=model.config.diversity_penalty,\n",
    ")\n",
    "\n",
    "\n",
    "if model.config.num_beams > 1:\n",
    "    beam_scorer = BeamSearchScorer(\n",
    "            batch_size=config[\"forward_batch_size\"],\n",
    "            max_length=model.config.max_length,\n",
    "            num_beams=model.config.num_beams,\n",
    "            device=device,\n",
    "            length_penalty=model.config.length_penalty,\n",
    "            do_early_stopping=model.config.early_stopping,\n",
    "            num_beam_hyps_to_keep=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b7e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_with_trigger(text_list, num_layers, cur_num_of_triggers, is_response=False, use_gumbel=False, get_ppl=False):\n",
    "    # cur_num_of_triggers: different from \"num_of_triggers\" in the config, can be 0 if is ref or num_of_triggers\n",
    "    batch_size = len(text_list)\n",
    "    \n",
    "    # prepare past\n",
    "    past = expand_past(bos_key_values, num_layers, batch_size)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        if trigger_format == \"token\":\n",
    "            trigger_embedding = model.ori_trigger_embedding.repeat(batch_size, 1, 1)\n",
    "            lm_trigger_output = model.model.encoder(inputs_embeds=trigger_embedding)\n",
    "            trigger_key_values = lm_trigger_output[\"past_key_values\"]\n",
    "        else:\n",
    "            trigger_key_values = expand_past(model.ori_trigger_key_values, num_layers, batch_size)\n",
    "        past = concat_past(past, trigger_key_values, num_layers)\n",
    "        \n",
    "    # prepare hidden\n",
    "    prev_hidden = bos_hidden.repeat(batch_size, 1, 1)\n",
    "    if cur_num_of_triggers > 0:\n",
    "        trigger_hidden = model.ori_trigger_hidden\n",
    "        trigger_hidden = trigger_hidden.repeat(batch_size, 1, 1)\n",
    "        prev_hidden = torch.cat((prev_hidden, trigger_hidden), dim=1)  # bze, seq_len, hid\n",
    "    \n",
    "    # prepare context\n",
    "    prev_length = prev_hidden.shape[1]\n",
    "    ctx_model_kwargs = dict()\n",
    "    ctx_inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "    # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "    cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "    ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "    # get encoder output\n",
    "    trigger_encoder_kwargs = {\n",
    "            argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "        }\n",
    "    trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "    try:\n",
    "        ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "    except:\n",
    "        print(ctx_inputs[\"input_ids\"].shape)\n",
    "        assert False\n",
    "        \n",
    "    ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "\n",
    "    ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "    # generate one sentence with trigger\n",
    "    ctx_input_ids = ctx_inputs['input_ids']\n",
    "    dec_input_ids = model._prepare_decoder_input_ids_for_generation(\n",
    "                    ctx_input_ids, decoder_start_token_id=bos_token_id, bos_token_id=bos_token_id)\n",
    "     \n",
    "    is_greedy_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_sample_gen_mode = (model.config.num_beams == 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    is_beam_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is False\n",
    "    is_beam_sample_gen_mode = (model.config.num_beams > 1) and (model.config.num_beam_groups == 1) and model.config.do_sample is True\n",
    "    \n",
    "    return_dict_in_generate = model.config.return_dict_in_generate\n",
    "    output_hidden_states = False\n",
    "    if is_response:\n",
    "        return_dict_in_generate = True\n",
    "        output_hidden_states = True\n",
    "    if use_gumbel:\n",
    "        return_dict_in_generate = True\n",
    "    \n",
    "    output_scores = False\n",
    "    if get_ppl:\n",
    "        output_scores = True\n",
    "        return_dict_in_generate = True\n",
    "        \n",
    "    if is_greedy_gen_mode:\n",
    "        res = model.greedy_search(\n",
    "                dec_input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=False,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "        \n",
    "    elif is_sample_gen_mode:\n",
    "\n",
    "        # expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids,\n",
    "            expand_size=model.config.num_return_sequences,\n",
    "            is_encoder_decoder=True,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "        \n",
    "\n",
    "        # sample\n",
    "        res = model.sample(\n",
    "            dec_input_ids,\n",
    "            logits_processor=logits_processor,\n",
    "            logits_warper=logits_warper,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=output_scores,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            use_gumbel=use_gumbel,\n",
    "            **ctx_model_kwargs,\n",
    "        )\n",
    "    elif is_beam_gen_mode:\n",
    "        # interleave with `num_beams`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_search(\n",
    "            dec_input_ids,\n",
    "            beam_scorer,\n",
    "            logits_processor=logits_processor,\n",
    "            max_length=model.config.max_length,\n",
    "            pad_token_id=pad_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            output_scores=False,\n",
    "            return_dict_in_generate=return_dict_in_generate,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            **ctx_model_kwargs,\n",
    "        ) \n",
    "    elif is_beam_sample_gen_mode:\n",
    "        # interleave with `num_beams * num_return_sequences`\n",
    "        dec_input_ids, ctx_model_kwargs = model._expand_inputs_for_generation(\n",
    "            dec_input_ids, expand_size=model.config.num_beams * model.config.num_return_sequences, is_encoder_decoder=True, **ctx_model_kwargs\n",
    "        )\n",
    "        res = model.beam_sample(\n",
    "                dec_input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                max_length=model.config.max_length,\n",
    "                pad_token_id=pad_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                output_scores=output_scores,\n",
    "                return_dict_in_generate=return_dict_in_generate,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                **ctx_model_kwargs,\n",
    "            )\n",
    "    \n",
    "    if use_gumbel:\n",
    "        generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        gumbel_vectors = res.gumbel_vectors\n",
    "        return generated_sentence_clean, gumbel_vectors\n",
    "    elif not is_response:  # generating prompts\n",
    "        if get_ppl:\n",
    "            generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "            generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "            \n",
    "            generated_sentence_mask = res.sequences.ne(pad_token_id).long()[:, :-2]  # the first one is bos\n",
    "            logits_tensor = torch.cat([raw_logits.unsqueeze(1) for raw_logits in res.scores], dim=1)  # bze x len x vocab\n",
    "            shift_logits = logits_tensor[..., :-1, :].contiguous()\n",
    "            shift_labels = res.sequences[..., 1:-1].contiguous()\n",
    "            loss_fct = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)).detach()\n",
    "            loss_reshape = loss.view(generated_sentence_mask.shape)  # bze x seq_len\n",
    "            # if loss is inf, then the masked loss (after multipling mask) will be nan\n",
    "            loss_reshape = torch.where(loss_reshape > 1e10, torch.ones_like(loss_reshape) * 0, loss_reshape)\n",
    "            masked_loss_sum = torch.sum(loss_reshape * generated_sentence_mask, dim=-1)  # [bze]\n",
    "            real_length = torch.sum(generated_sentence_mask, dim=-1)\n",
    "            masked_loss = torch.mean(masked_loss_sum / real_length).item()\n",
    "            ppl = math.exp(masked_loss)\n",
    "            return generated_sentence_clean, ppl\n",
    "        else:   \n",
    "            generated_sentence_raw = tokenizer.batch_decode(res)  \n",
    "            generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "            return generated_sentence_clean\n",
    "    else:\n",
    "        generated_sentence_raw = tokenizer.batch_decode(res.sequences)  \n",
    "        generated_sentence_clean = clean_blender_generation(generated_sentence_raw)\n",
    "        all_hidden_states = res.decoder_hidden_states  # tuple of hidden states (bze, 1, hid)\n",
    "        all_last_hidden_states_list = [i[-1] for i in all_hidden_states]\n",
    "        hidden_states = torch.cat(all_last_hidden_states_list, dim=1)  # bze, seq_len, hid\n",
    "        \n",
    "        generated_sentence_mask = res.sequences.ne(pad_token_id).long()[:, :-1]\n",
    "        \n",
    "        return generated_sentence_clean, hidden_states, generated_sentence_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8fcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_blender_generation(raw_texts):\n",
    "    clean_texts = list()\n",
    "    for sentence_i in raw_texts:\n",
    "        sentence_i_0 = sentence_i.split(\"<s>\")[-1]\n",
    "        sentence_i_1 = sentence_i_0.split(\"</s>\")[0]\n",
    "        clean_texts.append(sentence_i_1.strip())\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f79189e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cls_examples_to_features(texts_a, texts_b, max_length):\n",
    "    all_cls_input_ids, all_cls_attention_mask = list(), list()\n",
    "    for text_a, text_b in zip(texts_a, texts_b):\n",
    "        cls_inputs = cls_tokenizer.encode_plus(text_a, text_b, add_special_tokens=True, max_length=max_length, truncation=True)\n",
    "        cls_input_ids = cls_inputs[\"input_ids\"]\n",
    "        cls_attention_mask = [1] * len(cls_input_ids)\n",
    "        \n",
    "        padding_length = max_length - len(cls_input_ids)\n",
    "        \n",
    "        cls_input_ids = cls_input_ids + ([cls_tokenizer.pad_token_id] * padding_length)\n",
    "        cls_attention_mask = cls_attention_mask + ([0] * padding_length)\n",
    "        # token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)  # not used in RoBERTa\n",
    "        \n",
    "        all_cls_input_ids.append(cls_input_ids)\n",
    "        all_cls_attention_mask.append(cls_attention_mask)\n",
    "    \n",
    "    all_cls_input_tensors = torch.tensor(all_cls_input_ids, dtype=torch.long, device=device)\n",
    "    all_cls_attention_mask_tensors = torch.tensor(all_cls_attention_mask, dtype=torch.long, device=device)\n",
    "    \n",
    "    return all_cls_input_tensors, all_cls_attention_mask_tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09acbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implement gumbel softmax here\n",
    "# def generate_with_gumbel(c_texts, gumbel_vectors_tuple, prompt_texts, c_p_texts):\n",
    "#     past = expand_past(bos_key_values, num_enc_layers, mini_batch_size)  # deep copy? shouldn't be modifed\n",
    "#     # assume 1 trigger, key_value\n",
    "#     past = concat_past(past, past, num_enc_layers)\n",
    "    \n",
    "#     # prepare hidden\n",
    "#     prev_hidden = bos_hidden.repeat(mini_batch_size, 1, 1)\n",
    "#     prev_hidden = torch.cat((prev_hidden, prev_hidden), dim=1)\n",
    "    \n",
    "#     # prepare context\n",
    "#     prev_length = prev_hidden.shape[1]\n",
    "#     ctx_model_kwargs = dict()\n",
    "#     ctx_inputs = tokenizer(c_texts, return_tensors='pt', padding=True, truncation=True, max_length=126).to(\"cuda\")\n",
    "#     # because of the past, now key length (\"tgt\" as defined in blenderbot) is larger than query length (\"tgt\" as defined)\n",
    "#     cat_attn_mask = torch.cat((torch.ones(ctx_inputs[\"attention_mask\"].shape[0], prev_length, device=\"cuda\", dtype=torch.long), ctx_inputs[\"attention_mask\"]), dim=-1)\n",
    "#     ctx_model_kwargs[\"attention_mask\"] = cat_attn_mask\n",
    "    \n",
    "#     # get encoder output\n",
    "#     trigger_encoder_kwargs = {\n",
    "#             argument: value for argument, value in ctx_model_kwargs.items() if not argument.startswith(\"decoder_\")\n",
    "#         }\n",
    "#     trigger_encoder_kwargs[\"past_key_values\"] = past\n",
    "#     ctx_output = model.model.encoder(ctx_inputs[\"input_ids\"], return_dict=True, **trigger_encoder_kwargs, is_trigger=True)\n",
    "#     ctx_output[\"last_hidden_state\"] = torch.cat((prev_hidden, ctx_output[\"last_hidden_state\"]), dim=1)\n",
    "#     ctx_model_kwargs[\"encoder_outputs\"] = ctx_output\n",
    "    \n",
    "#     # prepare decoder\n",
    "#     prompt_inputs = tokenizer(p_texts, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "#     prompt_inputs_ids = prompt_inputs[\"input_ids\"]\n",
    "#     prompt_attn_mask = prompt_inputs[\"attention_mask\"]\n",
    "    \n",
    "#     gumbel_vectors_tensor = torch.cat(gumbel_vectors_tuple, dim=1)  # should be bze x seq_len x vocab_size\n",
    "#     assert gumbel_vectors_tensor.shape[1] == prompt_inputs_ids.shape[1], \"gumbel vector shape: %s; prompt inputs shape: %s\" % (str(gumbel_vectors_tensor.shape), str(prompt_inputs_ids.shape))\n",
    "#     prompt_inputs_emb = torch.matmul(gumbel_vectors_tensor, model.model.decoder.embed_tokens.weight.shape)  # bze x seq_len x hid\n",
    "    \n",
    "    \n",
    "#     # add bos\n",
    "#     dec_bos_ids = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device) * bos_token_id\n",
    "#     dec_bos_mask = torch.ones((prompt_inputs_ids.shape[0], 1), dtype=torch.long, device=device)\n",
    "#     dec_inputs_ids = torch.cat((dec_bos_ids, prompt_inputs_ids), dim=1)\n",
    "#     dec_attn_mask = torch.cat((dec_bos_mask, prompt_attn_mask), dim=1)\n",
    "#     prompt_length = torch.sum(dec_attn_mask, dim=-1)  # including bos and eos. shape: [bze]\n",
    "    \n",
    "#     model_inputs = {\"decoder_input_ids\": dec_inputs_ids, \"encoder_outputs\": ctx_model_kwargs[\"encoder_outputs\"],\n",
    "#                     \"attention_mask\": ctx_model_kwargs[\"attention_mask\"]}\n",
    "#     outputs = model(**model_inputs, return_dict=True)\n",
    "\n",
    "#     hidden_states = outputs[]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1931ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-10\n",
    "def get_representation(r_hidden, r_mask):  \n",
    "    cur_batch_size, hidden_size = r_hidden.shape[0], r_hidden.shape[-1]\n",
    "    r_mask = r_mask.unsqueeze(2).repeat(1, 1, hidden_size)\n",
    "    masked_hidden = r_hidden * r_mask\n",
    "    \n",
    "    avg_hidden = torch.sum(masked_hidden, dim=1) / (torch.sum(r_mask, dim=1).detach() + EPSILON)\n",
    "    return avg_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf13a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 1/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/60 [02:10<2:07:55, 130.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 2/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/60 [04:24<2:07:56, 132.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 3/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 3/60 [06:33<2:04:37, 131.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 4/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/60 [08:49<2:04:02, 132.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 5/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 5/60 [10:59<2:00:45, 131.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 6/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 6/60 [13:10<1:58:30, 131.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 7/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 7/60 [15:23<1:56:38, 132.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 8/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/60 [17:36<1:54:49, 132.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 9/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 9/60 [19:49<1:52:32, 132.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 10/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 10/60 [22:00<1:50:04, 132.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 11/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 11/60 [24:14<1:48:17, 132.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 12/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 12/60 [26:30<1:47:03, 133.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 13/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 13/60 [28:39<1:43:37, 132.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 14/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 14/60 [30:57<1:42:40, 133.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 15/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 15/60 [33:10<1:40:20, 133.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 16/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 16/60 [35:20<1:37:18, 132.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 17/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 17/60 [37:25<1:33:26, 130.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 18/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 18/60 [39:47<1:33:33, 133.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 19/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 19/60 [42:12<1:33:45, 137.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 20/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 20/60 [44:24<1:30:29, 135.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 21/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 21/60 [46:38<1:27:44, 134.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 22/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 22/60 [48:49<1:24:44, 133.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 23/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 23/60 [51:01<1:22:11, 133.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 24/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 24/60 [53:09<1:19:07, 131.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 25/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 25/60 [55:19<1:16:35, 131.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 26/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 26/60 [57:31<1:14:23, 131.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 27/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 27/60 [59:42<1:12:13, 131.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 28/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 28/60 [1:01:48<1:09:09, 129.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 29/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 29/60 [1:03:53<1:06:14, 128.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 30/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 30/60 [1:06:02<1:04:12, 128.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 31/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 31/60 [1:08:03<1:01:06, 126.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 32/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 32/60 [1:10:19<1:00:16, 129.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 33/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 33/60 [1:12:24<57:37, 128.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 34/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 34/60 [1:14:28<54:58, 126.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 35/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 35/60 [1:16:36<52:53, 126.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 36/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 36/60 [1:18:40<50:30, 126.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 37/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 37/60 [1:20:42<47:50, 124.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 38/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 38/60 [1:22:41<45:08, 123.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 39/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 39/60 [1:24:44<43:03, 123.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 40/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 40/60 [1:26:55<41:47, 125.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 41/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 41/60 [1:28:56<39:19, 124.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 42/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 42/60 [1:31:16<38:39, 128.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 43/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 43/60 [1:33:21<36:11, 127.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 44/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 44/60 [1:35:14<32:54, 123.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 45/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 45/60 [1:37:18<30:55, 123.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 46/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 46/60 [1:39:21<28:48, 123.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 47/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 47/60 [1:41:27<26:55, 124.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 48/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 48/60 [1:43:45<25:38, 128.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 49/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 49/60 [1:45:49<23:15, 126.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 50/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 50/60 [1:47:50<20:51, 125.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 51/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 51/60 [1:49:54<18:45, 125.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 52/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 52/60 [1:51:58<16:36, 124.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 53/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 53/60 [1:53:57<14:20, 122.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 54/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 54/60 [1:55:53<12:05, 120.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 55/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 55/60 [1:58:00<10:13, 122.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 56/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 56/60 [2:00:13<08:23, 125.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 57/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 57/60 [2:02:25<06:22, 127.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 58/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 58/60 [2:04:40<04:19, 129.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 59/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 59/60 [2:06:47<02:08, 128.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Epoch: 60/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [2:08:58<00:00, 128.97s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(total_steps // epoch_batch_size)):\n",
    "    print(\"***********Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(total_steps / epoch_batch_size))))\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = dict()\n",
    "    game_data = dict()\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    if mode == \"train\" and shuffle_data:\n",
    "        random.shuffle(context_list)\n",
    "    cond_list = context_list[:epoch_batch_size]\n",
    "    \n",
    "    log_context, log_prompt, log_response = list(), list(), list()\n",
    "    all_rewards = list()\n",
    "    all_ppl = list()\n",
    "    all_c_p_rewards = list()\n",
    "    \n",
    "    # check real reward:\n",
    "    for i in range(int(epoch_batch_size / batch_size)):\n",
    "        ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "        log_context += ctx_i\n",
    "        \n",
    "        p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "        log_prompt += p_texts\n",
    "        all_ppl.append(p_ppl)\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "        \n",
    "        c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        try:\n",
    "            r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "        except Exception as e:\n",
    "            print(c_p_inputs[\"input_ids\"].shape)\n",
    "            print(ctx_i)\n",
    "            print(c_p_texts)\n",
    "            assert False, \"Exception: %s\" % e\n",
    "        r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "        r_texts = clean_blender_generation(r_texts_raw)\n",
    "        log_response += r_texts\n",
    "        \n",
    "         # run classifier for rewards        \n",
    "        cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "        cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"][:, tgt_label].detach() \n",
    "            c_p_res = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"][:, tgt_label].detach() \n",
    "\n",
    "        all_c_p_rewards.append(c_p_res)\n",
    "        all_rewards.append(res)  # [bze]\n",
    "        \n",
    "    # logging\n",
    "    log_name = \"game_log_e%d\" % (epoch + 1)\n",
    "    log_rewards = torch.cat(all_rewards)\n",
    "    log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "    log_ppl = sum(all_ppl) / len(all_ppl)\n",
    "    table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist())]\n",
    "    logs.update({log_name:wandb.Table(\n",
    "        columns=['context', 'prompt', 'response', 'reward'],\n",
    "        rows=table_rows)})\n",
    "    logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "    logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "    logs['env/c_p_reward_mean'] = torch.mean(log_c_p_rewards).cpu().numpy()\n",
    "    logs['env/p_ppl'] = log_ppl\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.log(logs)\n",
    "    \n",
    "    model.zero_grad()\n",
    "     \n",
    "    # real training\n",
    "    for i in range(int(epoch_batch_size / batch_size)):\n",
    "        loss_per_update = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "#         p_texts, p_gumbel_vectors = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, use_gumbel=True)\n",
    "        p_texts = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers)\n",
    "        log_prompt += p_texts\n",
    "        \n",
    "        c_p_texts = list()\n",
    "        for c, p in zip(ctx_i, p_texts):\n",
    "            c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "        \n",
    "        # without gumbel softmax. Need to run generate_with_gumbel to use gumbel softmax\n",
    "        r_texts, r_hidden, r_mask = generate_sentence_with_trigger(c_p_texts, num_enc_layers, num_of_triggers, is_response=True)    \n",
    "        \n",
    "        # r_hidden_mask?????????\n",
    "#         with torch.no_grad():\n",
    "        avg_hidden = get_representation(r_hidden, r_mask)\n",
    "        prediction = classifier(avg_hidden)\n",
    "        # WARNING: There is a weird bug: used to be tgt_label, which somehow changed to (0,). so use [0] directly here\n",
    "        label = torch.tensor([0], device=device, dtype=torch.long).repeat(batch_size)\n",
    "        discrim_loss = ce_loss(prediction, label)\n",
    "        \n",
    "        loss_per_update += discrim_loss.item()\n",
    "        \n",
    "        discrim_loss.backward()\n",
    "        \n",
    "#         print(\"Debuggin current key_value\")\n",
    "#         print(model.l_1_value[:, 0, :, :10])\n",
    "#         print(model.ori_trigger_hidden[:, :, :10])\n",
    "#         print(\"++++++++++++\\n\\n\\n\")\n",
    "        \n",
    "        if (i + 1) % gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "#             print(\"\\n=======update loss: %.6f=======\" % (loss_per_update / gradient_accumulation_steps))\n",
    "            total_loss += loss_per_update\n",
    "            loss_per_update = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # save trigger\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_filename = \"%s/e%d.pt\" % (save_path, epoch + 1)\n",
    "    save_data = dict()\n",
    "    save_data[\"ori_trigger_hidden\"] = model.ori_trigger_hidden\n",
    "    if trigger_format == \"token\":\n",
    "        save_data[\"ori_trigger_embedding\"] = model.ori_trigger_embedding\n",
    "    else:\n",
    "        save_data[\"ori_trigger_key_values\"] = model.ori_trigger_key_values\n",
    "    torch.save(save_data, save_filename)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6596e23",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad924177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Evaluating a saved model\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "saved_model_path = \"/mnt//trigger_experiments/semi_safety/e60.pt\"\n",
    "saved_dict = torch.load(saved_model_path)\n",
    "model.ori_trigger_hidden = saved_dict[\"ori_trigger_hidden\"]\n",
    "model.ori_trigger_key_values = saved_dict[\"ori_trigger_key_values\"]\n",
    "print(\"WARNING: Evaluating a saved model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cbced3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating data/trigger_bad_valid.txt\n",
      "***********Evaluation at Epoch: 60/60*************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [10:56<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env/reward_mean': array(-0.7983979, dtype=float32), 'env/reward_std': array(1.3177015, dtype=float32), 'env/c_p_probs_mean': array(0.67617565, dtype=float32), 'env/c_p_probs_std': array(0.38747743, dtype=float32), 'env/reward_prob_mean': array(0.31896862, dtype=float32), 'env/reward_prob_std': array(0.3358653, dtype=float32), 'env/p_ppl': 17.783813842696706}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "softmax_fn = nn.Softmax(dim=-1)\n",
    "\n",
    "import csv\n",
    "\n",
    "csv_file = open(\"data/safety_train_all_semi_final_e60_1.csv\", \"w\")\n",
    "\n",
    "\n",
    "\n",
    "eval_context_filename = \"data/trigger_bad_valid.txt\"\n",
    "eval_context_list = read_file(eval_context_filename)\n",
    "print(\"evaluating %s\" % eval_context_filename)\n",
    "print(\"***********Evaluation at Epoch: %d/%d*************\" % (epoch + 1, int(np.ceil(total_steps / epoch_batch_size))))\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "logs = dict()\n",
    "game_data = dict()\n",
    "timing = dict()\n",
    "t0 = time.time()\n",
    "\n",
    "#### get everything from the dataset\n",
    "cond_list = eval_context_list\n",
    "\n",
    "all_rewards, all_c_p_r_rewards, all_c_p_rewards, all_c_p_rewards_adjusted = list(), list(), list(), list()\n",
    "all_probs, all_c_p_probs = list(), list()\n",
    "log_context, log_prompt, log_response = list(), list(), list()\n",
    "all_ppl = list()\n",
    "\n",
    "all_c_texts, all_p_texts = list(), list()\n",
    "all_r_texts, all_c_p_r_texts = list(), list()  # for debugging\n",
    "\n",
    "#### get prompt from model\n",
    "for i in tqdm(range(int(len(eval_context_list) / batch_size))):\n",
    "    ctx_i = cond_list[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    log_context += ctx_i\n",
    "\n",
    "    p_texts, p_ppl = generate_sentence_with_trigger(ctx_i, num_enc_layers, num_of_triggers, get_ppl=True)\n",
    "    log_prompt += p_texts\n",
    "    all_ppl.append(p_ppl)\n",
    "\n",
    "    c_p_texts = list()\n",
    "    for c, p in zip(ctx_i, p_texts):\n",
    "        c_p_texts.append(\"%s   %s\" % (c, p))\n",
    "\n",
    "    c_p_inputs = tokenizer(c_p_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    try:\n",
    "        r_tensor = model.generate(c_p_inputs['input_ids'], num_beams=model.config.num_beams, do_sample=model.config.do_sample)\n",
    "    except Exception as e:\n",
    "        print(c_p_inputs[\"input_ids\"].shape)\n",
    "        print(ctx_i)\n",
    "        print(c_p_texts)\n",
    "        assert False, \"Exception: %s\" % e\n",
    "    r_texts_raw = tokenizer.batch_decode(r_tensor)\n",
    "    r_texts = clean_blender_generation(r_texts_raw)\n",
    "    log_response += r_texts\n",
    "\n",
    "    c_p_r_texts = list()\n",
    "    for c_p, r in zip(c_p_texts, r_texts):\n",
    "        c_p_r_texts.append(\"%s   %s\" % (c_p, r))\n",
    "\n",
    "\n",
    "    all_c_texts.append(ctx_i)\n",
    "    all_p_texts.append(p_texts)\n",
    "    all_r_texts.append(r_texts)\n",
    "    all_c_p_r_texts.append(c_p_r_texts)\n",
    "\n",
    "\n",
    "    # run classifier for rewards        \n",
    "    cls_c_p_r_inputs, cls_c_p_r_mask = convert_cls_examples_to_features(r_texts, c_p_texts, cls_max_length)\n",
    "    cls_c_p_inputs, cls_c_p_mask = convert_cls_examples_to_features(p_texts, ctx_i, cls_max_length)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_logits = cls_model(cls_c_p_r_inputs, cls_c_p_r_mask)[\"logits\"]\n",
    "        res = all_logits[:, tgt_label].detach() \n",
    "        res_probs = softmax_fn(all_logits)[:, tgt_label].detach() \n",
    "        \n",
    "        c_p_logits = cls_model(cls_c_p_inputs, cls_c_p_mask)[\"logits\"]\n",
    "        c_p_res = c_p_logits[:, tgt_label].detach() \n",
    "        c_p_res_probs = softmax_fn(c_p_logits)[:, tgt_label].detach()\n",
    "\n",
    "\n",
    "\n",
    "    all_rewards.append(res)  # [bze]\n",
    "    # if prompt_reward, all_probs is actually for c_p_r\n",
    "    all_probs.append(res_probs)\n",
    "    all_c_p_rewards.append(c_p_res)\n",
    "    all_c_p_probs.append(c_p_res_probs)\n",
    "    \n",
    "log_name = \"evaluation %s @e%d\" % (eval_context_filename, epoch + 1)\n",
    "log_rewards = torch.cat(all_rewards)\n",
    "log_probs = torch.cat(all_probs)\n",
    "log_c_p_rewards = torch.cat(all_c_p_rewards)\n",
    "log_c_p_probs = torch.cat(all_c_p_probs)\n",
    "\n",
    "log_ppl = sum(all_ppl) / len(all_ppl)   \n",
    "\n",
    "table_rows = [list(r) for r in zip(log_context, log_prompt, log_response, log_rewards.cpu().tolist(), log_probs.cpu().tolist(), log_c_p_rewards.cpu().tolist(), log_c_p_probs.cpu().tolist(),)]\n",
    "\n",
    "fieldnames = ['context', 'prompt', 'response', 'reward', 'probs', 'c_p_reward', 'c_p_probs']\n",
    "\n",
    "logs['env/reward_mean'] = torch.mean(log_rewards).cpu().numpy()\n",
    "logs['env/reward_std'] = torch.std(log_rewards).cpu().numpy()\n",
    "\n",
    "logs['env/c_p_probs_mean'] = torch.mean(log_c_p_probs).cpu().numpy()\n",
    "logs['env/c_p_probs_std'] = torch.std(log_c_p_probs).cpu().numpy()\n",
    "    \n",
    "logs['env/reward_prob_mean'] = torch.mean(log_probs).cpu().numpy()\n",
    "logs['env/reward_prob_std'] = torch.std(log_probs).cpu().numpy()\n",
    "logs['env/p_ppl'] = log_ppl\n",
    "\n",
    "\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "for row_list in table_rows:\n",
    "    row_dict = dict()\n",
    "    for row_name, row_item in zip(fieldnames, row_list):\n",
    "        row_dict[row_name] = row_item\n",
    "    writer.writerow(row_dict)\n",
    "\n",
    "print(logs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae2636a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero",
   "language": "python",
   "name": "zero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
